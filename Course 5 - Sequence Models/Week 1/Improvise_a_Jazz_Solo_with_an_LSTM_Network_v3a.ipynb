{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvise a Jazz Solo with an LSTM Network\n",
    "\n",
    "Welcome to your final programming assignment of this week! In this notebook, you will implement a model that uses an LSTM to generate music. You will even be able to listen to your own music at the end of the assignment. \n",
    "\n",
    "**You will learn to:**\n",
    "- Apply an LSTM to music generation.\n",
    "- Generate your own jazz music with deep learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Updates</font>\n",
    "\n",
    "#### If you were working on the notebook before this update...\n",
    "* The current notebook is version \"3a\".\n",
    "* You can find your original work saved in the notebook with the previous version name (\"v3\") \n",
    "* To view the file directory, go to the menu \"File->Open\", and this will open a new tab that shows the file directory.\n",
    "\n",
    "#### List of updates\n",
    "* `djmodel`\n",
    "    - Explains `Input` layer and its parameter `shape`.\n",
    "    - Explains `Lambda` layer and replaces the given solution with hints and sample code (to improve the learning experience).\n",
    "    - Adds hints for using the Keras `Model`.\n",
    "* `music_inference_model`\n",
    "    - Explains each line of code in the `one_hot` function.\n",
    "    - Explains how to apply `one_hot` with a Lambda layer instead of giving the code solution (to improve the learning experience).\n",
    "    - Adds instructions on defining the `Model`.\n",
    "* `predict_and_sample`\n",
    "    - Provides detailed instructions for each step.\n",
    "    - Clarifies which variable/function to use for inference.\n",
    "* Spelling, grammar and wording corrections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following cell to load all the packages required in this assignment. This may take a few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import IPython\n",
    "import sys\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "from grammar import *\n",
    "from qa import *\n",
    "from preprocess import * \n",
    "from music_utils import *\n",
    "from data_utils import *\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Problem statement\n",
    "\n",
    "You would like to create a jazz music piece specially for a friend's birthday. However, you don't know any instruments or music composition. Fortunately, you know deep learning and will solve this problem using an LSTM network.  \n",
    "\n",
    "You will train a network to generate novel jazz solos in a style representative of a body of performed work.\n",
    "\n",
    "<img src=\"images/jazz.jpg\" style=\"width:450;height:300px;\">\n",
    "\n",
    "\n",
    "### 1.1 - Dataset\n",
    "\n",
    "You will train your algorithm on a corpus of Jazz music. Run the cell below to listen to a snippet of the audio from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio('./data/30s_seq.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have taken care of the preprocessing of the musical data to render it in terms of musical \"values.\" \n",
    "\n",
    "#### Details about music (optional)\n",
    "You can informally think of each \"value\" as a note, which comprises a pitch and duration. For example, if you press down a specific piano key for 0.5 seconds, then you have just played a note. In music theory, a \"value\" is actually more complicated than this--specifically, it also captures the information needed to play multiple notes at the same time. For example, when playing a music piece, you might press down two piano keys at the same time (playing multiple notes at the same time generates what's called a \"chord\"). But we don't need to worry about the details of music theory for this assignment. \n",
    "\n",
    "#### Music as a sequence of values\n",
    "* For the purpose of this assignment, all you need to know is that we will obtain a dataset of values, and will learn an RNN model to generate sequences of values. \n",
    "* Our music generation system will use 78 unique values. \n",
    "\n",
    "Run the following code to load the raw music data and preprocess it into values. This might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples: 60\n",
      "Tx (length of sequence): 30\n",
      "total # of unique values: 78\n",
      "shape of X: (60, 30, 78)\n",
      "Shape of Y: (30, 60, 78)\n"
     ]
    }
   ],
   "source": [
    "X, Y, n_values, indices_values = load_music_utils()\n",
    "print('number of training examples:', X.shape[0])\n",
    "print('Tx (length of sequence):', X.shape[1])\n",
    "print('total # of unique values:', n_values)\n",
    "print('shape of X:', X.shape)\n",
    "print('Shape of Y:', Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have just loaded the following:\n",
    "\n",
    "- `X`: This is an (m, $T_x$, 78) dimensional array. \n",
    "    - We have m training examples, each of which is a snippet of $T_x =30$ musical values. \n",
    "    - At each time step, the input is one of 78 different possible values, represented as a one-hot vector. \n",
    "        - For example, X[i,t,:] is a one-hot vector representing the value of the i-th example at time t. \n",
    "\n",
    "- `Y`: a $(T_y, m, 78)$ dimensional array\n",
    "    - This is essentially the same as `X`, but shifted one step to the left (to the past). \n",
    "    - Notice that the data in `Y` is **reordered** to be dimension $(T_y, m, 78)$, where $T_y = T_x$. This format makes it more convenient to feed into the LSTM later.\n",
    "    - Similar to the dinosaur assignment, we're using the previous values to predict the next value.\n",
    "        - So our sequence model will try to predict $y^{\\langle t \\rangle}$ given $x^{\\langle 1\\rangle}, \\ldots, x^{\\langle t \\rangle}$. \n",
    "\n",
    "- `n_values`: The number of unique values in this dataset. This should be 78. \n",
    "\n",
    "- `indices_values`: python dictionary mapping integers 0 through 77 to musical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Overview of our model\n",
    "\n",
    "Here is the architecture of the model we will use. This is similar to the Dinosaurus model, except that you will implement it in Keras.\n",
    "\n",
    "<img src=\"images/music_generation.png\" style=\"width:600;height:400px;\">\n",
    "\n",
    "\n",
    "* $X = (x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, \\cdots, x^{\\langle T_x \\rangle})$ is a window of size $T_x$ scanned over the musical corpus. \n",
    "* Each $x^{\\langle t \\rangle}$ is an index corresponding to a value.\n",
    "* $\\hat{y}^{t}$ is the prediction for the next value.\n",
    "* We will be training the model on random snippets of 30 values taken from a much longer piece of music. \n",
    "    - Thus, we won't bother to set the first input $x^{\\langle 1 \\rangle} = \\vec{0}$, since most of these snippets of audio start somewhere in the middle of a piece of music. \n",
    "    - We are setting each of the snippets to have the same length $T_x = 30$ to make vectorization easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of parts 2 and 3\n",
    "\n",
    "* We're going to train a model that predicts the next note in a style that is similar to the jazz music that it's trained on.  The training is contained in the weights and biases of the model. \n",
    "* In Part 3, we're then going to use those weights and biases in a new model which predicts a series of notes, using the previous note to predict the next note. \n",
    "* The weights and biases are transferred to the new model using 'global shared layers' described below\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Building the model\n",
    "\n",
    "* In this part you will build and train a model that will learn musical patterns. \n",
    "* The model takes input X of shape $(m, T_x, 78)$ and labels Y of shape $(T_y, m, 78)$. \n",
    "* We will use an LSTM with hidden states that have $n_{a} = 64$ dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of dimensions for the hidden state of each LSTM cell.\n",
    "n_a = 64 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Sequence generation uses a for-loop\n",
    "* If you're building an RNN where, at test time, the entire input sequence $x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, \\ldots, x^{\\langle T_x \\rangle}$ is given in advance, then Keras has simple built-in functions to build the model. \n",
    "* However, for **sequence generation, at test time we don't know all the values of $x^{\\langle t\\rangle}$ in advance**.\n",
    "* Instead we generate them one at a time using $x^{\\langle t\\rangle} = y^{\\langle t-1 \\rangle}$. \n",
    "    * The input at time \"t\" is the prediction at the previous time step \"t-1\".\n",
    "* So you'll need to implement your own for-loop to iterate over the time steps. \n",
    "\n",
    "#### Shareable weights\n",
    "* The function `djmodel()` will call the LSTM layer $T_x$ times using a for-loop.\n",
    "* It is important that all $T_x$ copies have the same weights. \n",
    "    - The $T_x$ steps should have shared weights that aren't re-initialized.\n",
    "* Referencing a globally defined shared layer will utilize the same layer-object instance at each time step.\n",
    "* The key steps for implementing layers with shareable weights in Keras are: \n",
    "1. Define the layer objects (we will use global variables for this).\n",
    "2. Call these objects when propagating the input.\n",
    "\n",
    "#### 3 types of layers\n",
    "* We have defined the layers objects you need as global variables.  \n",
    "* Please run the next cell to create them. \n",
    "* Please read the Keras documentation and understand these layers: \n",
    "    - [Reshape()](https://keras.io/layers/core/#reshape): Reshapes an output to a certain shape.\n",
    "    - [LSTM()](https://keras.io/layers/recurrent/#lstm): Long Short-Term Memory layer\n",
    "    - [Dense()](https://keras.io/layers/core/#dense): A regular fully-connected neural network layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_values = 78 # number of music values\n",
    "reshapor = Reshape((1, n_values))                        # Used in Step 2.B of djmodel(), below\n",
    "LSTM_cell = LSTM(n_a, return_state = True)         # Used in Step 2.C\n",
    "densor = Dense(n_values, activation='softmax')     # Used in Step 2.D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `reshapor`, `LSTM_cell` and `densor` are globally defined layer objects, that you'll use to implement `djmodel()`. \n",
    "* In order to propagate a Keras tensor object X through one of these layers, use `layer_object()`.\n",
    "    - For one input, use `layer_object(X)`\n",
    "    - For more than one input, put the inputs in a list: `layer_object([X1,X2])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Exercise**: Implement `djmodel()`. \n",
    "\n",
    "#### Inputs (given)\n",
    "* The `Input()` layer is used for defining the input `X` as well as the initial hidden state 'a0' and cell state `c0`.\n",
    "* The `shape` parameter takes a tuple that does not include the batch dimension (`m`).\n",
    "    - For example,\n",
    "    ```Python\n",
    "    X = Input(shape=(Tx, n_values)) # X has 3 dimensions and not 2: (m, Tx, n_values)\n",
    "    ```\n",
    "#### Step 1: Outputs (TODO)\n",
    "1. Create an empty list \"outputs\" to save the outputs of the LSTM Cell at every time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Loop through time steps (TODO)\n",
    "* Loop for $t \\in 1, \\ldots, T_x$:\n",
    "\n",
    "#### 2A. Select the 't' time-step vector from X.\n",
    "* X has the shape (m, Tx, n_values).\n",
    "* The shape of the 't' selection should be (n_values,). \n",
    "* Recall that if you were implementing in numpy instead of Keras, you would extract a slice from a 3D numpy array like this:\n",
    "```Python\n",
    "var1 = array1[:,1,:]\n",
    "```\n",
    "    \n",
    "#### Lambda layer\n",
    "* Since we're using Keras, we need to define this step inside a custom layer.\n",
    "* In Keras, this is a Lambda layer [Lambda](https://keras.io/layers/core/#lambda)\n",
    "* As an example, a Lambda layer that takes the previous layer and adds '1' looks like this\n",
    "```    \n",
    "       lambda_layer1 = Lambda(lambda z: z + 1)(previous_layer)\n",
    "``` \n",
    "* The previous layer in this case is `X`.\n",
    "* `z` is a local variable of the lambda function. \n",
    "    * The `previous_layer` gets passed into the parameter `z` in the lowercase `lambda` function.\n",
    "    * You can choose the name of the variable to be something else if you want.\n",
    "* The operation after the colon ':' should be the operation to extract a slice from the previous layer.\n",
    "* **Hint**: You'll be using the variable `t` within the definition of the lambda layer even though it isn't passed in as an argument to Lambda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2B. Reshape x to be (1,n_values).\n",
    "* Use the `reshapor()` layer.  It is a function that takes the previous layer as its input argument.\n",
    "\n",
    "#### 2C. Run x through one step of LSTM_cell.\n",
    "* Initialize the `LSTM_cell` with the previous step's hidden state $a$ and cell state $c$. \n",
    "* Use the following formatting:\n",
    "```python\n",
    "next_hidden_state, _, next_cell_state = LSTM_cell(inputs=input_x, initial_state=[previous_hidden_state, previous_cell_state])\n",
    "```\n",
    "    * Choose appropriate variables for inputs, hidden state and cell state.\n",
    "\n",
    "#### 2D. Dense layer\n",
    "* Propagate the LSTM's hidden state through a dense+softmax layer using `densor`. \n",
    "    \n",
    "#### 2E. Append output\n",
    "* Append the output to the list of \"outputs\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: After the loop, create the model\n",
    "* Use the Keras `Model` object to create a model.\n",
    "* specify the inputs and outputs:\n",
    "```Python\n",
    "model = Model(inputs=[input_x, initial_hidden_state, initial_cell_state], outputs=the_outputs)\n",
    "```\n",
    "    * Choose the appropriate variables for the input tensor, hidden state, cell state, and output.\n",
    "* See the documentation for [Model](https://keras.io/models/model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: djmodel\n",
    "\n",
    "def djmodel(Tx, n_a, n_values):\n",
    "    \"\"\"\n",
    "    Implement the model\n",
    "    \n",
    "    Arguments:\n",
    "    Tx -- length of the sequence in a corpus\n",
    "    n_a -- the number of activations used in our model\n",
    "    n_values -- number of unique values in the music data \n",
    "    \n",
    "    Returns:\n",
    "    model -- a keras instance model with n_a activations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input layer and specify the shape\n",
    "    X = Input(shape=(Tx, n_values))\n",
    "    \n",
    "    # Define the initial hidden state a0 and initial cell state c0\n",
    "    # using `Input`\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    # Step 1: Create empty list to append the outputs while you iterate (≈1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop\n",
    "    for t in range(Tx):\n",
    "        \n",
    "        # Step 2.A: select the \"t\"th time step vector from X. \n",
    "        x = Lambda(lambda z: z[:, t, :])(X)\n",
    "        # Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)\n",
    "        x = reshapor(x)\n",
    "        # Step 2.C: Perform one step of the LSTM_cell\n",
    "        a, _, c = LSTM_cell(inputs=x, initial_state=[a, c])\n",
    "        # Step 2.D: Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = densor(a)\n",
    "        # Step 2.E: add the output to \"outputs\"\n",
    "        outputs.append(out)\n",
    "        \n",
    "    # Step 3: Create model instance\n",
    "    model = Model(inputs=[X, a0, c0], outputs=outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model object\n",
    "* Run the following cell to define your model. \n",
    "* We will use `Tx=30`, `n_a=64` (the dimension of the LSTM activations), and `n_values=78`. \n",
    "* This cell may take a few seconds to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = djmodel(Tx = 30 , n_a = 64, n_values = 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 30, 78)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 1, 78)         0           lambda_1[0][0]                   \n",
      "                                                                   lambda_2[0][0]                   \n",
      "                                                                   lambda_3[0][0]                   \n",
      "                                                                   lambda_4[0][0]                   \n",
      "                                                                   lambda_5[0][0]                   \n",
      "                                                                   lambda_6[0][0]                   \n",
      "                                                                   lambda_7[0][0]                   \n",
      "                                                                   lambda_8[0][0]                   \n",
      "                                                                   lambda_9[0][0]                   \n",
      "                                                                   lambda_10[0][0]                  \n",
      "                                                                   lambda_11[0][0]                  \n",
      "                                                                   lambda_12[0][0]                  \n",
      "                                                                   lambda_13[0][0]                  \n",
      "                                                                   lambda_14[0][0]                  \n",
      "                                                                   lambda_15[0][0]                  \n",
      "                                                                   lambda_16[0][0]                  \n",
      "                                                                   lambda_17[0][0]                  \n",
      "                                                                   lambda_18[0][0]                  \n",
      "                                                                   lambda_19[0][0]                  \n",
      "                                                                   lambda_20[0][0]                  \n",
      "                                                                   lambda_21[0][0]                  \n",
      "                                                                   lambda_22[0][0]                  \n",
      "                                                                   lambda_23[0][0]                  \n",
      "                                                                   lambda_24[0][0]                  \n",
      "                                                                   lambda_25[0][0]                  \n",
      "                                                                   lambda_26[0][0]                  \n",
      "                                                                   lambda_27[0][0]                  \n",
      "                                                                   lambda_28[0][0]                  \n",
      "                                                                   lambda_29[0][0]                  \n",
      "                                                                   lambda_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "a0 (InputLayer)                  (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c0 (InputLayer)                  (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    [(None, 64), (None, 6 36608       reshape_1[0][0]                  \n",
      "                                                                   a0[0][0]                         \n",
      "                                                                   c0[0][0]                         \n",
      "                                                                   reshape_1[1][0]                  \n",
      "                                                                   lstm_1[0][0]                     \n",
      "                                                                   lstm_1[0][2]                     \n",
      "                                                                   reshape_1[2][0]                  \n",
      "                                                                   lstm_1[1][0]                     \n",
      "                                                                   lstm_1[1][2]                     \n",
      "                                                                   reshape_1[3][0]                  \n",
      "                                                                   lstm_1[2][0]                     \n",
      "                                                                   lstm_1[2][2]                     \n",
      "                                                                   reshape_1[4][0]                  \n",
      "                                                                   lstm_1[3][0]                     \n",
      "                                                                   lstm_1[3][2]                     \n",
      "                                                                   reshape_1[5][0]                  \n",
      "                                                                   lstm_1[4][0]                     \n",
      "                                                                   lstm_1[4][2]                     \n",
      "                                                                   reshape_1[6][0]                  \n",
      "                                                                   lstm_1[5][0]                     \n",
      "                                                                   lstm_1[5][2]                     \n",
      "                                                                   reshape_1[7][0]                  \n",
      "                                                                   lstm_1[6][0]                     \n",
      "                                                                   lstm_1[6][2]                     \n",
      "                                                                   reshape_1[8][0]                  \n",
      "                                                                   lstm_1[7][0]                     \n",
      "                                                                   lstm_1[7][2]                     \n",
      "                                                                   reshape_1[9][0]                  \n",
      "                                                                   lstm_1[8][0]                     \n",
      "                                                                   lstm_1[8][2]                     \n",
      "                                                                   reshape_1[10][0]                 \n",
      "                                                                   lstm_1[9][0]                     \n",
      "                                                                   lstm_1[9][2]                     \n",
      "                                                                   reshape_1[11][0]                 \n",
      "                                                                   lstm_1[10][0]                    \n",
      "                                                                   lstm_1[10][2]                    \n",
      "                                                                   reshape_1[12][0]                 \n",
      "                                                                   lstm_1[11][0]                    \n",
      "                                                                   lstm_1[11][2]                    \n",
      "                                                                   reshape_1[13][0]                 \n",
      "                                                                   lstm_1[12][0]                    \n",
      "                                                                   lstm_1[12][2]                    \n",
      "                                                                   reshape_1[14][0]                 \n",
      "                                                                   lstm_1[13][0]                    \n",
      "                                                                   lstm_1[13][2]                    \n",
      "                                                                   reshape_1[15][0]                 \n",
      "                                                                   lstm_1[14][0]                    \n",
      "                                                                   lstm_1[14][2]                    \n",
      "                                                                   reshape_1[16][0]                 \n",
      "                                                                   lstm_1[15][0]                    \n",
      "                                                                   lstm_1[15][2]                    \n",
      "                                                                   reshape_1[17][0]                 \n",
      "                                                                   lstm_1[16][0]                    \n",
      "                                                                   lstm_1[16][2]                    \n",
      "                                                                   reshape_1[18][0]                 \n",
      "                                                                   lstm_1[17][0]                    \n",
      "                                                                   lstm_1[17][2]                    \n",
      "                                                                   reshape_1[19][0]                 \n",
      "                                                                   lstm_1[18][0]                    \n",
      "                                                                   lstm_1[18][2]                    \n",
      "                                                                   reshape_1[20][0]                 \n",
      "                                                                   lstm_1[19][0]                    \n",
      "                                                                   lstm_1[19][2]                    \n",
      "                                                                   reshape_1[21][0]                 \n",
      "                                                                   lstm_1[20][0]                    \n",
      "                                                                   lstm_1[20][2]                    \n",
      "                                                                   reshape_1[22][0]                 \n",
      "                                                                   lstm_1[21][0]                    \n",
      "                                                                   lstm_1[21][2]                    \n",
      "                                                                   reshape_1[23][0]                 \n",
      "                                                                   lstm_1[22][0]                    \n",
      "                                                                   lstm_1[22][2]                    \n",
      "                                                                   reshape_1[24][0]                 \n",
      "                                                                   lstm_1[23][0]                    \n",
      "                                                                   lstm_1[23][2]                    \n",
      "                                                                   reshape_1[25][0]                 \n",
      "                                                                   lstm_1[24][0]                    \n",
      "                                                                   lstm_1[24][2]                    \n",
      "                                                                   reshape_1[26][0]                 \n",
      "                                                                   lstm_1[25][0]                    \n",
      "                                                                   lstm_1[25][2]                    \n",
      "                                                                   reshape_1[27][0]                 \n",
      "                                                                   lstm_1[26][0]                    \n",
      "                                                                   lstm_1[26][2]                    \n",
      "                                                                   reshape_1[28][0]                 \n",
      "                                                                   lstm_1[27][0]                    \n",
      "                                                                   lstm_1[27][2]                    \n",
      "                                                                   reshape_1[29][0]                 \n",
      "                                                                   lstm_1[28][0]                    \n",
      "                                                                   lstm_1[28][2]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)                (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)                (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)                (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)                (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)                (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)                (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)                (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)               (None, 78)            0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 78)            5070        lstm_1[0][0]                     \n",
      "                                                                   lstm_1[1][0]                     \n",
      "                                                                   lstm_1[2][0]                     \n",
      "                                                                   lstm_1[3][0]                     \n",
      "                                                                   lstm_1[4][0]                     \n",
      "                                                                   lstm_1[5][0]                     \n",
      "                                                                   lstm_1[6][0]                     \n",
      "                                                                   lstm_1[7][0]                     \n",
      "                                                                   lstm_1[8][0]                     \n",
      "                                                                   lstm_1[9][0]                     \n",
      "                                                                   lstm_1[10][0]                    \n",
      "                                                                   lstm_1[11][0]                    \n",
      "                                                                   lstm_1[12][0]                    \n",
      "                                                                   lstm_1[13][0]                    \n",
      "                                                                   lstm_1[14][0]                    \n",
      "                                                                   lstm_1[15][0]                    \n",
      "                                                                   lstm_1[16][0]                    \n",
      "                                                                   lstm_1[17][0]                    \n",
      "                                                                   lstm_1[18][0]                    \n",
      "                                                                   lstm_1[19][0]                    \n",
      "                                                                   lstm_1[20][0]                    \n",
      "                                                                   lstm_1[21][0]                    \n",
      "                                                                   lstm_1[22][0]                    \n",
      "                                                                   lstm_1[23][0]                    \n",
      "                                                                   lstm_1[24][0]                    \n",
      "                                                                   lstm_1[25][0]                    \n",
      "                                                                   lstm_1[26][0]                    \n",
      "                                                                   lstm_1[27][0]                    \n",
      "                                                                   lstm_1[28][0]                    \n",
      "                                                                   lstm_1[29][0]                    \n",
      "====================================================================================================\n",
      "Total params: 41,678\n",
      "Trainable params: 41,678\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**  \n",
    "Scroll to the bottom of the output, and you'll see the following:\n",
    "\n",
    "```Python\n",
    "Total params: 41,678\n",
    "Trainable params: 41,678\n",
    "Non-trainable params: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model for training\n",
    "* You now need to compile your model to be trained. \n",
    "* We will use:\n",
    "    - optimizer: Adam optimizer\n",
    "    - Loss function: categorical cross-entropy (for multi-class classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize hidden state and cell state\n",
    "Finally, let's initialize `a0` and `c0` for the LSTM's initial state to be zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = 60\n",
    "a0 = np.zeros((m, n_a))\n",
    "c0 = np.zeros((m, n_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "* Lets now fit the model! \n",
    "* We will turn `Y` into a list, since the cost function expects `Y` to be provided in this format \n",
    "    - `list(Y)` is a list with 30 items, where each of the list items is of shape (60,78). \n",
    "    - Lets train for 100 epochs. This will take a few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 4s - loss: 126.0101 - dense_1_loss_1: 4.3552 - dense_1_loss_2: 4.3542 - dense_1_loss_3: 4.3458 - dense_1_loss_4: 4.3455 - dense_1_loss_5: 4.3498 - dense_1_loss_6: 4.3507 - dense_1_loss_7: 4.3511 - dense_1_loss_8: 4.3415 - dense_1_loss_9: 4.3420 - dense_1_loss_10: 4.3430 - dense_1_loss_11: 4.3466 - dense_1_loss_12: 4.3459 - dense_1_loss_13: 4.3470 - dense_1_loss_14: 4.3400 - dense_1_loss_15: 4.3463 - dense_1_loss_16: 4.3444 - dense_1_loss_17: 4.3443 - dense_1_loss_18: 4.3508 - dense_1_loss_19: 4.3420 - dense_1_loss_20: 4.3410 - dense_1_loss_21: 4.3411 - dense_1_loss_22: 4.3422 - dense_1_loss_23: 4.3413 - dense_1_loss_24: 4.3346 - dense_1_loss_25: 4.3438 - dense_1_loss_26: 4.3484 - dense_1_loss_27: 4.3447 - dense_1_loss_28: 4.3428 - dense_1_loss_29: 4.3441 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0000e+00 - dense_1_acc_2: 0.0000e+00 - dense_1_acc_3: 0.0500 - dense_1_acc_4: 0.0833 - dense_1_acc_5: 0.0333 - dense_1_acc_6: 0.0333 - dense_1_acc_7: 0.0167 - dense_1_acc_8: 0.1000 - dense_1_acc_9: 0.0500 - dense_1_acc_10: 0.0833 - dense_1_acc_11: 0.0500 - dense_1_acc_12: 0.0667 - dense_1_acc_13: 0.0667 - dense_1_acc_14: 0.0667 - dense_1_acc_15: 0.0167 - dense_1_acc_16: 0.0500 - dense_1_acc_17: 0.0500 - dense_1_acc_18: 0.0333 - dense_1_acc_19: 0.0833 - dense_1_acc_20: 0.0667 - dense_1_acc_21: 0.1000 - dense_1_acc_22: 0.0667 - dense_1_acc_23: 0.1000 - dense_1_acc_24: 0.1167 - dense_1_acc_25: 0.0833 - dense_1_acc_26: 0.0833 - dense_1_acc_27: 0.0333 - dense_1_acc_28: 0.0667 - dense_1_acc_29: 0.0667 - dense_1_acc_30: 0.0167                                                         \n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s - loss: 123.0003 - dense_1_loss_1: 4.3358 - dense_1_loss_2: 4.3140 - dense_1_loss_3: 4.2873 - dense_1_loss_4: 4.2844 - dense_1_loss_5: 4.2699 - dense_1_loss_6: 4.2774 - dense_1_loss_7: 4.2647 - dense_1_loss_8: 4.2451 - dense_1_loss_9: 4.2463 - dense_1_loss_10: 4.2344 - dense_1_loss_11: 4.2249 - dense_1_loss_12: 4.2625 - dense_1_loss_13: 4.2309 - dense_1_loss_14: 4.2030 - dense_1_loss_15: 4.2255 - dense_1_loss_16: 4.2211 - dense_1_loss_17: 4.2260 - dense_1_loss_18: 4.2610 - dense_1_loss_19: 4.2085 - dense_1_loss_20: 4.2299 - dense_1_loss_21: 4.2145 - dense_1_loss_22: 4.2079 - dense_1_loss_23: 4.2150 - dense_1_loss_24: 4.2238 - dense_1_loss_25: 4.2336 - dense_1_loss_26: 4.1901 - dense_1_loss_27: 4.2119 - dense_1_loss_28: 4.2035 - dense_1_loss_29: 4.2477 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1667 - dense_1_acc_3: 0.3000 - dense_1_acc_4: 0.2000 - dense_1_acc_5: 0.1667 - dense_1_acc_6: 0.1833 - dense_1_acc_7: 0.1667 - dense_1_acc_8: 0.2667 - dense_1_acc_9: 0.2333 - dense_1_acc_10: 0.1833 - dense_1_acc_11: 0.2000 - dense_1_acc_12: 0.0667 - dense_1_acc_13: 0.2167 - dense_1_acc_14: 0.2333 - dense_1_acc_15: 0.1833 - dense_1_acc_16: 0.2000 - dense_1_acc_17: 0.2833 - dense_1_acc_18: 0.1833 - dense_1_acc_19: 0.1667 - dense_1_acc_20: 0.1333 - dense_1_acc_21: 0.1333 - dense_1_acc_22: 0.1667 - dense_1_acc_23: 0.1167 - dense_1_acc_24: 0.1000 - dense_1_acc_25: 0.1667 - dense_1_acc_26: 0.1833 - dense_1_acc_27: 0.0667 - dense_1_acc_28: 0.1833 - dense_1_acc_29: 0.1667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s - loss: 116.9013 - dense_1_loss_1: 4.3152 - dense_1_loss_2: 4.2671 - dense_1_loss_3: 4.2082 - dense_1_loss_4: 4.1914 - dense_1_loss_5: 4.1498 - dense_1_loss_6: 4.1664 - dense_1_loss_7: 4.1185 - dense_1_loss_8: 4.0637 - dense_1_loss_9: 4.0082 - dense_1_loss_10: 3.9411 - dense_1_loss_11: 3.8853 - dense_1_loss_12: 4.1447 - dense_1_loss_13: 3.9836 - dense_1_loss_14: 3.8812 - dense_1_loss_15: 4.0286 - dense_1_loss_16: 3.9549 - dense_1_loss_17: 3.9639 - dense_1_loss_18: 4.1457 - dense_1_loss_19: 3.8898 - dense_1_loss_20: 3.9835 - dense_1_loss_21: 3.9489 - dense_1_loss_22: 3.9039 - dense_1_loss_23: 3.9294 - dense_1_loss_24: 3.9714 - dense_1_loss_25: 4.1350 - dense_1_loss_26: 3.7397 - dense_1_loss_27: 3.9230 - dense_1_loss_28: 3.8530 - dense_1_loss_29: 4.2060 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.0833 - dense_1_acc_3: 0.2500 - dense_1_acc_4: 0.2167 - dense_1_acc_5: 0.2000 - dense_1_acc_6: 0.1500 - dense_1_acc_7: 0.1000 - dense_1_acc_8: 0.2000 - dense_1_acc_9: 0.1333 - dense_1_acc_10: 0.1500 - dense_1_acc_11: 0.0833 - dense_1_acc_12: 0.0500 - dense_1_acc_13: 0.1000 - dense_1_acc_14: 0.1333 - dense_1_acc_15: 0.0833 - dense_1_acc_16: 0.0833 - dense_1_acc_17: 0.1833 - dense_1_acc_18: 0.0667 - dense_1_acc_19: 0.1000 - dense_1_acc_20: 0.0833 - dense_1_acc_21: 0.0667 - dense_1_acc_22: 0.0667 - dense_1_acc_23: 0.1000 - dense_1_acc_24: 0.1000 - dense_1_acc_25: 0.0833 - dense_1_acc_26: 0.1333 - dense_1_acc_27: 0.0500 - dense_1_acc_28: 0.0833 - dense_1_acc_29: 0.0833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s - loss: 113.2190 - dense_1_loss_1: 4.2930 - dense_1_loss_2: 4.2165 - dense_1_loss_3: 4.1126 - dense_1_loss_4: 4.0890 - dense_1_loss_5: 3.9902 - dense_1_loss_6: 4.0242 - dense_1_loss_7: 3.9477 - dense_1_loss_8: 3.7710 - dense_1_loss_9: 3.8056 - dense_1_loss_10: 3.6486 - dense_1_loss_11: 3.6983 - dense_1_loss_12: 4.0632 - dense_1_loss_13: 3.8410 - dense_1_loss_14: 3.7365 - dense_1_loss_15: 3.8137 - dense_1_loss_16: 3.8309 - dense_1_loss_17: 3.9365 - dense_1_loss_18: 3.9791 - dense_1_loss_19: 3.7439 - dense_1_loss_20: 3.9821 - dense_1_loss_21: 3.9568 - dense_1_loss_22: 3.8701 - dense_1_loss_23: 3.8378 - dense_1_loss_24: 3.7818 - dense_1_loss_25: 4.0057 - dense_1_loss_26: 3.6054 - dense_1_loss_27: 3.7516 - dense_1_loss_28: 3.8062 - dense_1_loss_29: 4.0798 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2000 - dense_1_acc_3: 0.3000 - dense_1_acc_4: 0.2000 - dense_1_acc_5: 0.2167 - dense_1_acc_6: 0.1500 - dense_1_acc_7: 0.1000 - dense_1_acc_8: 0.2167 - dense_1_acc_9: 0.1500 - dense_1_acc_10: 0.1500 - dense_1_acc_11: 0.1167 - dense_1_acc_12: 0.1167 - dense_1_acc_13: 0.1333 - dense_1_acc_14: 0.1500 - dense_1_acc_15: 0.0667 - dense_1_acc_16: 0.1333 - dense_1_acc_17: 0.1500 - dense_1_acc_18: 0.0833 - dense_1_acc_19: 0.0833 - dense_1_acc_20: 0.0833 - dense_1_acc_21: 0.0667 - dense_1_acc_22: 0.0833 - dense_1_acc_23: 0.0667 - dense_1_acc_24: 0.0167 - dense_1_acc_25: 0.1333 - dense_1_acc_26: 0.1833 - dense_1_acc_27: 0.0333 - dense_1_acc_28: 0.1333 - dense_1_acc_29: 0.1167 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s - loss: 110.1653 - dense_1_loss_1: 4.2749 - dense_1_loss_2: 4.1732 - dense_1_loss_3: 4.0432 - dense_1_loss_4: 4.0246 - dense_1_loss_5: 3.9033 - dense_1_loss_6: 3.9476 - dense_1_loss_7: 3.8750 - dense_1_loss_8: 3.6670 - dense_1_loss_9: 3.7572 - dense_1_loss_10: 3.5705 - dense_1_loss_11: 3.6402 - dense_1_loss_12: 3.9062 - dense_1_loss_13: 3.7186 - dense_1_loss_14: 3.6642 - dense_1_loss_15: 3.7015 - dense_1_loss_16: 3.6966 - dense_1_loss_17: 3.8237 - dense_1_loss_18: 3.7884 - dense_1_loss_19: 3.5907 - dense_1_loss_20: 3.8376 - dense_1_loss_21: 3.8720 - dense_1_loss_22: 3.7352 - dense_1_loss_23: 3.6418 - dense_1_loss_24: 3.6752 - dense_1_loss_25: 3.8271 - dense_1_loss_26: 3.5771 - dense_1_loss_27: 3.6312 - dense_1_loss_28: 3.6769 - dense_1_loss_29: 3.9246 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.2500 - dense_1_acc_3: 0.3500 - dense_1_acc_4: 0.2167 - dense_1_acc_5: 0.2500 - dense_1_acc_6: 0.1000 - dense_1_acc_7: 0.1667 - dense_1_acc_8: 0.2333 - dense_1_acc_9: 0.1500 - dense_1_acc_10: 0.2167 - dense_1_acc_11: 0.1500 - dense_1_acc_12: 0.1000 - dense_1_acc_13: 0.1333 - dense_1_acc_14: 0.1500 - dense_1_acc_15: 0.2167 - dense_1_acc_16: 0.0833 - dense_1_acc_17: 0.1333 - dense_1_acc_18: 0.1000 - dense_1_acc_19: 0.1833 - dense_1_acc_20: 0.0333 - dense_1_acc_21: 0.0667 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.1333 - dense_1_acc_24: 0.1000 - dense_1_acc_25: 0.0833 - dense_1_acc_26: 0.1167 - dense_1_acc_27: 0.1167 - dense_1_acc_28: 0.1167 - dense_1_acc_29: 0.0667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s - loss: 109.0643 - dense_1_loss_1: 4.2584 - dense_1_loss_2: 4.1359 - dense_1_loss_3: 3.9759 - dense_1_loss_4: 3.9506 - dense_1_loss_5: 3.8275 - dense_1_loss_6: 3.8769 - dense_1_loss_7: 3.8063 - dense_1_loss_8: 3.5652 - dense_1_loss_9: 3.6624 - dense_1_loss_10: 3.4568 - dense_1_loss_11: 3.6395 - dense_1_loss_12: 3.7876 - dense_1_loss_13: 3.6125 - dense_1_loss_14: 3.6453 - dense_1_loss_15: 3.6262 - dense_1_loss_16: 3.7012 - dense_1_loss_17: 3.7672 - dense_1_loss_18: 3.7133 - dense_1_loss_19: 3.5662 - dense_1_loss_20: 3.8625 - dense_1_loss_21: 3.8573 - dense_1_loss_22: 3.7819 - dense_1_loss_23: 3.6750 - dense_1_loss_24: 3.6623 - dense_1_loss_25: 3.8905 - dense_1_loss_26: 3.5017 - dense_1_loss_27: 3.6846 - dense_1_loss_28: 3.8000 - dense_1_loss_29: 3.7736 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0500 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.3333 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.2333 - dense_1_acc_6: 0.1000 - dense_1_acc_7: 0.1500 - dense_1_acc_8: 0.2667 - dense_1_acc_9: 0.1667 - dense_1_acc_10: 0.1667 - dense_1_acc_11: 0.1333 - dense_1_acc_12: 0.1333 - dense_1_acc_13: 0.1500 - dense_1_acc_14: 0.1833 - dense_1_acc_15: 0.2167 - dense_1_acc_16: 0.1000 - dense_1_acc_17: 0.1500 - dense_1_acc_18: 0.1000 - dense_1_acc_19: 0.2000 - dense_1_acc_20: 0.0500 - dense_1_acc_21: 0.0833 - dense_1_acc_22: 0.1667 - dense_1_acc_23: 0.1000 - dense_1_acc_24: 0.1167 - dense_1_acc_25: 0.0667 - dense_1_acc_26: 0.2333 - dense_1_acc_27: 0.1167 - dense_1_acc_28: 0.1667 - dense_1_acc_29: 0.1333 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s - loss: 105.1965 - dense_1_loss_1: 4.2452 - dense_1_loss_2: 4.1041 - dense_1_loss_3: 3.9184 - dense_1_loss_4: 3.8895 - dense_1_loss_5: 3.7492 - dense_1_loss_6: 3.7991 - dense_1_loss_7: 3.7447 - dense_1_loss_8: 3.4587 - dense_1_loss_9: 3.6061 - dense_1_loss_10: 3.4262 - dense_1_loss_11: 3.4992 - dense_1_loss_12: 3.6997 - dense_1_loss_13: 3.4366 - dense_1_loss_14: 3.3839 - dense_1_loss_15: 3.5005 - dense_1_loss_16: 3.5025 - dense_1_loss_17: 3.5230 - dense_1_loss_18: 3.5108 - dense_1_loss_19: 3.3998 - dense_1_loss_20: 3.6436 - dense_1_loss_21: 3.6799 - dense_1_loss_22: 3.5825 - dense_1_loss_23: 3.5781 - dense_1_loss_24: 3.5087 - dense_1_loss_25: 3.6419 - dense_1_loss_26: 3.4095 - dense_1_loss_27: 3.4953 - dense_1_loss_28: 3.5473 - dense_1_loss_29: 3.7126 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0833 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.2667 - dense_1_acc_4: 0.2333 - dense_1_acc_5: 0.2167 - dense_1_acc_6: 0.1000 - dense_1_acc_7: 0.1500 - dense_1_acc_8: 0.2667 - dense_1_acc_9: 0.1000 - dense_1_acc_10: 0.2000 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.1000 - dense_1_acc_13: 0.2000 - dense_1_acc_14: 0.2000 - dense_1_acc_15: 0.1333 - dense_1_acc_16: 0.1333 - dense_1_acc_17: 0.2000 - dense_1_acc_18: 0.1333 - dense_1_acc_19: 0.1500 - dense_1_acc_20: 0.1000 - dense_1_acc_21: 0.0500 - dense_1_acc_22: 0.1333 - dense_1_acc_23: 0.0833 - dense_1_acc_24: 0.0667 - dense_1_acc_25: 0.1167 - dense_1_acc_26: 0.1500 - dense_1_acc_27: 0.0833 - dense_1_acc_28: 0.1833 - dense_1_acc_29: 0.0667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s - loss: 101.8070 - dense_1_loss_1: 4.2328 - dense_1_loss_2: 4.0672 - dense_1_loss_3: 3.8560 - dense_1_loss_4: 3.8113 - dense_1_loss_5: 3.6587 - dense_1_loss_6: 3.7142 - dense_1_loss_7: 3.6499 - dense_1_loss_8: 3.3310 - dense_1_loss_9: 3.4553 - dense_1_loss_10: 3.2891 - dense_1_loss_11: 3.3829 - dense_1_loss_12: 3.5461 - dense_1_loss_13: 3.2827 - dense_1_loss_14: 3.2705 - dense_1_loss_15: 3.3542 - dense_1_loss_16: 3.3516 - dense_1_loss_17: 3.2861 - dense_1_loss_18: 3.4001 - dense_1_loss_19: 3.2641 - dense_1_loss_20: 3.4707 - dense_1_loss_21: 3.5191 - dense_1_loss_22: 3.4306 - dense_1_loss_23: 3.4275 - dense_1_loss_24: 3.4132 - dense_1_loss_25: 3.6018 - dense_1_loss_26: 3.3117 - dense_1_loss_27: 3.3878 - dense_1_loss_28: 3.4906 - dense_1_loss_29: 3.5504 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1833 - dense_1_acc_3: 0.2333 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2000 - dense_1_acc_6: 0.1167 - dense_1_acc_7: 0.1000 - dense_1_acc_8: 0.2167 - dense_1_acc_9: 0.1167 - dense_1_acc_10: 0.1833 - dense_1_acc_11: 0.1833 - dense_1_acc_12: 0.1167 - dense_1_acc_13: 0.1833 - dense_1_acc_14: 0.2167 - dense_1_acc_15: 0.1167 - dense_1_acc_16: 0.1667 - dense_1_acc_17: 0.2500 - dense_1_acc_18: 0.1167 - dense_1_acc_19: 0.2167 - dense_1_acc_20: 0.2000 - dense_1_acc_21: 0.1167 - dense_1_acc_22: 0.1167 - dense_1_acc_23: 0.1833 - dense_1_acc_24: 0.1000 - dense_1_acc_25: 0.1333 - dense_1_acc_26: 0.1833 - dense_1_acc_27: 0.1167 - dense_1_acc_28: 0.1667 - dense_1_acc_29: 0.1500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s - loss: 98.3900 - dense_1_loss_1: 4.2219 - dense_1_loss_2: 4.0279 - dense_1_loss_3: 3.7859 - dense_1_loss_4: 3.7336 - dense_1_loss_5: 3.5633 - dense_1_loss_6: 3.6205 - dense_1_loss_7: 3.5568 - dense_1_loss_8: 3.2179 - dense_1_loss_9: 3.3030 - dense_1_loss_10: 3.1588 - dense_1_loss_11: 3.2910 - dense_1_loss_12: 3.4259 - dense_1_loss_13: 3.1765 - dense_1_loss_14: 3.1676 - dense_1_loss_15: 3.2292 - dense_1_loss_16: 3.2754 - dense_1_loss_17: 3.2200 - dense_1_loss_18: 3.2462 - dense_1_loss_19: 3.1877 - dense_1_loss_20: 3.3653 - dense_1_loss_21: 3.3965 - dense_1_loss_22: 3.2758 - dense_1_loss_23: 3.3334 - dense_1_loss_24: 3.2667 - dense_1_loss_25: 3.4413 - dense_1_loss_26: 3.0414 - dense_1_loss_27: 3.1856 - dense_1_loss_28: 3.3228 - dense_1_loss_29: 3.3519 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1833 - dense_1_acc_3: 0.2333 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.2000 - dense_1_acc_6: 0.1167 - dense_1_acc_7: 0.1167 - dense_1_acc_8: 0.1500 - dense_1_acc_9: 0.2000 - dense_1_acc_10: 0.1833 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.1000 - dense_1_acc_13: 0.1500 - dense_1_acc_14: 0.1667 - dense_1_acc_15: 0.1833 - dense_1_acc_16: 0.1833 - dense_1_acc_17: 0.2333 - dense_1_acc_18: 0.1167 - dense_1_acc_19: 0.2000 - dense_1_acc_20: 0.1833 - dense_1_acc_21: 0.1167 - dense_1_acc_22: 0.1333 - dense_1_acc_23: 0.1500 - dense_1_acc_24: 0.0833 - dense_1_acc_25: 0.1333 - dense_1_acc_26: 0.2333 - dense_1_acc_27: 0.0667 - dense_1_acc_28: 0.1667 - dense_1_acc_29: 0.2000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s - loss: 94.6088 - dense_1_loss_1: 4.2130 - dense_1_loss_2: 3.9915 - dense_1_loss_3: 3.7201 - dense_1_loss_4: 3.6557 - dense_1_loss_5: 3.4567 - dense_1_loss_6: 3.4932 - dense_1_loss_7: 3.4182 - dense_1_loss_8: 3.0835 - dense_1_loss_9: 3.1607 - dense_1_loss_10: 3.0033 - dense_1_loss_11: 3.0647 - dense_1_loss_12: 3.2714 - dense_1_loss_13: 2.9979 - dense_1_loss_14: 2.9286 - dense_1_loss_15: 3.0513 - dense_1_loss_16: 3.0828 - dense_1_loss_17: 3.0352 - dense_1_loss_18: 3.1125 - dense_1_loss_19: 3.0780 - dense_1_loss_20: 3.2093 - dense_1_loss_21: 3.2794 - dense_1_loss_22: 3.1244 - dense_1_loss_23: 3.2121 - dense_1_loss_24: 3.1290 - dense_1_loss_25: 3.3149 - dense_1_loss_26: 2.9949 - dense_1_loss_27: 3.0968 - dense_1_loss_28: 3.1790 - dense_1_loss_29: 3.2504 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1667 - dense_1_acc_3: 0.2500 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2000 - dense_1_acc_6: 0.1000 - dense_1_acc_7: 0.1000 - dense_1_acc_8: 0.2000 - dense_1_acc_9: 0.1833 - dense_1_acc_10: 0.2000 - dense_1_acc_11: 0.2000 - dense_1_acc_12: 0.1333 - dense_1_acc_13: 0.1833 - dense_1_acc_14: 0.2333 - dense_1_acc_15: 0.2167 - dense_1_acc_16: 0.1667 - dense_1_acc_17: 0.3000 - dense_1_acc_18: 0.1333 - dense_1_acc_19: 0.2333 - dense_1_acc_20: 0.1667 - dense_1_acc_21: 0.1333 - dense_1_acc_22: 0.1500 - dense_1_acc_23: 0.1000 - dense_1_acc_24: 0.1167 - dense_1_acc_25: 0.1667 - dense_1_acc_26: 0.2000 - dense_1_acc_27: 0.1167 - dense_1_acc_28: 0.1667 - dense_1_acc_29: 0.2000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 90.3842 - dense_1_loss_1: 4.2039 - dense_1_loss_2: 3.9550 - dense_1_loss_3: 3.6553 - dense_1_loss_4: 3.5675 - dense_1_loss_5: 3.3454 - dense_1_loss_6: 3.3601 - dense_1_loss_7: 3.2881 - dense_1_loss_8: 2.9463 - dense_1_loss_9: 3.0280 - dense_1_loss_10: 2.8461 - dense_1_loss_11: 2.9551 - dense_1_loss_12: 3.1033 - dense_1_loss_13: 2.8405 - dense_1_loss_14: 2.7255 - dense_1_loss_15: 2.9042 - dense_1_loss_16: 2.9018 - dense_1_loss_17: 2.8858 - dense_1_loss_18: 2.9287 - dense_1_loss_19: 2.9341 - dense_1_loss_20: 3.0112 - dense_1_loss_21: 3.0850 - dense_1_loss_22: 2.9944 - dense_1_loss_23: 3.0570 - dense_1_loss_24: 2.9567 - dense_1_loss_25: 3.1083 - dense_1_loss_26: 2.7529 - dense_1_loss_27: 2.9952 - dense_1_loss_28: 2.9709 - dense_1_loss_29: 3.0777 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2167 - dense_1_acc_6: 0.1000 - dense_1_acc_7: 0.1500 - dense_1_acc_8: 0.2333 - dense_1_acc_9: 0.2333 - dense_1_acc_10: 0.2500 - dense_1_acc_11: 0.2000 - dense_1_acc_12: 0.1167 - dense_1_acc_13: 0.2500 - dense_1_acc_14: 0.3667 - dense_1_acc_15: 0.2667 - dense_1_acc_16: 0.2000 - dense_1_acc_17: 0.3333 - dense_1_acc_18: 0.2167 - dense_1_acc_19: 0.2333 - dense_1_acc_20: 0.2833 - dense_1_acc_21: 0.1833 - dense_1_acc_22: 0.1667 - dense_1_acc_23: 0.1667 - dense_1_acc_24: 0.1500 - dense_1_acc_25: 0.2333 - dense_1_acc_26: 0.3167 - dense_1_acc_27: 0.1000 - dense_1_acc_28: 0.2000 - dense_1_acc_29: 0.2167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s - loss: 86.2169 - dense_1_loss_1: 4.1949 - dense_1_loss_2: 3.9151 - dense_1_loss_3: 3.5840 - dense_1_loss_4: 3.4706 - dense_1_loss_5: 3.2210 - dense_1_loss_6: 3.2111 - dense_1_loss_7: 3.1647 - dense_1_loss_8: 2.8245 - dense_1_loss_9: 2.8713 - dense_1_loss_10: 2.6963 - dense_1_loss_11: 2.8729 - dense_1_loss_12: 2.9374 - dense_1_loss_13: 2.6877 - dense_1_loss_14: 2.6201 - dense_1_loss_15: 2.7633 - dense_1_loss_16: 2.7980 - dense_1_loss_17: 2.7488 - dense_1_loss_18: 2.7488 - dense_1_loss_19: 2.7738 - dense_1_loss_20: 2.7851 - dense_1_loss_21: 2.8927 - dense_1_loss_22: 2.8499 - dense_1_loss_23: 2.9101 - dense_1_loss_24: 2.8095 - dense_1_loss_25: 2.9762 - dense_1_loss_26: 2.5321 - dense_1_loss_27: 2.7290 - dense_1_loss_28: 2.7463 - dense_1_loss_29: 2.8818 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1000 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2167 - dense_1_acc_6: 0.1167 - dense_1_acc_7: 0.1333 - dense_1_acc_8: 0.2333 - dense_1_acc_9: 0.2500 - dense_1_acc_10: 0.2833 - dense_1_acc_11: 0.2500 - dense_1_acc_12: 0.1167 - dense_1_acc_13: 0.3167 - dense_1_acc_14: 0.3167 - dense_1_acc_15: 0.3500 - dense_1_acc_16: 0.1667 - dense_1_acc_17: 0.3000 - dense_1_acc_18: 0.2000 - dense_1_acc_19: 0.2333 - dense_1_acc_20: 0.2833 - dense_1_acc_21: 0.1833 - dense_1_acc_22: 0.1667 - dense_1_acc_23: 0.1500 - dense_1_acc_24: 0.2167 - dense_1_acc_25: 0.2333 - dense_1_acc_26: 0.4000 - dense_1_acc_27: 0.2333 - dense_1_acc_28: 0.2833 - dense_1_acc_29: 0.2333 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s - loss: 82.2994 - dense_1_loss_1: 4.1857 - dense_1_loss_2: 3.8755 - dense_1_loss_3: 3.5159 - dense_1_loss_4: 3.3732 - dense_1_loss_5: 3.0948 - dense_1_loss_6: 3.0694 - dense_1_loss_7: 3.0494 - dense_1_loss_8: 2.6969 - dense_1_loss_9: 2.7391 - dense_1_loss_10: 2.5874 - dense_1_loss_11: 2.7378 - dense_1_loss_12: 2.8310 - dense_1_loss_13: 2.6053 - dense_1_loss_14: 2.4679 - dense_1_loss_15: 2.6290 - dense_1_loss_16: 2.6501 - dense_1_loss_17: 2.6170 - dense_1_loss_18: 2.6292 - dense_1_loss_19: 2.6663 - dense_1_loss_20: 2.6330 - dense_1_loss_21: 2.6308 - dense_1_loss_22: 2.6767 - dense_1_loss_23: 2.6956 - dense_1_loss_24: 2.6226 - dense_1_loss_25: 2.8101 - dense_1_loss_26: 2.4523 - dense_1_loss_27: 2.5439 - dense_1_loss_28: 2.5611 - dense_1_loss_29: 2.6524 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1333 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.1833 - dense_1_acc_5: 0.2333 - dense_1_acc_6: 0.1333 - dense_1_acc_7: 0.1500 - dense_1_acc_8: 0.2833 - dense_1_acc_9: 0.2167 - dense_1_acc_10: 0.2500 - dense_1_acc_11: 0.2000 - dense_1_acc_12: 0.1333 - dense_1_acc_13: 0.3167 - dense_1_acc_14: 0.2667 - dense_1_acc_15: 0.2667 - dense_1_acc_16: 0.1667 - dense_1_acc_17: 0.2167 - dense_1_acc_18: 0.1667 - dense_1_acc_19: 0.2000 - dense_1_acc_20: 0.2167 - dense_1_acc_21: 0.2167 - dense_1_acc_22: 0.2333 - dense_1_acc_23: 0.2500 - dense_1_acc_24: 0.2167 - dense_1_acc_25: 0.1833 - dense_1_acc_26: 0.3333 - dense_1_acc_27: 0.2833 - dense_1_acc_28: 0.3333 - dense_1_acc_29: 0.2333 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s - loss: 79.1658 - dense_1_loss_1: 4.1785 - dense_1_loss_2: 3.8337 - dense_1_loss_3: 3.4391 - dense_1_loss_4: 3.2606 - dense_1_loss_5: 2.9574 - dense_1_loss_6: 2.9012 - dense_1_loss_7: 2.9298 - dense_1_loss_8: 2.6019 - dense_1_loss_9: 2.6501 - dense_1_loss_10: 2.5348 - dense_1_loss_11: 2.6221 - dense_1_loss_12: 2.6720 - dense_1_loss_13: 2.4628 - dense_1_loss_14: 2.3399 - dense_1_loss_15: 2.5254 - dense_1_loss_16: 2.5159 - dense_1_loss_17: 2.5256 - dense_1_loss_18: 2.4511 - dense_1_loss_19: 2.5061 - dense_1_loss_20: 2.4840 - dense_1_loss_21: 2.5252 - dense_1_loss_22: 2.4863 - dense_1_loss_23: 2.5792 - dense_1_loss_24: 2.5102 - dense_1_loss_25: 2.6469 - dense_1_loss_26: 2.3630 - dense_1_loss_27: 2.4691 - dense_1_loss_28: 2.5735 - dense_1_loss_29: 2.6202 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2000 - dense_1_acc_4: 0.2000 - dense_1_acc_5: 0.2667 - dense_1_acc_6: 0.1667 - dense_1_acc_7: 0.1667 - dense_1_acc_8: 0.3500 - dense_1_acc_9: 0.2333 - dense_1_acc_10: 0.2667 - dense_1_acc_11: 0.2500 - dense_1_acc_12: 0.2000 - dense_1_acc_13: 0.3833 - dense_1_acc_14: 0.3167 - dense_1_acc_15: 0.3000 - dense_1_acc_16: 0.1667 - dense_1_acc_17: 0.2667 - dense_1_acc_18: 0.1833 - dense_1_acc_19: 0.2667 - dense_1_acc_20: 0.2333 - dense_1_acc_21: 0.2500 - dense_1_acc_22: 0.2500 - dense_1_acc_23: 0.2500 - dense_1_acc_24: 0.3000 - dense_1_acc_25: 0.1667 - dense_1_acc_26: 0.3667 - dense_1_acc_27: 0.3333 - dense_1_acc_28: 0.2167 - dense_1_acc_29: 0.2500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s - loss: 75.8067 - dense_1_loss_1: 4.1703 - dense_1_loss_2: 3.7924 - dense_1_loss_3: 3.3644 - dense_1_loss_4: 3.1536 - dense_1_loss_5: 2.8261 - dense_1_loss_6: 2.7517 - dense_1_loss_7: 2.8028 - dense_1_loss_8: 2.5112 - dense_1_loss_9: 2.5590 - dense_1_loss_10: 2.3787 - dense_1_loss_11: 2.4929 - dense_1_loss_12: 2.4571 - dense_1_loss_13: 2.3270 - dense_1_loss_14: 2.2869 - dense_1_loss_15: 2.4006 - dense_1_loss_16: 2.4114 - dense_1_loss_17: 2.3258 - dense_1_loss_18: 2.3075 - dense_1_loss_19: 2.3961 - dense_1_loss_20: 2.4183 - dense_1_loss_21: 2.4113 - dense_1_loss_22: 2.3589 - dense_1_loss_23: 2.4502 - dense_1_loss_24: 2.3770 - dense_1_loss_25: 2.5626 - dense_1_loss_26: 2.1810 - dense_1_loss_27: 2.4439 - dense_1_loss_28: 2.4513 - dense_1_loss_29: 2.4367 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2167 - dense_1_acc_3: 0.2500 - dense_1_acc_4: 0.2333 - dense_1_acc_5: 0.3000 - dense_1_acc_6: 0.2000 - dense_1_acc_7: 0.1833 - dense_1_acc_8: 0.3500 - dense_1_acc_9: 0.3500 - dense_1_acc_10: 0.3333 - dense_1_acc_11: 0.2833 - dense_1_acc_12: 0.2500 - dense_1_acc_13: 0.3667 - dense_1_acc_14: 0.2667 - dense_1_acc_15: 0.2667 - dense_1_acc_16: 0.2500 - dense_1_acc_17: 0.2833 - dense_1_acc_18: 0.2500 - dense_1_acc_19: 0.2333 - dense_1_acc_20: 0.2333 - dense_1_acc_21: 0.2833 - dense_1_acc_22: 0.3167 - dense_1_acc_23: 0.2500 - dense_1_acc_24: 0.3167 - dense_1_acc_25: 0.1667 - dense_1_acc_26: 0.3667 - dense_1_acc_27: 0.2333 - dense_1_acc_28: 0.2167 - dense_1_acc_29: 0.2500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s - loss: 73.5673 - dense_1_loss_1: 4.1627 - dense_1_loss_2: 3.7538 - dense_1_loss_3: 3.2940 - dense_1_loss_4: 3.0559 - dense_1_loss_5: 2.7149 - dense_1_loss_6: 2.6457 - dense_1_loss_7: 2.7418 - dense_1_loss_8: 2.4559 - dense_1_loss_9: 2.4930 - dense_1_loss_10: 2.3559 - dense_1_loss_11: 2.4740 - dense_1_loss_12: 2.4180 - dense_1_loss_13: 2.2724 - dense_1_loss_14: 2.2464 - dense_1_loss_15: 2.3650 - dense_1_loss_16: 2.3261 - dense_1_loss_17: 2.2554 - dense_1_loss_18: 2.2580 - dense_1_loss_19: 2.2543 - dense_1_loss_20: 2.2900 - dense_1_loss_21: 2.2747 - dense_1_loss_22: 2.2821 - dense_1_loss_23: 2.3625 - dense_1_loss_24: 2.2512 - dense_1_loss_25: 2.4679 - dense_1_loss_26: 2.1606 - dense_1_loss_27: 2.3444 - dense_1_loss_28: 2.3409 - dense_1_loss_29: 2.2497 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2500 - dense_1_acc_3: 0.3167 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.3333 - dense_1_acc_6: 0.2500 - dense_1_acc_7: 0.2000 - dense_1_acc_8: 0.3667 - dense_1_acc_9: 0.3000 - dense_1_acc_10: 0.3333 - dense_1_acc_11: 0.3167 - dense_1_acc_12: 0.2667 - dense_1_acc_13: 0.4167 - dense_1_acc_14: 0.3167 - dense_1_acc_15: 0.3167 - dense_1_acc_16: 0.2833 - dense_1_acc_17: 0.3000 - dense_1_acc_18: 0.2833 - dense_1_acc_19: 0.3667 - dense_1_acc_20: 0.2833 - dense_1_acc_21: 0.2833 - dense_1_acc_22: 0.3333 - dense_1_acc_23: 0.3667 - dense_1_acc_24: 0.3333 - dense_1_acc_25: 0.1833 - dense_1_acc_26: 0.3333 - dense_1_acc_27: 0.3333 - dense_1_acc_28: 0.3000 - dense_1_acc_29: 0.3500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s - loss: 70.4135 - dense_1_loss_1: 4.1558 - dense_1_loss_2: 3.7150 - dense_1_loss_3: 3.2219 - dense_1_loss_4: 2.9637 - dense_1_loss_5: 2.6017 - dense_1_loss_6: 2.5327 - dense_1_loss_7: 2.5977 - dense_1_loss_8: 2.3544 - dense_1_loss_9: 2.4117 - dense_1_loss_10: 2.2392 - dense_1_loss_11: 2.3402 - dense_1_loss_12: 2.2695 - dense_1_loss_13: 2.1510 - dense_1_loss_14: 2.1717 - dense_1_loss_15: 2.2408 - dense_1_loss_16: 2.2163 - dense_1_loss_17: 2.0438 - dense_1_loss_18: 2.1469 - dense_1_loss_19: 2.1869 - dense_1_loss_20: 2.1690 - dense_1_loss_21: 2.1361 - dense_1_loss_22: 2.1647 - dense_1_loss_23: 2.1700 - dense_1_loss_24: 2.2073 - dense_1_loss_25: 2.3425 - dense_1_loss_26: 2.0946 - dense_1_loss_27: 2.2800 - dense_1_loss_28: 2.1878 - dense_1_loss_29: 2.1007 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.3000 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3333 - dense_1_acc_6: 0.2500 - dense_1_acc_7: 0.2667 - dense_1_acc_8: 0.5000 - dense_1_acc_9: 0.3000 - dense_1_acc_10: 0.3667 - dense_1_acc_11: 0.3167 - dense_1_acc_12: 0.3333 - dense_1_acc_13: 0.4500 - dense_1_acc_14: 0.4167 - dense_1_acc_15: 0.3000 - dense_1_acc_16: 0.3167 - dense_1_acc_17: 0.4000 - dense_1_acc_18: 0.2500 - dense_1_acc_19: 0.3667 - dense_1_acc_20: 0.2833 - dense_1_acc_21: 0.3333 - dense_1_acc_22: 0.3333 - dense_1_acc_23: 0.3167 - dense_1_acc_24: 0.2500 - dense_1_acc_25: 0.1500 - dense_1_acc_26: 0.4167 - dense_1_acc_27: 0.3833 - dense_1_acc_28: 0.2500 - dense_1_acc_29: 0.3333 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s - loss: 66.9047 - dense_1_loss_1: 4.1478 - dense_1_loss_2: 3.6774 - dense_1_loss_3: 3.1473 - dense_1_loss_4: 2.8653 - dense_1_loss_5: 2.5118 - dense_1_loss_6: 2.4149 - dense_1_loss_7: 2.4538 - dense_1_loss_8: 2.2208 - dense_1_loss_9: 2.3308 - dense_1_loss_10: 2.1657 - dense_1_loss_11: 2.2008 - dense_1_loss_12: 2.1043 - dense_1_loss_13: 2.0362 - dense_1_loss_14: 2.0086 - dense_1_loss_15: 2.1371 - dense_1_loss_16: 2.0927 - dense_1_loss_17: 1.9084 - dense_1_loss_18: 2.0608 - dense_1_loss_19: 1.9878 - dense_1_loss_20: 2.0545 - dense_1_loss_21: 1.9904 - dense_1_loss_22: 1.9949 - dense_1_loss_23: 2.0442 - dense_1_loss_24: 2.0186 - dense_1_loss_25: 2.1916 - dense_1_loss_26: 1.9168 - dense_1_loss_27: 2.1188 - dense_1_loss_28: 2.0702 - dense_1_loss_29: 2.0326 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.2833 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3500 - dense_1_acc_6: 0.2833 - dense_1_acc_7: 0.2667 - dense_1_acc_8: 0.4667 - dense_1_acc_9: 0.3333 - dense_1_acc_10: 0.4000 - dense_1_acc_11: 0.3667 - dense_1_acc_12: 0.3500 - dense_1_acc_13: 0.4000 - dense_1_acc_14: 0.4500 - dense_1_acc_15: 0.3333 - dense_1_acc_16: 0.3333 - dense_1_acc_17: 0.4500 - dense_1_acc_18: 0.2833 - dense_1_acc_19: 0.4167 - dense_1_acc_20: 0.3500 - dense_1_acc_21: 0.3333 - dense_1_acc_22: 0.4167 - dense_1_acc_23: 0.3667 - dense_1_acc_24: 0.3333 - dense_1_acc_25: 0.2000 - dense_1_acc_26: 0.5333 - dense_1_acc_27: 0.4500 - dense_1_acc_28: 0.3833 - dense_1_acc_29: 0.4000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s - loss: 63.7163 - dense_1_loss_1: 4.1387 - dense_1_loss_2: 3.6378 - dense_1_loss_3: 3.0700 - dense_1_loss_4: 2.7753 - dense_1_loss_5: 2.4064 - dense_1_loss_6: 2.3294 - dense_1_loss_7: 2.3279 - dense_1_loss_8: 2.1255 - dense_1_loss_9: 2.1939 - dense_1_loss_10: 2.0482 - dense_1_loss_11: 2.0987 - dense_1_loss_12: 1.9731 - dense_1_loss_13: 1.8800 - dense_1_loss_14: 1.9089 - dense_1_loss_15: 1.9832 - dense_1_loss_16: 2.0080 - dense_1_loss_17: 1.8208 - dense_1_loss_18: 1.9802 - dense_1_loss_19: 1.8643 - dense_1_loss_20: 1.9105 - dense_1_loss_21: 1.8838 - dense_1_loss_22: 1.8833 - dense_1_loss_23: 1.9205 - dense_1_loss_24: 1.8876 - dense_1_loss_25: 2.0627 - dense_1_loss_26: 1.7902 - dense_1_loss_27: 1.9875 - dense_1_loss_28: 1.8913 - dense_1_loss_29: 1.9283 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.2833 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3667 - dense_1_acc_6: 0.2833 - dense_1_acc_7: 0.3000 - dense_1_acc_8: 0.4667 - dense_1_acc_9: 0.3833 - dense_1_acc_10: 0.4167 - dense_1_acc_11: 0.4167 - dense_1_acc_12: 0.4167 - dense_1_acc_13: 0.4333 - dense_1_acc_14: 0.4833 - dense_1_acc_15: 0.4000 - dense_1_acc_16: 0.3667 - dense_1_acc_17: 0.4833 - dense_1_acc_18: 0.3000 - dense_1_acc_19: 0.4667 - dense_1_acc_20: 0.4167 - dense_1_acc_21: 0.4500 - dense_1_acc_22: 0.4500 - dense_1_acc_23: 0.4500 - dense_1_acc_24: 0.4000 - dense_1_acc_25: 0.3000 - dense_1_acc_26: 0.5000 - dense_1_acc_27: 0.4000 - dense_1_acc_28: 0.4667 - dense_1_acc_29: 0.4167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s - loss: 61.1286 - dense_1_loss_1: 4.1305 - dense_1_loss_2: 3.5954 - dense_1_loss_3: 2.9952 - dense_1_loss_4: 2.6932 - dense_1_loss_5: 2.3041 - dense_1_loss_6: 2.2376 - dense_1_loss_7: 2.2259 - dense_1_loss_8: 2.0368 - dense_1_loss_9: 2.0576 - dense_1_loss_10: 1.9157 - dense_1_loss_11: 2.0386 - dense_1_loss_12: 1.8876 - dense_1_loss_13: 1.7519 - dense_1_loss_14: 1.8170 - dense_1_loss_15: 1.8895 - dense_1_loss_16: 1.9319 - dense_1_loss_17: 1.7052 - dense_1_loss_18: 1.8836 - dense_1_loss_19: 1.7851 - dense_1_loss_20: 1.7599 - dense_1_loss_21: 1.7936 - dense_1_loss_22: 1.7602 - dense_1_loss_23: 1.8657 - dense_1_loss_24: 1.8094 - dense_1_loss_25: 1.9317 - dense_1_loss_26: 1.7804 - dense_1_loss_27: 1.8819 - dense_1_loss_28: 1.8040 - dense_1_loss_29: 1.8593 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.3000 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3667 - dense_1_acc_6: 0.3000 - dense_1_acc_7: 0.3167 - dense_1_acc_8: 0.4667 - dense_1_acc_9: 0.4167 - dense_1_acc_10: 0.4333 - dense_1_acc_11: 0.4167 - dense_1_acc_12: 0.3333 - dense_1_acc_13: 0.5167 - dense_1_acc_14: 0.4667 - dense_1_acc_15: 0.3333 - dense_1_acc_16: 0.3500 - dense_1_acc_17: 0.4167 - dense_1_acc_18: 0.3667 - dense_1_acc_19: 0.4333 - dense_1_acc_20: 0.3833 - dense_1_acc_21: 0.4333 - dense_1_acc_22: 0.5167 - dense_1_acc_23: 0.4500 - dense_1_acc_24: 0.3833 - dense_1_acc_25: 0.3000 - dense_1_acc_26: 0.5500 - dense_1_acc_27: 0.4167 - dense_1_acc_28: 0.4167 - dense_1_acc_29: 0.4333 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 58.7176 - dense_1_loss_1: 4.1226 - dense_1_loss_2: 3.5540 - dense_1_loss_3: 2.9190 - dense_1_loss_4: 2.6080 - dense_1_loss_5: 2.2109 - dense_1_loss_6: 2.1351 - dense_1_loss_7: 2.0997 - dense_1_loss_8: 1.9437 - dense_1_loss_9: 1.9590 - dense_1_loss_10: 1.8365 - dense_1_loss_11: 1.8963 - dense_1_loss_12: 1.7646 - dense_1_loss_13: 1.6733 - dense_1_loss_14: 1.6983 - dense_1_loss_15: 1.8237 - dense_1_loss_16: 1.8461 - dense_1_loss_17: 1.6758 - dense_1_loss_18: 1.7673 - dense_1_loss_19: 1.7180 - dense_1_loss_20: 1.7124 - dense_1_loss_21: 1.7121 - dense_1_loss_22: 1.6376 - dense_1_loss_23: 1.7418 - dense_1_loss_24: 1.7564 - dense_1_loss_25: 1.8380 - dense_1_loss_26: 1.7695 - dense_1_loss_27: 1.7870 - dense_1_loss_28: 1.7235 - dense_1_loss_29: 1.7875 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.3333 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3833 - dense_1_acc_6: 0.3000 - dense_1_acc_7: 0.3500 - dense_1_acc_8: 0.5167 - dense_1_acc_9: 0.4000 - dense_1_acc_10: 0.4500 - dense_1_acc_11: 0.4167 - dense_1_acc_12: 0.4667 - dense_1_acc_13: 0.5333 - dense_1_acc_14: 0.5667 - dense_1_acc_15: 0.4167 - dense_1_acc_16: 0.4000 - dense_1_acc_17: 0.5000 - dense_1_acc_18: 0.4333 - dense_1_acc_19: 0.4667 - dense_1_acc_20: 0.4833 - dense_1_acc_21: 0.4833 - dense_1_acc_22: 0.5833 - dense_1_acc_23: 0.5500 - dense_1_acc_24: 0.4500 - dense_1_acc_25: 0.3833 - dense_1_acc_26: 0.4667 - dense_1_acc_27: 0.4333 - dense_1_acc_28: 0.5000 - dense_1_acc_29: 0.4667 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s - loss: 56.2135 - dense_1_loss_1: 4.1140 - dense_1_loss_2: 3.5089 - dense_1_loss_3: 2.8371 - dense_1_loss_4: 2.5196 - dense_1_loss_5: 2.1280 - dense_1_loss_6: 2.0229 - dense_1_loss_7: 2.0026 - dense_1_loss_8: 1.8323 - dense_1_loss_9: 1.8648 - dense_1_loss_10: 1.6757 - dense_1_loss_11: 1.8023 - dense_1_loss_12: 1.6245 - dense_1_loss_13: 1.5501 - dense_1_loss_14: 1.5692 - dense_1_loss_15: 1.7384 - dense_1_loss_16: 1.6810 - dense_1_loss_17: 1.5713 - dense_1_loss_18: 1.6519 - dense_1_loss_19: 1.5853 - dense_1_loss_20: 1.6462 - dense_1_loss_21: 1.6657 - dense_1_loss_22: 1.5439 - dense_1_loss_23: 1.6994 - dense_1_loss_24: 1.6884 - dense_1_loss_25: 1.7447 - dense_1_loss_26: 1.7090 - dense_1_loss_27: 1.7779 - dense_1_loss_28: 1.7285 - dense_1_loss_29: 1.7300 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.3500 - dense_1_acc_4: 0.2833 - dense_1_acc_5: 0.3667 - dense_1_acc_6: 0.3833 - dense_1_acc_7: 0.4667 - dense_1_acc_8: 0.5667 - dense_1_acc_9: 0.5167 - dense_1_acc_10: 0.4667 - dense_1_acc_11: 0.4333 - dense_1_acc_12: 0.4667 - dense_1_acc_13: 0.5500 - dense_1_acc_14: 0.5500 - dense_1_acc_15: 0.4000 - dense_1_acc_16: 0.4500 - dense_1_acc_17: 0.5833 - dense_1_acc_18: 0.4333 - dense_1_acc_19: 0.5167 - dense_1_acc_20: 0.5000 - dense_1_acc_21: 0.5167 - dense_1_acc_22: 0.6167 - dense_1_acc_23: 0.4833 - dense_1_acc_24: 0.5333 - dense_1_acc_25: 0.4333 - dense_1_acc_26: 0.4833 - dense_1_acc_27: 0.4667 - dense_1_acc_28: 0.4000 - dense_1_acc_29: 0.5167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s - loss: 53.1083 - dense_1_loss_1: 4.1036 - dense_1_loss_2: 3.4635 - dense_1_loss_3: 2.7593 - dense_1_loss_4: 2.4328 - dense_1_loss_5: 2.0341 - dense_1_loss_6: 1.9140 - dense_1_loss_7: 1.8992 - dense_1_loss_8: 1.7360 - dense_1_loss_9: 1.7858 - dense_1_loss_10: 1.6003 - dense_1_loss_11: 1.6865 - dense_1_loss_12: 1.5368 - dense_1_loss_13: 1.4406 - dense_1_loss_14: 1.4816 - dense_1_loss_15: 1.6801 - dense_1_loss_16: 1.5709 - dense_1_loss_17: 1.5260 - dense_1_loss_18: 1.5383 - dense_1_loss_19: 1.4735 - dense_1_loss_20: 1.5029 - dense_1_loss_21: 1.5350 - dense_1_loss_22: 1.4831 - dense_1_loss_23: 1.5136 - dense_1_loss_24: 1.5175 - dense_1_loss_25: 1.6203 - dense_1_loss_26: 1.5650 - dense_1_loss_27: 1.5972 - dense_1_loss_28: 1.5251 - dense_1_loss_29: 1.5857 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3167 - dense_1_acc_3: 0.3667 - dense_1_acc_4: 0.3000 - dense_1_acc_5: 0.4000 - dense_1_acc_6: 0.4667 - dense_1_acc_7: 0.4500 - dense_1_acc_8: 0.6667 - dense_1_acc_9: 0.5333 - dense_1_acc_10: 0.5667 - dense_1_acc_11: 0.4833 - dense_1_acc_12: 0.5500 - dense_1_acc_13: 0.6500 - dense_1_acc_14: 0.6667 - dense_1_acc_15: 0.5000 - dense_1_acc_16: 0.6167 - dense_1_acc_17: 0.6167 - dense_1_acc_18: 0.6167 - dense_1_acc_19: 0.6500 - dense_1_acc_20: 0.6000 - dense_1_acc_21: 0.6000 - dense_1_acc_22: 0.6500 - dense_1_acc_23: 0.6333 - dense_1_acc_24: 0.6167 - dense_1_acc_25: 0.5333 - dense_1_acc_26: 0.6500 - dense_1_acc_27: 0.6333 - dense_1_acc_28: 0.7167 - dense_1_acc_29: 0.6500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s - loss: 51.2644 - dense_1_loss_1: 4.0942 - dense_1_loss_2: 3.4183 - dense_1_loss_3: 2.6821 - dense_1_loss_4: 2.3569 - dense_1_loss_5: 1.9531 - dense_1_loss_6: 1.8352 - dense_1_loss_7: 1.8136 - dense_1_loss_8: 1.6560 - dense_1_loss_9: 1.7054 - dense_1_loss_10: 1.5575 - dense_1_loss_11: 1.6063 - dense_1_loss_12: 1.5073 - dense_1_loss_13: 1.4145 - dense_1_loss_14: 1.4408 - dense_1_loss_15: 1.6111 - dense_1_loss_16: 1.5115 - dense_1_loss_17: 1.5033 - dense_1_loss_18: 1.5048 - dense_1_loss_19: 1.4681 - dense_1_loss_20: 1.4480 - dense_1_loss_21: 1.4529 - dense_1_loss_22: 1.4352 - dense_1_loss_23: 1.4087 - dense_1_loss_24: 1.4659 - dense_1_loss_25: 1.5090 - dense_1_loss_26: 1.4823 - dense_1_loss_27: 1.4804 - dense_1_loss_28: 1.4417 - dense_1_loss_29: 1.5001 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.3667 - dense_1_acc_4: 0.3000 - dense_1_acc_5: 0.4500 - dense_1_acc_6: 0.4333 - dense_1_acc_7: 0.5000 - dense_1_acc_8: 0.6833 - dense_1_acc_9: 0.5833 - dense_1_acc_10: 0.5833 - dense_1_acc_11: 0.5000 - dense_1_acc_12: 0.5333 - dense_1_acc_13: 0.6000 - dense_1_acc_14: 0.6500 - dense_1_acc_15: 0.4333 - dense_1_acc_16: 0.5667 - dense_1_acc_17: 0.5000 - dense_1_acc_18: 0.5167 - dense_1_acc_19: 0.6333 - dense_1_acc_20: 0.6333 - dense_1_acc_21: 0.6167 - dense_1_acc_22: 0.7500 - dense_1_acc_23: 0.6667 - dense_1_acc_24: 0.6000 - dense_1_acc_25: 0.5833 - dense_1_acc_26: 0.6333 - dense_1_acc_27: 0.6167 - dense_1_acc_28: 0.7500 - dense_1_acc_29: 0.6833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s - loss: 48.5817 - dense_1_loss_1: 4.0840 - dense_1_loss_2: 3.3712 - dense_1_loss_3: 2.6023 - dense_1_loss_4: 2.2829 - dense_1_loss_5: 1.8683 - dense_1_loss_6: 1.7445 - dense_1_loss_7: 1.6973 - dense_1_loss_8: 1.5385 - dense_1_loss_9: 1.6104 - dense_1_loss_10: 1.4088 - dense_1_loss_11: 1.4920 - dense_1_loss_12: 1.3747 - dense_1_loss_13: 1.2669 - dense_1_loss_14: 1.2940 - dense_1_loss_15: 1.5210 - dense_1_loss_16: 1.3934 - dense_1_loss_17: 1.3538 - dense_1_loss_18: 1.3813 - dense_1_loss_19: 1.3588 - dense_1_loss_20: 1.3239 - dense_1_loss_21: 1.3996 - dense_1_loss_22: 1.3107 - dense_1_loss_23: 1.4167 - dense_1_loss_24: 1.3852 - dense_1_loss_25: 1.4493 - dense_1_loss_26: 1.3992 - dense_1_loss_27: 1.4179 - dense_1_loss_28: 1.3907 - dense_1_loss_29: 1.4443 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.4000 - dense_1_acc_4: 0.3000 - dense_1_acc_5: 0.4667 - dense_1_acc_6: 0.4667 - dense_1_acc_7: 0.5000 - dense_1_acc_8: 0.6833 - dense_1_acc_9: 0.6500 - dense_1_acc_10: 0.6667 - dense_1_acc_11: 0.5833 - dense_1_acc_12: 0.6667 - dense_1_acc_13: 0.7667 - dense_1_acc_14: 0.7167 - dense_1_acc_15: 0.5167 - dense_1_acc_16: 0.6500 - dense_1_acc_17: 0.6500 - dense_1_acc_18: 0.6500 - dense_1_acc_19: 0.6833 - dense_1_acc_20: 0.6833 - dense_1_acc_21: 0.6833 - dense_1_acc_22: 0.7833 - dense_1_acc_23: 0.6667 - dense_1_acc_24: 0.6833 - dense_1_acc_25: 0.5500 - dense_1_acc_26: 0.7167 - dense_1_acc_27: 0.6833 - dense_1_acc_28: 0.7500 - dense_1_acc_29: 0.6833 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s - loss: 46.2789 - dense_1_loss_1: 4.0751 - dense_1_loss_2: 3.3210 - dense_1_loss_3: 2.5246 - dense_1_loss_4: 2.2017 - dense_1_loss_5: 1.7916 - dense_1_loss_6: 1.6477 - dense_1_loss_7: 1.5891 - dense_1_loss_8: 1.4700 - dense_1_loss_9: 1.5177 - dense_1_loss_10: 1.3057 - dense_1_loss_11: 1.3915 - dense_1_loss_12: 1.2899 - dense_1_loss_13: 1.1999 - dense_1_loss_14: 1.2204 - dense_1_loss_15: 1.3969 - dense_1_loss_16: 1.2874 - dense_1_loss_17: 1.2668 - dense_1_loss_18: 1.2988 - dense_1_loss_19: 1.3029 - dense_1_loss_20: 1.2435 - dense_1_loss_21: 1.3282 - dense_1_loss_22: 1.2301 - dense_1_loss_23: 1.3310 - dense_1_loss_24: 1.3017 - dense_1_loss_25: 1.3492 - dense_1_loss_26: 1.3199 - dense_1_loss_27: 1.3610 - dense_1_loss_28: 1.3285 - dense_1_loss_29: 1.3872 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.3667 - dense_1_acc_4: 0.3000 - dense_1_acc_5: 0.4833 - dense_1_acc_6: 0.4833 - dense_1_acc_7: 0.5833 - dense_1_acc_8: 0.7333 - dense_1_acc_9: 0.6333 - dense_1_acc_10: 0.7167 - dense_1_acc_11: 0.6500 - dense_1_acc_12: 0.7500 - dense_1_acc_13: 0.8167 - dense_1_acc_14: 0.7667 - dense_1_acc_15: 0.6000 - dense_1_acc_16: 0.7833 - dense_1_acc_17: 0.6667 - dense_1_acc_18: 0.6500 - dense_1_acc_19: 0.7000 - dense_1_acc_20: 0.8000 - dense_1_acc_21: 0.6833 - dense_1_acc_22: 0.8333 - dense_1_acc_23: 0.7500 - dense_1_acc_24: 0.7333 - dense_1_acc_25: 0.6333 - dense_1_acc_26: 0.7667 - dense_1_acc_27: 0.7167 - dense_1_acc_28: 0.8167 - dense_1_acc_29: 0.7167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s - loss: 44.1364 - dense_1_loss_1: 4.0656 - dense_1_loss_2: 3.2737 - dense_1_loss_3: 2.4548 - dense_1_loss_4: 2.1153 - dense_1_loss_5: 1.7142 - dense_1_loss_6: 1.5765 - dense_1_loss_7: 1.4903 - dense_1_loss_8: 1.4092 - dense_1_loss_9: 1.4236 - dense_1_loss_10: 1.2626 - dense_1_loss_11: 1.3382 - dense_1_loss_12: 1.2465 - dense_1_loss_13: 1.1417 - dense_1_loss_14: 1.1989 - dense_1_loss_15: 1.2859 - dense_1_loss_16: 1.2174 - dense_1_loss_17: 1.2190 - dense_1_loss_18: 1.2028 - dense_1_loss_19: 1.2248 - dense_1_loss_20: 1.1966 - dense_1_loss_21: 1.2351 - dense_1_loss_22: 1.1801 - dense_1_loss_23: 1.1877 - dense_1_loss_24: 1.2102 - dense_1_loss_25: 1.2622 - dense_1_loss_26: 1.2039 - dense_1_loss_27: 1.2632 - dense_1_loss_28: 1.2141 - dense_1_loss_29: 1.3224 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.3667 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.4833 - dense_1_acc_6: 0.5333 - dense_1_acc_7: 0.6500 - dense_1_acc_8: 0.7667 - dense_1_acc_9: 0.6833 - dense_1_acc_10: 0.7833 - dense_1_acc_11: 0.6667 - dense_1_acc_12: 0.7333 - dense_1_acc_13: 0.8000 - dense_1_acc_14: 0.7167 - dense_1_acc_15: 0.6667 - dense_1_acc_16: 0.8667 - dense_1_acc_17: 0.7333 - dense_1_acc_18: 0.7000 - dense_1_acc_19: 0.7833 - dense_1_acc_20: 0.7833 - dense_1_acc_21: 0.8667 - dense_1_acc_22: 0.8667 - dense_1_acc_23: 0.8167 - dense_1_acc_24: 0.7667 - dense_1_acc_25: 0.7000 - dense_1_acc_26: 0.8000 - dense_1_acc_27: 0.7333 - dense_1_acc_28: 0.8667 - dense_1_acc_29: 0.7167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s - loss: 42.0427 - dense_1_loss_1: 4.0568 - dense_1_loss_2: 3.2225 - dense_1_loss_3: 2.3790 - dense_1_loss_4: 2.0373 - dense_1_loss_5: 1.6407 - dense_1_loss_6: 1.4887 - dense_1_loss_7: 1.4011 - dense_1_loss_8: 1.3174 - dense_1_loss_9: 1.3502 - dense_1_loss_10: 1.1805 - dense_1_loss_11: 1.2689 - dense_1_loss_12: 1.1727 - dense_1_loss_13: 1.0533 - dense_1_loss_14: 1.1335 - dense_1_loss_15: 1.2100 - dense_1_loss_16: 1.1339 - dense_1_loss_17: 1.1535 - dense_1_loss_18: 1.1304 - dense_1_loss_19: 1.1442 - dense_1_loss_20: 1.1280 - dense_1_loss_21: 1.1581 - dense_1_loss_22: 1.1112 - dense_1_loss_23: 1.1279 - dense_1_loss_24: 1.1215 - dense_1_loss_25: 1.2004 - dense_1_loss_26: 1.1425 - dense_1_loss_27: 1.1732 - dense_1_loss_28: 1.1508 - dense_1_loss_29: 1.2545 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.3667 - dense_1_acc_4: 0.3000 - dense_1_acc_5: 0.4833 - dense_1_acc_6: 0.6000 - dense_1_acc_7: 0.7000 - dense_1_acc_8: 0.8333 - dense_1_acc_9: 0.7667 - dense_1_acc_10: 0.7833 - dense_1_acc_11: 0.7500 - dense_1_acc_12: 0.8000 - dense_1_acc_13: 0.9000 - dense_1_acc_14: 0.8167 - dense_1_acc_15: 0.7167 - dense_1_acc_16: 0.9167 - dense_1_acc_17: 0.8000 - dense_1_acc_18: 0.8000 - dense_1_acc_19: 0.8500 - dense_1_acc_20: 0.8500 - dense_1_acc_21: 0.8667 - dense_1_acc_22: 0.8833 - dense_1_acc_23: 0.8333 - dense_1_acc_24: 0.8333 - dense_1_acc_25: 0.7333 - dense_1_acc_26: 0.8000 - dense_1_acc_27: 0.7833 - dense_1_acc_28: 0.8333 - dense_1_acc_29: 0.7167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s - loss: 40.0679 - dense_1_loss_1: 4.0491 - dense_1_loss_2: 3.1759 - dense_1_loss_3: 2.3085 - dense_1_loss_4: 1.9508 - dense_1_loss_5: 1.5649 - dense_1_loss_6: 1.3915 - dense_1_loss_7: 1.3015 - dense_1_loss_8: 1.2338 - dense_1_loss_9: 1.2507 - dense_1_loss_10: 1.0698 - dense_1_loss_11: 1.1719 - dense_1_loss_12: 1.1126 - dense_1_loss_13: 0.9547 - dense_1_loss_14: 1.0240 - dense_1_loss_15: 1.1520 - dense_1_loss_16: 1.0783 - dense_1_loss_17: 1.0713 - dense_1_loss_18: 1.0694 - dense_1_loss_19: 1.0604 - dense_1_loss_20: 1.0764 - dense_1_loss_21: 1.0982 - dense_1_loss_22: 1.0449 - dense_1_loss_23: 1.1362 - dense_1_loss_24: 1.0557 - dense_1_loss_25: 1.1459 - dense_1_loss_26: 1.1152 - dense_1_loss_27: 1.1332 - dense_1_loss_28: 1.0918 - dense_1_loss_29: 1.1791 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.4500 - dense_1_acc_4: 0.3000 - dense_1_acc_5: 0.4667 - dense_1_acc_6: 0.6333 - dense_1_acc_7: 0.7833 - dense_1_acc_8: 0.8167 - dense_1_acc_9: 0.7833 - dense_1_acc_10: 0.8500 - dense_1_acc_11: 0.8167 - dense_1_acc_12: 0.8833 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.9000 - dense_1_acc_15: 0.7500 - dense_1_acc_16: 0.9167 - dense_1_acc_17: 0.8833 - dense_1_acc_18: 0.9000 - dense_1_acc_19: 0.8833 - dense_1_acc_20: 0.8833 - dense_1_acc_21: 0.9000 - dense_1_acc_22: 0.9000 - dense_1_acc_23: 0.8667 - dense_1_acc_24: 0.8500 - dense_1_acc_25: 0.7500 - dense_1_acc_26: 0.8000 - dense_1_acc_27: 0.8333 - dense_1_acc_28: 0.8500 - dense_1_acc_29: 0.7833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s - loss: 38.0503 - dense_1_loss_1: 4.0421 - dense_1_loss_2: 3.1262 - dense_1_loss_3: 2.2375 - dense_1_loss_4: 1.8673 - dense_1_loss_5: 1.4941 - dense_1_loss_6: 1.3096 - dense_1_loss_7: 1.2100 - dense_1_loss_8: 1.1829 - dense_1_loss_9: 1.1552 - dense_1_loss_10: 1.0036 - dense_1_loss_11: 1.0787 - dense_1_loss_12: 1.0513 - dense_1_loss_13: 0.9146 - dense_1_loss_14: 0.9467 - dense_1_loss_15: 1.0560 - dense_1_loss_16: 1.0375 - dense_1_loss_17: 0.9915 - dense_1_loss_18: 1.0063 - dense_1_loss_19: 0.9998 - dense_1_loss_20: 1.0055 - dense_1_loss_21: 1.0129 - dense_1_loss_22: 0.9846 - dense_1_loss_23: 1.0568 - dense_1_loss_24: 0.9951 - dense_1_loss_25: 1.0534 - dense_1_loss_26: 1.0452 - dense_1_loss_27: 1.0745 - dense_1_loss_28: 1.0139 - dense_1_loss_29: 1.0974 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.4500 - dense_1_acc_4: 0.3333 - dense_1_acc_5: 0.4833 - dense_1_acc_6: 0.7167 - dense_1_acc_7: 0.8000 - dense_1_acc_8: 0.8333 - dense_1_acc_9: 0.8500 - dense_1_acc_10: 0.8833 - dense_1_acc_11: 0.8833 - dense_1_acc_12: 0.9167 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.9333 - dense_1_acc_15: 0.8833 - dense_1_acc_16: 0.9500 - dense_1_acc_17: 0.9500 - dense_1_acc_18: 0.9333 - dense_1_acc_19: 0.9000 - dense_1_acc_20: 0.9000 - dense_1_acc_21: 0.9167 - dense_1_acc_22: 0.9167 - dense_1_acc_23: 0.8667 - dense_1_acc_24: 0.9000 - dense_1_acc_25: 0.8333 - dense_1_acc_26: 0.8333 - dense_1_acc_27: 0.8667 - dense_1_acc_28: 0.8833 - dense_1_acc_29: 0.8500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 36.2616 - dense_1_loss_1: 4.0331 - dense_1_loss_2: 3.0817 - dense_1_loss_3: 2.1706 - dense_1_loss_4: 1.7851 - dense_1_loss_5: 1.4297 - dense_1_loss_6: 1.2397 - dense_1_loss_7: 1.1530 - dense_1_loss_8: 1.1256 - dense_1_loss_9: 1.0943 - dense_1_loss_10: 0.9515 - dense_1_loss_11: 1.0280 - dense_1_loss_12: 0.9920 - dense_1_loss_13: 0.8790 - dense_1_loss_14: 0.9116 - dense_1_loss_15: 0.9842 - dense_1_loss_16: 0.9655 - dense_1_loss_17: 0.9472 - dense_1_loss_18: 0.9324 - dense_1_loss_19: 0.9304 - dense_1_loss_20: 0.9461 - dense_1_loss_21: 0.9488 - dense_1_loss_22: 0.9257 - dense_1_loss_23: 0.9475 - dense_1_loss_24: 0.9367 - dense_1_loss_25: 0.9698 - dense_1_loss_26: 0.9712 - dense_1_loss_27: 0.9872 - dense_1_loss_28: 0.9493 - dense_1_loss_29: 1.0450 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.4833 - dense_1_acc_4: 0.3500 - dense_1_acc_5: 0.5500 - dense_1_acc_6: 0.8000 - dense_1_acc_7: 0.8333 - dense_1_acc_8: 0.8500 - dense_1_acc_9: 0.8667 - dense_1_acc_10: 0.9000 - dense_1_acc_11: 0.9167 - dense_1_acc_12: 0.9000 - dense_1_acc_13: 0.9333 - dense_1_acc_14: 0.9333 - dense_1_acc_15: 0.9333 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9500 - dense_1_acc_18: 0.9333 - dense_1_acc_19: 0.9167 - dense_1_acc_20: 0.9333 - dense_1_acc_21: 0.8833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 0.8833 - dense_1_acc_24: 0.9167 - dense_1_acc_25: 0.8667 - dense_1_acc_26: 0.8833 - dense_1_acc_27: 0.9167 - dense_1_acc_28: 0.9333 - dense_1_acc_29: 0.9000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s - loss: 34.4577 - dense_1_loss_1: 4.0255 - dense_1_loss_2: 3.0348 - dense_1_loss_3: 2.1045 - dense_1_loss_4: 1.7145 - dense_1_loss_5: 1.3708 - dense_1_loss_6: 1.1717 - dense_1_loss_7: 1.0831 - dense_1_loss_8: 1.0481 - dense_1_loss_9: 1.0326 - dense_1_loss_10: 0.8921 - dense_1_loss_11: 0.9355 - dense_1_loss_12: 0.9002 - dense_1_loss_13: 0.8210 - dense_1_loss_14: 0.8448 - dense_1_loss_15: 0.9202 - dense_1_loss_16: 0.8872 - dense_1_loss_17: 0.8886 - dense_1_loss_18: 0.8664 - dense_1_loss_19: 0.8608 - dense_1_loss_20: 0.8847 - dense_1_loss_21: 0.8922 - dense_1_loss_22: 0.8752 - dense_1_loss_23: 0.8808 - dense_1_loss_24: 0.8788 - dense_1_loss_25: 0.9130 - dense_1_loss_26: 0.9159 - dense_1_loss_27: 0.9367 - dense_1_loss_28: 0.9016 - dense_1_loss_29: 0.9762 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.4833 - dense_1_acc_4: 0.3833 - dense_1_acc_5: 0.5667 - dense_1_acc_6: 0.8167 - dense_1_acc_7: 0.8333 - dense_1_acc_8: 0.8667 - dense_1_acc_9: 0.8833 - dense_1_acc_10: 0.8667 - dense_1_acc_11: 0.9333 - dense_1_acc_12: 0.9333 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.9000 - dense_1_acc_15: 0.9167 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9167 - dense_1_acc_18: 0.9667 - dense_1_acc_19: 0.9167 - dense_1_acc_20: 0.9333 - dense_1_acc_21: 0.9333 - dense_1_acc_22: 0.9667 - dense_1_acc_23: 0.9667 - dense_1_acc_24: 0.9333 - dense_1_acc_25: 0.8667 - dense_1_acc_26: 0.9000 - dense_1_acc_27: 0.9167 - dense_1_acc_28: 0.9333 - dense_1_acc_29: 0.9167 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s - loss: 32.7671 - dense_1_loss_1: 4.0190 - dense_1_loss_2: 2.9863 - dense_1_loss_3: 2.0403 - dense_1_loss_4: 1.6314 - dense_1_loss_5: 1.3051 - dense_1_loss_6: 1.1024 - dense_1_loss_7: 1.0003 - dense_1_loss_8: 0.9857 - dense_1_loss_9: 0.9573 - dense_1_loss_10: 0.8176 - dense_1_loss_11: 0.8666 - dense_1_loss_12: 0.8407 - dense_1_loss_13: 0.7669 - dense_1_loss_14: 0.7881 - dense_1_loss_15: 0.8376 - dense_1_loss_16: 0.8241 - dense_1_loss_17: 0.8294 - dense_1_loss_18: 0.8195 - dense_1_loss_19: 0.8067 - dense_1_loss_20: 0.8235 - dense_1_loss_21: 0.8427 - dense_1_loss_22: 0.8124 - dense_1_loss_23: 0.8403 - dense_1_loss_24: 0.8355 - dense_1_loss_25: 0.8633 - dense_1_loss_26: 0.8679 - dense_1_loss_27: 0.8859 - dense_1_loss_28: 0.8551 - dense_1_loss_29: 0.9157 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.5333 - dense_1_acc_4: 0.3833 - dense_1_acc_5: 0.5833 - dense_1_acc_6: 0.8500 - dense_1_acc_7: 0.8500 - dense_1_acc_8: 0.8833 - dense_1_acc_9: 0.9000 - dense_1_acc_10: 0.9333 - dense_1_acc_11: 0.9500 - dense_1_acc_12: 0.9500 - dense_1_acc_13: 0.9667 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 0.9500 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 0.9667 - dense_1_acc_19: 0.9333 - dense_1_acc_20: 0.9500 - dense_1_acc_21: 0.9500 - dense_1_acc_22: 0.9833 - dense_1_acc_23: 0.9667 - dense_1_acc_24: 0.9667 - dense_1_acc_25: 0.9167 - dense_1_acc_26: 0.9333 - dense_1_acc_27: 0.9167 - dense_1_acc_28: 0.9333 - dense_1_acc_29: 0.9000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s - loss: 31.1209 - dense_1_loss_1: 4.0118 - dense_1_loss_2: 2.9403 - dense_1_loss_3: 1.9722 - dense_1_loss_4: 1.5373 - dense_1_loss_5: 1.2381 - dense_1_loss_6: 1.0385 - dense_1_loss_7: 0.9275 - dense_1_loss_8: 0.9258 - dense_1_loss_9: 0.8844 - dense_1_loss_10: 0.7527 - dense_1_loss_11: 0.8141 - dense_1_loss_12: 0.7869 - dense_1_loss_13: 0.7081 - dense_1_loss_14: 0.7410 - dense_1_loss_15: 0.7713 - dense_1_loss_16: 0.7896 - dense_1_loss_17: 0.7726 - dense_1_loss_18: 0.7666 - dense_1_loss_19: 0.7743 - dense_1_loss_20: 0.7744 - dense_1_loss_21: 0.7977 - dense_1_loss_22: 0.7401 - dense_1_loss_23: 0.7805 - dense_1_loss_24: 0.7773 - dense_1_loss_25: 0.8217 - dense_1_loss_26: 0.8077 - dense_1_loss_27: 0.8116 - dense_1_loss_28: 0.8022 - dense_1_loss_29: 0.8547 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.5500 - dense_1_acc_4: 0.4500 - dense_1_acc_5: 0.6333 - dense_1_acc_6: 0.8667 - dense_1_acc_7: 0.9333 - dense_1_acc_8: 0.9000 - dense_1_acc_9: 0.9167 - dense_1_acc_10: 0.9667 - dense_1_acc_11: 0.9667 - dense_1_acc_12: 0.9667 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 0.9500 - dense_1_acc_16: 0.9667 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 0.9833 - dense_1_acc_19: 0.9333 - dense_1_acc_20: 0.9667 - dense_1_acc_21: 0.9333 - dense_1_acc_22: 0.9833 - dense_1_acc_23: 0.9500 - dense_1_acc_24: 0.9333 - dense_1_acc_25: 0.9500 - dense_1_acc_26: 0.9500 - dense_1_acc_27: 0.9500 - dense_1_acc_28: 0.9333 - dense_1_acc_29: 0.8833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s - loss: 29.5758 - dense_1_loss_1: 4.0053 - dense_1_loss_2: 2.8917 - dense_1_loss_3: 1.9070 - dense_1_loss_4: 1.4569 - dense_1_loss_5: 1.1832 - dense_1_loss_6: 0.9760 - dense_1_loss_7: 0.8765 - dense_1_loss_8: 0.8604 - dense_1_loss_9: 0.8328 - dense_1_loss_10: 0.7108 - dense_1_loss_11: 0.7691 - dense_1_loss_12: 0.7180 - dense_1_loss_13: 0.6551 - dense_1_loss_14: 0.6826 - dense_1_loss_15: 0.7371 - dense_1_loss_16: 0.7285 - dense_1_loss_17: 0.7343 - dense_1_loss_18: 0.7034 - dense_1_loss_19: 0.7191 - dense_1_loss_20: 0.7286 - dense_1_loss_21: 0.7454 - dense_1_loss_22: 0.6775 - dense_1_loss_23: 0.7145 - dense_1_loss_24: 0.7194 - dense_1_loss_25: 0.7921 - dense_1_loss_26: 0.7404 - dense_1_loss_27: 0.7395 - dense_1_loss_28: 0.7641 - dense_1_loss_29: 0.8067 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.5833 - dense_1_acc_4: 0.5333 - dense_1_acc_5: 0.7000 - dense_1_acc_6: 0.8833 - dense_1_acc_7: 0.9167 - dense_1_acc_8: 0.9000 - dense_1_acc_9: 0.9333 - dense_1_acc_10: 0.9833 - dense_1_acc_11: 0.9833 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 0.9667 - dense_1_acc_16: 0.9833 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 0.9833 - dense_1_acc_19: 0.9500 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9500 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 0.9833 - dense_1_acc_24: 0.9500 - dense_1_acc_25: 0.9500 - dense_1_acc_26: 0.9500 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9333 - dense_1_acc_29: 0.9333 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s - loss: 28.0733 - dense_1_loss_1: 3.9991 - dense_1_loss_2: 2.8453 - dense_1_loss_3: 1.8477 - dense_1_loss_4: 1.3902 - dense_1_loss_5: 1.1217 - dense_1_loss_6: 0.9082 - dense_1_loss_7: 0.8190 - dense_1_loss_8: 0.7943 - dense_1_loss_9: 0.7822 - dense_1_loss_10: 0.6661 - dense_1_loss_11: 0.7050 - dense_1_loss_12: 0.6596 - dense_1_loss_13: 0.6040 - dense_1_loss_14: 0.6355 - dense_1_loss_15: 0.6943 - dense_1_loss_16: 0.6649 - dense_1_loss_17: 0.6924 - dense_1_loss_18: 0.6449 - dense_1_loss_19: 0.6587 - dense_1_loss_20: 0.6817 - dense_1_loss_21: 0.6964 - dense_1_loss_22: 0.6333 - dense_1_loss_23: 0.6622 - dense_1_loss_24: 0.6635 - dense_1_loss_25: 0.7494 - dense_1_loss_26: 0.6832 - dense_1_loss_27: 0.7033 - dense_1_loss_28: 0.7102 - dense_1_loss_29: 0.7570 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.6000 - dense_1_acc_4: 0.5167 - dense_1_acc_5: 0.7000 - dense_1_acc_6: 0.9000 - dense_1_acc_7: 0.9333 - dense_1_acc_8: 0.9167 - dense_1_acc_9: 0.9333 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 0.9667 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9667 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9500 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9500 - dense_1_acc_26: 0.9667 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9333 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s - loss: 26.6627 - dense_1_loss_1: 3.9921 - dense_1_loss_2: 2.7985 - dense_1_loss_3: 1.7862 - dense_1_loss_4: 1.3234 - dense_1_loss_5: 1.0638 - dense_1_loss_6: 0.8517 - dense_1_loss_7: 0.7643 - dense_1_loss_8: 0.7375 - dense_1_loss_9: 0.7242 - dense_1_loss_10: 0.6160 - dense_1_loss_11: 0.6511 - dense_1_loss_12: 0.6190 - dense_1_loss_13: 0.5568 - dense_1_loss_14: 0.5908 - dense_1_loss_15: 0.6390 - dense_1_loss_16: 0.6186 - dense_1_loss_17: 0.6391 - dense_1_loss_18: 0.6032 - dense_1_loss_19: 0.6172 - dense_1_loss_20: 0.6258 - dense_1_loss_21: 0.6500 - dense_1_loss_22: 0.5994 - dense_1_loss_23: 0.6115 - dense_1_loss_24: 0.6200 - dense_1_loss_25: 0.6927 - dense_1_loss_26: 0.6355 - dense_1_loss_27: 0.6582 - dense_1_loss_28: 0.6715 - dense_1_loss_29: 0.7056 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.6000 - dense_1_acc_4: 0.5667 - dense_1_acc_5: 0.7167 - dense_1_acc_6: 0.9167 - dense_1_acc_7: 0.9500 - dense_1_acc_8: 0.9333 - dense_1_acc_9: 0.9333 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 0.9833 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9500 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s - loss: 25.3169 - dense_1_loss_1: 3.9861 - dense_1_loss_2: 2.7516 - dense_1_loss_3: 1.7257 - dense_1_loss_4: 1.2509 - dense_1_loss_5: 1.0022 - dense_1_loss_6: 0.7926 - dense_1_loss_7: 0.7114 - dense_1_loss_8: 0.6895 - dense_1_loss_9: 0.6640 - dense_1_loss_10: 0.5706 - dense_1_loss_11: 0.6000 - dense_1_loss_12: 0.5828 - dense_1_loss_13: 0.5083 - dense_1_loss_14: 0.5461 - dense_1_loss_15: 0.5937 - dense_1_loss_16: 0.5816 - dense_1_loss_17: 0.5912 - dense_1_loss_18: 0.5698 - dense_1_loss_19: 0.5738 - dense_1_loss_20: 0.5842 - dense_1_loss_21: 0.6051 - dense_1_loss_22: 0.5473 - dense_1_loss_23: 0.5726 - dense_1_loss_24: 0.5804 - dense_1_loss_25: 0.6384 - dense_1_loss_26: 0.5972 - dense_1_loss_27: 0.6083 - dense_1_loss_28: 0.6291 - dense_1_loss_29: 0.6623 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.6000 - dense_1_acc_4: 0.6167 - dense_1_acc_5: 0.7500 - dense_1_acc_6: 0.9333 - dense_1_acc_7: 0.9667 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9500 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9667 - dense_1_acc_29: 0.9500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s - loss: 24.0434 - dense_1_loss_1: 3.9808 - dense_1_loss_2: 2.7041 - dense_1_loss_3: 1.6654 - dense_1_loss_4: 1.1814 - dense_1_loss_5: 0.9469 - dense_1_loss_6: 0.7430 - dense_1_loss_7: 0.6666 - dense_1_loss_8: 0.6372 - dense_1_loss_9: 0.6192 - dense_1_loss_10: 0.5282 - dense_1_loss_11: 0.5567 - dense_1_loss_12: 0.5366 - dense_1_loss_13: 0.4678 - dense_1_loss_14: 0.5147 - dense_1_loss_15: 0.5423 - dense_1_loss_16: 0.5372 - dense_1_loss_17: 0.5481 - dense_1_loss_18: 0.5332 - dense_1_loss_19: 0.5326 - dense_1_loss_20: 0.5498 - dense_1_loss_21: 0.5618 - dense_1_loss_22: 0.5155 - dense_1_loss_23: 0.5229 - dense_1_loss_24: 0.5379 - dense_1_loss_25: 0.5909 - dense_1_loss_26: 0.5516 - dense_1_loss_27: 0.5664 - dense_1_loss_28: 0.5797 - dense_1_loss_29: 0.6249 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.6000 - dense_1_acc_4: 0.6833 - dense_1_acc_5: 0.7500 - dense_1_acc_6: 0.9333 - dense_1_acc_7: 0.9667 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 0.9833 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9500 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9667 - dense_1_acc_29: 0.9500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s - loss: 22.8448 - dense_1_loss_1: 3.9747 - dense_1_loss_2: 2.6576 - dense_1_loss_3: 1.6098 - dense_1_loss_4: 1.1105 - dense_1_loss_5: 0.9015 - dense_1_loss_6: 0.6870 - dense_1_loss_7: 0.6278 - dense_1_loss_8: 0.5959 - dense_1_loss_9: 0.5649 - dense_1_loss_10: 0.4893 - dense_1_loss_11: 0.5150 - dense_1_loss_12: 0.4924 - dense_1_loss_13: 0.4294 - dense_1_loss_14: 0.4760 - dense_1_loss_15: 0.5099 - dense_1_loss_16: 0.4922 - dense_1_loss_17: 0.5164 - dense_1_loss_18: 0.4867 - dense_1_loss_19: 0.4910 - dense_1_loss_20: 0.5189 - dense_1_loss_21: 0.5197 - dense_1_loss_22: 0.4731 - dense_1_loss_23: 0.4827 - dense_1_loss_24: 0.5013 - dense_1_loss_25: 0.5535 - dense_1_loss_26: 0.5149 - dense_1_loss_27: 0.5232 - dense_1_loss_28: 0.5450 - dense_1_loss_29: 0.5843 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3500 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.7667 - dense_1_acc_5: 0.7667 - dense_1_acc_6: 0.9333 - dense_1_acc_7: 0.9667 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 0.9833 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9667 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9500 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 21.7114 - dense_1_loss_1: 3.9691 - dense_1_loss_2: 2.6106 - dense_1_loss_3: 1.5551 - dense_1_loss_4: 1.0418 - dense_1_loss_5: 0.8514 - dense_1_loss_6: 0.6471 - dense_1_loss_7: 0.5815 - dense_1_loss_8: 0.5572 - dense_1_loss_9: 0.5257 - dense_1_loss_10: 0.4574 - dense_1_loss_11: 0.4752 - dense_1_loss_12: 0.4587 - dense_1_loss_13: 0.4000 - dense_1_loss_14: 0.4526 - dense_1_loss_15: 0.4620 - dense_1_loss_16: 0.4495 - dense_1_loss_17: 0.4768 - dense_1_loss_18: 0.4522 - dense_1_loss_19: 0.4586 - dense_1_loss_20: 0.4755 - dense_1_loss_21: 0.4810 - dense_1_loss_22: 0.4486 - dense_1_loss_23: 0.4459 - dense_1_loss_24: 0.4583 - dense_1_loss_25: 0.5060 - dense_1_loss_26: 0.4777 - dense_1_loss_27: 0.4947 - dense_1_loss_28: 0.5046 - dense_1_loss_29: 0.5366 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.8667 - dense_1_acc_5: 0.7667 - dense_1_acc_6: 0.9500 - dense_1_acc_7: 0.9667 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9667 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s - loss: 20.6458 - dense_1_loss_1: 3.9633 - dense_1_loss_2: 2.5687 - dense_1_loss_3: 1.5001 - dense_1_loss_4: 0.9801 - dense_1_loss_5: 0.8093 - dense_1_loss_6: 0.6002 - dense_1_loss_7: 0.5394 - dense_1_loss_8: 0.5171 - dense_1_loss_9: 0.4871 - dense_1_loss_10: 0.4225 - dense_1_loss_11: 0.4366 - dense_1_loss_12: 0.4267 - dense_1_loss_13: 0.3687 - dense_1_loss_14: 0.4063 - dense_1_loss_15: 0.4417 - dense_1_loss_16: 0.4166 - dense_1_loss_17: 0.4385 - dense_1_loss_18: 0.4141 - dense_1_loss_19: 0.4278 - dense_1_loss_20: 0.4410 - dense_1_loss_21: 0.4429 - dense_1_loss_22: 0.4111 - dense_1_loss_23: 0.4150 - dense_1_loss_24: 0.4204 - dense_1_loss_25: 0.4741 - dense_1_loss_26: 0.4460 - dense_1_loss_27: 0.4549 - dense_1_loss_28: 0.4722 - dense_1_loss_29: 0.5034 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4000 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.8833 - dense_1_acc_5: 0.8167 - dense_1_acc_6: 0.9500 - dense_1_acc_7: 0.9667 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9667 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s - loss: 19.6575 - dense_1_loss_1: 3.9583 - dense_1_loss_2: 2.5241 - dense_1_loss_3: 1.4490 - dense_1_loss_4: 0.9197 - dense_1_loss_5: 0.7644 - dense_1_loss_6: 0.5611 - dense_1_loss_7: 0.4991 - dense_1_loss_8: 0.4769 - dense_1_loss_9: 0.4540 - dense_1_loss_10: 0.3940 - dense_1_loss_11: 0.4035 - dense_1_loss_12: 0.3980 - dense_1_loss_13: 0.3408 - dense_1_loss_14: 0.3759 - dense_1_loss_15: 0.4095 - dense_1_loss_16: 0.3920 - dense_1_loss_17: 0.4026 - dense_1_loss_18: 0.3833 - dense_1_loss_19: 0.3937 - dense_1_loss_20: 0.4123 - dense_1_loss_21: 0.4116 - dense_1_loss_22: 0.3777 - dense_1_loss_23: 0.3873 - dense_1_loss_24: 0.3930 - dense_1_loss_25: 0.4373 - dense_1_loss_26: 0.4119 - dense_1_loss_27: 0.4222 - dense_1_loss_28: 0.4381 - dense_1_loss_29: 0.4662 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4000 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.9167 - dense_1_acc_5: 0.8167 - dense_1_acc_6: 0.9500 - dense_1_acc_7: 0.9667 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9667 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s - loss: 18.7478 - dense_1_loss_1: 3.9525 - dense_1_loss_2: 2.4820 - dense_1_loss_3: 1.4000 - dense_1_loss_4: 0.8682 - dense_1_loss_5: 0.7254 - dense_1_loss_6: 0.5273 - dense_1_loss_7: 0.4689 - dense_1_loss_8: 0.4406 - dense_1_loss_9: 0.4224 - dense_1_loss_10: 0.3619 - dense_1_loss_11: 0.3795 - dense_1_loss_12: 0.3675 - dense_1_loss_13: 0.3161 - dense_1_loss_14: 0.3542 - dense_1_loss_15: 0.3713 - dense_1_loss_16: 0.3624 - dense_1_loss_17: 0.3709 - dense_1_loss_18: 0.3545 - dense_1_loss_19: 0.3655 - dense_1_loss_20: 0.3835 - dense_1_loss_21: 0.3812 - dense_1_loss_22: 0.3559 - dense_1_loss_23: 0.3539 - dense_1_loss_24: 0.3650 - dense_1_loss_25: 0.4020 - dense_1_loss_26: 0.3816 - dense_1_loss_27: 0.3884 - dense_1_loss_28: 0.4103 - dense_1_loss_29: 0.4352 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4167 - dense_1_acc_3: 0.6667 - dense_1_acc_4: 0.9167 - dense_1_acc_5: 0.8167 - dense_1_acc_6: 0.9500 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 0.9833 - dense_1_acc_25: 0.9667 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s - loss: 17.8831 - dense_1_loss_1: 3.9482 - dense_1_loss_2: 2.4397 - dense_1_loss_3: 1.3514 - dense_1_loss_4: 0.8194 - dense_1_loss_5: 0.6871 - dense_1_loss_6: 0.4894 - dense_1_loss_7: 0.4379 - dense_1_loss_8: 0.4055 - dense_1_loss_9: 0.3904 - dense_1_loss_10: 0.3328 - dense_1_loss_11: 0.3523 - dense_1_loss_12: 0.3409 - dense_1_loss_13: 0.2881 - dense_1_loss_14: 0.3246 - dense_1_loss_15: 0.3458 - dense_1_loss_16: 0.3373 - dense_1_loss_17: 0.3372 - dense_1_loss_18: 0.3311 - dense_1_loss_19: 0.3341 - dense_1_loss_20: 0.3565 - dense_1_loss_21: 0.3576 - dense_1_loss_22: 0.3226 - dense_1_loss_23: 0.3273 - dense_1_loss_24: 0.3366 - dense_1_loss_25: 0.3817 - dense_1_loss_26: 0.3497 - dense_1_loss_27: 0.3536 - dense_1_loss_28: 0.3869 - dense_1_loss_29: 0.4175 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4000 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.9167 - dense_1_acc_5: 0.8167 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s - loss: 17.0831 - dense_1_loss_1: 3.9430 - dense_1_loss_2: 2.3985 - dense_1_loss_3: 1.3061 - dense_1_loss_4: 0.7664 - dense_1_loss_5: 0.6473 - dense_1_loss_6: 0.4580 - dense_1_loss_7: 0.4052 - dense_1_loss_8: 0.3802 - dense_1_loss_9: 0.3626 - dense_1_loss_10: 0.3123 - dense_1_loss_11: 0.3179 - dense_1_loss_12: 0.3165 - dense_1_loss_13: 0.2676 - dense_1_loss_14: 0.3022 - dense_1_loss_15: 0.3192 - dense_1_loss_16: 0.3120 - dense_1_loss_17: 0.3152 - dense_1_loss_18: 0.3083 - dense_1_loss_19: 0.3131 - dense_1_loss_20: 0.3305 - dense_1_loss_21: 0.3322 - dense_1_loss_22: 0.2965 - dense_1_loss_23: 0.3062 - dense_1_loss_24: 0.3113 - dense_1_loss_25: 0.3492 - dense_1_loss_26: 0.3269 - dense_1_loss_27: 0.3402 - dense_1_loss_28: 0.3542 - dense_1_loss_29: 0.3843 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4000 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.9167 - dense_1_acc_5: 0.8333 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s - loss: 16.3389 - dense_1_loss_1: 3.9384 - dense_1_loss_2: 2.3572 - dense_1_loss_3: 1.2630 - dense_1_loss_4: 0.7216 - dense_1_loss_5: 0.6133 - dense_1_loss_6: 0.4262 - dense_1_loss_7: 0.3756 - dense_1_loss_8: 0.3506 - dense_1_loss_9: 0.3311 - dense_1_loss_10: 0.2860 - dense_1_loss_11: 0.2961 - dense_1_loss_12: 0.2874 - dense_1_loss_13: 0.2470 - dense_1_loss_14: 0.2815 - dense_1_loss_15: 0.2987 - dense_1_loss_16: 0.2888 - dense_1_loss_17: 0.2910 - dense_1_loss_18: 0.2849 - dense_1_loss_19: 0.2880 - dense_1_loss_20: 0.3087 - dense_1_loss_21: 0.3077 - dense_1_loss_22: 0.2727 - dense_1_loss_23: 0.2871 - dense_1_loss_24: 0.2894 - dense_1_loss_25: 0.3301 - dense_1_loss_26: 0.3024 - dense_1_loss_27: 0.3066 - dense_1_loss_28: 0.3366 - dense_1_loss_29: 0.3711 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4000 - dense_1_acc_3: 0.7000 - dense_1_acc_4: 0.9167 - dense_1_acc_5: 0.8833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s - loss: 15.6328 - dense_1_loss_1: 3.9341 - dense_1_loss_2: 2.3166 - dense_1_loss_3: 1.2226 - dense_1_loss_4: 0.6785 - dense_1_loss_5: 0.5755 - dense_1_loss_6: 0.4008 - dense_1_loss_7: 0.3470 - dense_1_loss_8: 0.3252 - dense_1_loss_9: 0.3111 - dense_1_loss_10: 0.2639 - dense_1_loss_11: 0.2830 - dense_1_loss_12: 0.2666 - dense_1_loss_13: 0.2291 - dense_1_loss_14: 0.2685 - dense_1_loss_15: 0.2724 - dense_1_loss_16: 0.2652 - dense_1_loss_17: 0.2677 - dense_1_loss_18: 0.2623 - dense_1_loss_19: 0.2676 - dense_1_loss_20: 0.2897 - dense_1_loss_21: 0.2805 - dense_1_loss_22: 0.2574 - dense_1_loss_23: 0.2600 - dense_1_loss_24: 0.2697 - dense_1_loss_25: 0.3023 - dense_1_loss_26: 0.2785 - dense_1_loss_27: 0.2848 - dense_1_loss_28: 0.3089 - dense_1_loss_29: 0.3435 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4167 - dense_1_acc_3: 0.7000 - dense_1_acc_4: 0.9167 - dense_1_acc_5: 0.9333 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s - loss: 15.0025 - dense_1_loss_1: 3.9295 - dense_1_loss_2: 2.2780 - dense_1_loss_3: 1.1803 - dense_1_loss_4: 0.6418 - dense_1_loss_5: 0.5427 - dense_1_loss_6: 0.3778 - dense_1_loss_7: 0.3260 - dense_1_loss_8: 0.3052 - dense_1_loss_9: 0.2904 - dense_1_loss_10: 0.2470 - dense_1_loss_11: 0.2640 - dense_1_loss_12: 0.2520 - dense_1_loss_13: 0.2152 - dense_1_loss_14: 0.2535 - dense_1_loss_15: 0.2517 - dense_1_loss_16: 0.2463 - dense_1_loss_17: 0.2507 - dense_1_loss_18: 0.2411 - dense_1_loss_19: 0.2486 - dense_1_loss_20: 0.2677 - dense_1_loss_21: 0.2595 - dense_1_loss_22: 0.2373 - dense_1_loss_23: 0.2431 - dense_1_loss_24: 0.2495 - dense_1_loss_25: 0.2749 - dense_1_loss_26: 0.2575 - dense_1_loss_27: 0.2692 - dense_1_loss_28: 0.2857 - dense_1_loss_29: 0.3162 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4167 - dense_1_acc_3: 0.7000 - dense_1_acc_4: 0.9167 - dense_1_acc_5: 0.9333 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s - loss: 14.4042 - dense_1_loss_1: 3.9250 - dense_1_loss_2: 2.2396 - dense_1_loss_3: 1.1412 - dense_1_loss_4: 0.6066 - dense_1_loss_5: 0.5157 - dense_1_loss_6: 0.3523 - dense_1_loss_7: 0.3042 - dense_1_loss_8: 0.2846 - dense_1_loss_9: 0.2638 - dense_1_loss_10: 0.2266 - dense_1_loss_11: 0.2385 - dense_1_loss_12: 0.2317 - dense_1_loss_13: 0.1992 - dense_1_loss_14: 0.2253 - dense_1_loss_15: 0.2404 - dense_1_loss_16: 0.2286 - dense_1_loss_17: 0.2328 - dense_1_loss_18: 0.2242 - dense_1_loss_19: 0.2294 - dense_1_loss_20: 0.2490 - dense_1_loss_21: 0.2446 - dense_1_loss_22: 0.2178 - dense_1_loss_23: 0.2302 - dense_1_loss_24: 0.2300 - dense_1_loss_25: 0.2616 - dense_1_loss_26: 0.2402 - dense_1_loss_27: 0.2491 - dense_1_loss_28: 0.2685 - dense_1_loss_29: 0.3034 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4167 - dense_1_acc_3: 0.7000 - dense_1_acc_4: 0.9167 - dense_1_acc_5: 0.9333 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9833 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 13.8578 - dense_1_loss_1: 3.9205 - dense_1_loss_2: 2.2014 - dense_1_loss_3: 1.1058 - dense_1_loss_4: 0.5768 - dense_1_loss_5: 0.4875 - dense_1_loss_6: 0.3331 - dense_1_loss_7: 0.2838 - dense_1_loss_8: 0.2637 - dense_1_loss_9: 0.2491 - dense_1_loss_10: 0.2105 - dense_1_loss_11: 0.2200 - dense_1_loss_12: 0.2161 - dense_1_loss_13: 0.1857 - dense_1_loss_14: 0.2089 - dense_1_loss_15: 0.2203 - dense_1_loss_16: 0.2128 - dense_1_loss_17: 0.2156 - dense_1_loss_18: 0.2096 - dense_1_loss_19: 0.2165 - dense_1_loss_20: 0.2293 - dense_1_loss_21: 0.2278 - dense_1_loss_22: 0.2046 - dense_1_loss_23: 0.2095 - dense_1_loss_24: 0.2127 - dense_1_loss_25: 0.2460 - dense_1_loss_26: 0.2226 - dense_1_loss_27: 0.2306 - dense_1_loss_28: 0.2492 - dense_1_loss_29: 0.2878 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4500 - dense_1_acc_3: 0.7167 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9333 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s - loss: 13.3449 - dense_1_loss_1: 3.9164 - dense_1_loss_2: 2.1655 - dense_1_loss_3: 1.0697 - dense_1_loss_4: 0.5458 - dense_1_loss_5: 0.4581 - dense_1_loss_6: 0.3160 - dense_1_loss_7: 0.2619 - dense_1_loss_8: 0.2484 - dense_1_loss_9: 0.2346 - dense_1_loss_10: 0.1976 - dense_1_loss_11: 0.2044 - dense_1_loss_12: 0.2041 - dense_1_loss_13: 0.1722 - dense_1_loss_14: 0.1989 - dense_1_loss_15: 0.2021 - dense_1_loss_16: 0.1981 - dense_1_loss_17: 0.2003 - dense_1_loss_18: 0.1962 - dense_1_loss_19: 0.2027 - dense_1_loss_20: 0.2129 - dense_1_loss_21: 0.2110 - dense_1_loss_22: 0.1918 - dense_1_loss_23: 0.1925 - dense_1_loss_24: 0.1989 - dense_1_loss_25: 0.2246 - dense_1_loss_26: 0.2071 - dense_1_loss_27: 0.2175 - dense_1_loss_28: 0.2308 - dense_1_loss_29: 0.2650 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4500 - dense_1_acc_3: 0.7167 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s - loss: 12.8820 - dense_1_loss_1: 3.9118 - dense_1_loss_2: 2.1292 - dense_1_loss_3: 1.0366 - dense_1_loss_4: 0.5187 - dense_1_loss_5: 0.4353 - dense_1_loss_6: 0.2965 - dense_1_loss_7: 0.2464 - dense_1_loss_8: 0.2312 - dense_1_loss_9: 0.2177 - dense_1_loss_10: 0.1840 - dense_1_loss_11: 0.1934 - dense_1_loss_12: 0.1897 - dense_1_loss_13: 0.1579 - dense_1_loss_14: 0.1868 - dense_1_loss_15: 0.1896 - dense_1_loss_16: 0.1845 - dense_1_loss_17: 0.1862 - dense_1_loss_18: 0.1830 - dense_1_loss_19: 0.1869 - dense_1_loss_20: 0.1997 - dense_1_loss_21: 0.1957 - dense_1_loss_22: 0.1797 - dense_1_loss_23: 0.1793 - dense_1_loss_24: 0.1872 - dense_1_loss_25: 0.2114 - dense_1_loss_26: 0.1932 - dense_1_loss_27: 0.2013 - dense_1_loss_28: 0.2180 - dense_1_loss_29: 0.2510 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7167 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s - loss: 12.4554 - dense_1_loss_1: 3.9076 - dense_1_loss_2: 2.0946 - dense_1_loss_3: 1.0044 - dense_1_loss_4: 0.4936 - dense_1_loss_5: 0.4127 - dense_1_loss_6: 0.2774 - dense_1_loss_7: 0.2311 - dense_1_loss_8: 0.2157 - dense_1_loss_9: 0.2024 - dense_1_loss_10: 0.1723 - dense_1_loss_11: 0.1805 - dense_1_loss_12: 0.1760 - dense_1_loss_13: 0.1479 - dense_1_loss_14: 0.1750 - dense_1_loss_15: 0.1803 - dense_1_loss_16: 0.1719 - dense_1_loss_17: 0.1743 - dense_1_loss_18: 0.1712 - dense_1_loss_19: 0.1732 - dense_1_loss_20: 0.1889 - dense_1_loss_21: 0.1824 - dense_1_loss_22: 0.1683 - dense_1_loss_23: 0.1664 - dense_1_loss_24: 0.1746 - dense_1_loss_25: 0.1985 - dense_1_loss_26: 0.1804 - dense_1_loss_27: 0.1878 - dense_1_loss_28: 0.2057 - dense_1_loss_29: 0.2402 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7167 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s - loss: 12.0589 - dense_1_loss_1: 3.9035 - dense_1_loss_2: 2.0590 - dense_1_loss_3: 0.9737 - dense_1_loss_4: 0.4691 - dense_1_loss_5: 0.3922 - dense_1_loss_6: 0.2636 - dense_1_loss_7: 0.2175 - dense_1_loss_8: 0.2033 - dense_1_loss_9: 0.1911 - dense_1_loss_10: 0.1629 - dense_1_loss_11: 0.1684 - dense_1_loss_12: 0.1643 - dense_1_loss_13: 0.1402 - dense_1_loss_14: 0.1653 - dense_1_loss_15: 0.1670 - dense_1_loss_16: 0.1613 - dense_1_loss_17: 0.1630 - dense_1_loss_18: 0.1604 - dense_1_loss_19: 0.1624 - dense_1_loss_20: 0.1769 - dense_1_loss_21: 0.1706 - dense_1_loss_22: 0.1560 - dense_1_loss_23: 0.1568 - dense_1_loss_24: 0.1624 - dense_1_loss_25: 0.1858 - dense_1_loss_26: 0.1681 - dense_1_loss_27: 0.1792 - dense_1_loss_28: 0.1905 - dense_1_loss_29: 0.2248 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7500 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s - loss: 11.6895 - dense_1_loss_1: 3.8997 - dense_1_loss_2: 2.0269 - dense_1_loss_3: 0.9444 - dense_1_loss_4: 0.4460 - dense_1_loss_5: 0.3698 - dense_1_loss_6: 0.2490 - dense_1_loss_7: 0.2037 - dense_1_loss_8: 0.1894 - dense_1_loss_9: 0.1800 - dense_1_loss_10: 0.1541 - dense_1_loss_11: 0.1551 - dense_1_loss_12: 0.1549 - dense_1_loss_13: 0.1325 - dense_1_loss_14: 0.1576 - dense_1_loss_15: 0.1542 - dense_1_loss_16: 0.1510 - dense_1_loss_17: 0.1534 - dense_1_loss_18: 0.1517 - dense_1_loss_19: 0.1527 - dense_1_loss_20: 0.1639 - dense_1_loss_21: 0.1601 - dense_1_loss_22: 0.1474 - dense_1_loss_23: 0.1484 - dense_1_loss_24: 0.1526 - dense_1_loss_25: 0.1720 - dense_1_loss_26: 0.1601 - dense_1_loss_27: 0.1711 - dense_1_loss_28: 0.1784 - dense_1_loss_29: 0.2090 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7833 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s - loss: 11.3537 - dense_1_loss_1: 3.8955 - dense_1_loss_2: 1.9939 - dense_1_loss_3: 0.9172 - dense_1_loss_4: 0.4251 - dense_1_loss_5: 0.3523 - dense_1_loss_6: 0.2361 - dense_1_loss_7: 0.1934 - dense_1_loss_8: 0.1787 - dense_1_loss_9: 0.1677 - dense_1_loss_10: 0.1439 - dense_1_loss_11: 0.1469 - dense_1_loss_12: 0.1464 - dense_1_loss_13: 0.1240 - dense_1_loss_14: 0.1460 - dense_1_loss_15: 0.1472 - dense_1_loss_16: 0.1433 - dense_1_loss_17: 0.1429 - dense_1_loss_18: 0.1415 - dense_1_loss_19: 0.1436 - dense_1_loss_20: 0.1549 - dense_1_loss_21: 0.1497 - dense_1_loss_22: 0.1377 - dense_1_loss_23: 0.1389 - dense_1_loss_24: 0.1446 - dense_1_loss_25: 0.1634 - dense_1_loss_26: 0.1515 - dense_1_loss_27: 0.1546 - dense_1_loss_28: 0.1707 - dense_1_loss_29: 0.2020 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7833 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s - loss: 11.0382 - dense_1_loss_1: 3.8915 - dense_1_loss_2: 1.9622 - dense_1_loss_3: 0.8926 - dense_1_loss_4: 0.4036 - dense_1_loss_5: 0.3352 - dense_1_loss_6: 0.2247 - dense_1_loss_7: 0.1827 - dense_1_loss_8: 0.1686 - dense_1_loss_9: 0.1582 - dense_1_loss_10: 0.1345 - dense_1_loss_11: 0.1389 - dense_1_loss_12: 0.1380 - dense_1_loss_13: 0.1168 - dense_1_loss_14: 0.1363 - dense_1_loss_15: 0.1395 - dense_1_loss_16: 0.1352 - dense_1_loss_17: 0.1342 - dense_1_loss_18: 0.1335 - dense_1_loss_19: 0.1353 - dense_1_loss_20: 0.1463 - dense_1_loss_21: 0.1405 - dense_1_loss_22: 0.1289 - dense_1_loss_23: 0.1312 - dense_1_loss_24: 0.1356 - dense_1_loss_25: 0.1541 - dense_1_loss_26: 0.1414 - dense_1_loss_27: 0.1444 - dense_1_loss_28: 0.1617 - dense_1_loss_29: 0.1925 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4667 - dense_1_acc_3: 0.7833 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s - loss: 10.7376 - dense_1_loss_1: 3.8882 - dense_1_loss_2: 1.9330 - dense_1_loss_3: 0.8659 - dense_1_loss_4: 0.3851 - dense_1_loss_5: 0.3161 - dense_1_loss_6: 0.2155 - dense_1_loss_7: 0.1724 - dense_1_loss_8: 0.1587 - dense_1_loss_9: 0.1516 - dense_1_loss_10: 0.1270 - dense_1_loss_11: 0.1306 - dense_1_loss_12: 0.1320 - dense_1_loss_13: 0.1110 - dense_1_loss_14: 0.1289 - dense_1_loss_15: 0.1308 - dense_1_loss_16: 0.1278 - dense_1_loss_17: 0.1274 - dense_1_loss_18: 0.1262 - dense_1_loss_19: 0.1276 - dense_1_loss_20: 0.1382 - dense_1_loss_21: 0.1319 - dense_1_loss_22: 0.1206 - dense_1_loss_23: 0.1233 - dense_1_loss_24: 0.1278 - dense_1_loss_25: 0.1423 - dense_1_loss_26: 0.1319 - dense_1_loss_27: 0.1392 - dense_1_loss_28: 0.1498 - dense_1_loss_29: 0.1770 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8167 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s - loss: 10.4623 - dense_1_loss_1: 3.8842 - dense_1_loss_2: 1.9035 - dense_1_loss_3: 0.8428 - dense_1_loss_4: 0.3681 - dense_1_loss_5: 0.2989 - dense_1_loss_6: 0.2051 - dense_1_loss_7: 0.1635 - dense_1_loss_8: 0.1497 - dense_1_loss_9: 0.1419 - dense_1_loss_10: 0.1192 - dense_1_loss_11: 0.1238 - dense_1_loss_12: 0.1246 - dense_1_loss_13: 0.1042 - dense_1_loss_14: 0.1212 - dense_1_loss_15: 0.1242 - dense_1_loss_16: 0.1195 - dense_1_loss_17: 0.1206 - dense_1_loss_18: 0.1192 - dense_1_loss_19: 0.1203 - dense_1_loss_20: 0.1296 - dense_1_loss_21: 0.1246 - dense_1_loss_22: 0.1155 - dense_1_loss_23: 0.1156 - dense_1_loss_24: 0.1201 - dense_1_loss_25: 0.1351 - dense_1_loss_26: 0.1244 - dense_1_loss_27: 0.1339 - dense_1_loss_28: 0.1400 - dense_1_loss_29: 0.1688 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 10.2090 - dense_1_loss_1: 3.8803 - dense_1_loss_2: 1.8758 - dense_1_loss_3: 0.8216 - dense_1_loss_4: 0.3529 - dense_1_loss_5: 0.2853 - dense_1_loss_6: 0.1931 - dense_1_loss_7: 0.1564 - dense_1_loss_8: 0.1415 - dense_1_loss_9: 0.1329 - dense_1_loss_10: 0.1124 - dense_1_loss_11: 0.1171 - dense_1_loss_12: 0.1166 - dense_1_loss_13: 0.0983 - dense_1_loss_14: 0.1138 - dense_1_loss_15: 0.1195 - dense_1_loss_16: 0.1123 - dense_1_loss_17: 0.1139 - dense_1_loss_18: 0.1129 - dense_1_loss_19: 0.1131 - dense_1_loss_20: 0.1213 - dense_1_loss_21: 0.1181 - dense_1_loss_22: 0.1106 - dense_1_loss_23: 0.1091 - dense_1_loss_24: 0.1138 - dense_1_loss_25: 0.1299 - dense_1_loss_26: 0.1175 - dense_1_loss_27: 0.1248 - dense_1_loss_28: 0.1335 - dense_1_loss_29: 0.1607 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s - loss: 9.9770 - dense_1_loss_1: 3.8764 - dense_1_loss_2: 1.8479 - dense_1_loss_3: 0.8007 - dense_1_loss_4: 0.3386 - dense_1_loss_5: 0.2709 - dense_1_loss_6: 0.1843 - dense_1_loss_7: 0.1483 - dense_1_loss_8: 0.1339 - dense_1_loss_9: 0.1255 - dense_1_loss_10: 0.1066 - dense_1_loss_11: 0.1115 - dense_1_loss_12: 0.1099 - dense_1_loss_13: 0.0935 - dense_1_loss_14: 0.1081 - dense_1_loss_15: 0.1143 - dense_1_loss_16: 0.1060 - dense_1_loss_17: 0.1084 - dense_1_loss_18: 0.1074 - dense_1_loss_19: 0.1071 - dense_1_loss_20: 0.1144 - dense_1_loss_21: 0.1125 - dense_1_loss_22: 0.1050 - dense_1_loss_23: 0.1042 - dense_1_loss_24: 0.1073 - dense_1_loss_25: 0.1235 - dense_1_loss_26: 0.1119 - dense_1_loss_27: 0.1184 - dense_1_loss_28: 0.1269 - dense_1_loss_29: 0.1534 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00      \n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s - loss: 9.7496 - dense_1_loss_1: 3.8730 - dense_1_loss_2: 1.8214 - dense_1_loss_3: 0.7801 - dense_1_loss_4: 0.3221 - dense_1_loss_5: 0.2560 - dense_1_loss_6: 0.1777 - dense_1_loss_7: 0.1411 - dense_1_loss_8: 0.1271 - dense_1_loss_9: 0.1198 - dense_1_loss_10: 0.1006 - dense_1_loss_11: 0.1061 - dense_1_loss_12: 0.1043 - dense_1_loss_13: 0.0886 - dense_1_loss_14: 0.1036 - dense_1_loss_15: 0.1070 - dense_1_loss_16: 0.1008 - dense_1_loss_17: 0.1031 - dense_1_loss_18: 0.1016 - dense_1_loss_19: 0.1021 - dense_1_loss_20: 0.1090 - dense_1_loss_21: 0.1064 - dense_1_loss_22: 0.0994 - dense_1_loss_23: 0.0987 - dense_1_loss_24: 0.1010 - dense_1_loss_25: 0.1158 - dense_1_loss_26: 0.1065 - dense_1_loss_27: 0.1136 - dense_1_loss_28: 0.1186 - dense_1_loss_29: 0.1446 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s - loss: 9.5417 - dense_1_loss_1: 3.8691 - dense_1_loss_2: 1.7962 - dense_1_loss_3: 0.7599 - dense_1_loss_4: 0.3085 - dense_1_loss_5: 0.2420 - dense_1_loss_6: 0.1705 - dense_1_loss_7: 0.1343 - dense_1_loss_8: 0.1209 - dense_1_loss_9: 0.1139 - dense_1_loss_10: 0.0960 - dense_1_loss_11: 0.1008 - dense_1_loss_12: 0.0994 - dense_1_loss_13: 0.0843 - dense_1_loss_14: 0.0995 - dense_1_loss_15: 0.1010 - dense_1_loss_16: 0.0962 - dense_1_loss_17: 0.0980 - dense_1_loss_18: 0.0969 - dense_1_loss_19: 0.0967 - dense_1_loss_20: 0.1034 - dense_1_loss_21: 0.1010 - dense_1_loss_22: 0.0943 - dense_1_loss_23: 0.0939 - dense_1_loss_24: 0.0966 - dense_1_loss_25: 0.1090 - dense_1_loss_26: 0.1017 - dense_1_loss_27: 0.1082 - dense_1_loss_28: 0.1127 - dense_1_loss_29: 0.1366 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9667 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s - loss: 9.3474 - dense_1_loss_1: 3.8658 - dense_1_loss_2: 1.7705 - dense_1_loss_3: 0.7413 - dense_1_loss_4: 0.2964 - dense_1_loss_5: 0.2309 - dense_1_loss_6: 0.1630 - dense_1_loss_7: 0.1286 - dense_1_loss_8: 0.1151 - dense_1_loss_9: 0.1083 - dense_1_loss_10: 0.0913 - dense_1_loss_11: 0.0960 - dense_1_loss_12: 0.0949 - dense_1_loss_13: 0.0802 - dense_1_loss_14: 0.0949 - dense_1_loss_15: 0.0958 - dense_1_loss_16: 0.0918 - dense_1_loss_17: 0.0928 - dense_1_loss_18: 0.0924 - dense_1_loss_19: 0.0922 - dense_1_loss_20: 0.0983 - dense_1_loss_21: 0.0960 - dense_1_loss_22: 0.0896 - dense_1_loss_23: 0.0887 - dense_1_loss_24: 0.0921 - dense_1_loss_25: 0.1042 - dense_1_loss_26: 0.0964 - dense_1_loss_27: 0.1015 - dense_1_loss_28: 0.1077 - dense_1_loss_29: 0.1306 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s - loss: 9.1664 - dense_1_loss_1: 3.8622 - dense_1_loss_2: 1.7467 - dense_1_loss_3: 0.7231 - dense_1_loss_4: 0.2851 - dense_1_loss_5: 0.2201 - dense_1_loss_6: 0.1557 - dense_1_loss_7: 0.1232 - dense_1_loss_8: 0.1095 - dense_1_loss_9: 0.1027 - dense_1_loss_10: 0.0868 - dense_1_loss_11: 0.0912 - dense_1_loss_12: 0.0901 - dense_1_loss_13: 0.0770 - dense_1_loss_14: 0.0899 - dense_1_loss_15: 0.0920 - dense_1_loss_16: 0.0877 - dense_1_loss_17: 0.0880 - dense_1_loss_18: 0.0884 - dense_1_loss_19: 0.0879 - dense_1_loss_20: 0.0938 - dense_1_loss_21: 0.0916 - dense_1_loss_22: 0.0858 - dense_1_loss_23: 0.0841 - dense_1_loss_24: 0.0876 - dense_1_loss_25: 0.1005 - dense_1_loss_26: 0.0909 - dense_1_loss_27: 0.0959 - dense_1_loss_28: 0.1031 - dense_1_loss_29: 0.1257 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8500 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s - loss: 8.9965 - dense_1_loss_1: 3.8586 - dense_1_loss_2: 1.7229 - dense_1_loss_3: 0.7066 - dense_1_loss_4: 0.2739 - dense_1_loss_5: 0.2108 - dense_1_loss_6: 0.1501 - dense_1_loss_7: 0.1185 - dense_1_loss_8: 0.1045 - dense_1_loss_9: 0.0987 - dense_1_loss_10: 0.0832 - dense_1_loss_11: 0.0869 - dense_1_loss_12: 0.0863 - dense_1_loss_13: 0.0740 - dense_1_loss_14: 0.0860 - dense_1_loss_15: 0.0875 - dense_1_loss_16: 0.0837 - dense_1_loss_17: 0.0840 - dense_1_loss_18: 0.0842 - dense_1_loss_19: 0.0837 - dense_1_loss_20: 0.0895 - dense_1_loss_21: 0.0869 - dense_1_loss_22: 0.0816 - dense_1_loss_23: 0.0803 - dense_1_loss_24: 0.0837 - dense_1_loss_25: 0.0953 - dense_1_loss_26: 0.0867 - dense_1_loss_27: 0.0922 - dense_1_loss_28: 0.0978 - dense_1_loss_29: 0.1184 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4833 - dense_1_acc_3: 0.8500 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s - loss: 8.8395 - dense_1_loss_1: 3.8552 - dense_1_loss_2: 1.7000 - dense_1_loss_3: 0.6898 - dense_1_loss_4: 0.2639 - dense_1_loss_5: 0.2010 - dense_1_loss_6: 0.1447 - dense_1_loss_7: 0.1137 - dense_1_loss_8: 0.0991 - dense_1_loss_9: 0.0953 - dense_1_loss_10: 0.0797 - dense_1_loss_11: 0.0835 - dense_1_loss_12: 0.0829 - dense_1_loss_13: 0.0707 - dense_1_loss_14: 0.0830 - dense_1_loss_15: 0.0830 - dense_1_loss_16: 0.0798 - dense_1_loss_17: 0.0806 - dense_1_loss_18: 0.0803 - dense_1_loss_19: 0.0802 - dense_1_loss_20: 0.0859 - dense_1_loss_21: 0.0830 - dense_1_loss_22: 0.0782 - dense_1_loss_23: 0.0769 - dense_1_loss_24: 0.0802 - dense_1_loss_25: 0.0905 - dense_1_loss_26: 0.0830 - dense_1_loss_27: 0.0897 - dense_1_loss_28: 0.0930 - dense_1_loss_29: 0.1128 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5167 - dense_1_acc_3: 0.8500 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s - loss: 8.6883 - dense_1_loss_1: 3.8519 - dense_1_loss_2: 1.6784 - dense_1_loss_3: 0.6748 - dense_1_loss_4: 0.2538 - dense_1_loss_5: 0.1922 - dense_1_loss_6: 0.1385 - dense_1_loss_7: 0.1090 - dense_1_loss_8: 0.0943 - dense_1_loss_9: 0.0911 - dense_1_loss_10: 0.0762 - dense_1_loss_11: 0.0799 - dense_1_loss_12: 0.0791 - dense_1_loss_13: 0.0676 - dense_1_loss_14: 0.0792 - dense_1_loss_15: 0.0797 - dense_1_loss_16: 0.0764 - dense_1_loss_17: 0.0773 - dense_1_loss_18: 0.0768 - dense_1_loss_19: 0.0761 - dense_1_loss_20: 0.0822 - dense_1_loss_21: 0.0797 - dense_1_loss_22: 0.0750 - dense_1_loss_23: 0.0741 - dense_1_loss_24: 0.0771 - dense_1_loss_25: 0.0862 - dense_1_loss_26: 0.0794 - dense_1_loss_27: 0.0856 - dense_1_loss_28: 0.0897 - dense_1_loss_29: 0.1070 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5333 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s - loss: 8.5458 - dense_1_loss_1: 3.8485 - dense_1_loss_2: 1.6560 - dense_1_loss_3: 0.6593 - dense_1_loss_4: 0.2447 - dense_1_loss_5: 0.1843 - dense_1_loss_6: 0.1327 - dense_1_loss_7: 0.1046 - dense_1_loss_8: 0.0905 - dense_1_loss_9: 0.0868 - dense_1_loss_10: 0.0731 - dense_1_loss_11: 0.0769 - dense_1_loss_12: 0.0760 - dense_1_loss_13: 0.0645 - dense_1_loss_14: 0.0759 - dense_1_loss_15: 0.0767 - dense_1_loss_16: 0.0730 - dense_1_loss_17: 0.0742 - dense_1_loss_18: 0.0736 - dense_1_loss_19: 0.0729 - dense_1_loss_20: 0.0785 - dense_1_loss_21: 0.0762 - dense_1_loss_22: 0.0723 - dense_1_loss_23: 0.0706 - dense_1_loss_24: 0.0739 - dense_1_loss_25: 0.0828 - dense_1_loss_26: 0.0763 - dense_1_loss_27: 0.0815 - dense_1_loss_28: 0.0865 - dense_1_loss_29: 0.1029 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5833 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 8.4130 - dense_1_loss_1: 3.8452 - dense_1_loss_2: 1.6359 - dense_1_loss_3: 0.6450 - dense_1_loss_4: 0.2353 - dense_1_loss_5: 0.1773 - dense_1_loss_6: 0.1276 - dense_1_loss_7: 0.1007 - dense_1_loss_8: 0.0872 - dense_1_loss_9: 0.0833 - dense_1_loss_10: 0.0703 - dense_1_loss_11: 0.0739 - dense_1_loss_12: 0.0730 - dense_1_loss_13: 0.0620 - dense_1_loss_14: 0.0726 - dense_1_loss_15: 0.0740 - dense_1_loss_16: 0.0703 - dense_1_loss_17: 0.0711 - dense_1_loss_18: 0.0709 - dense_1_loss_19: 0.0703 - dense_1_loss_20: 0.0752 - dense_1_loss_21: 0.0731 - dense_1_loss_22: 0.0694 - dense_1_loss_23: 0.0674 - dense_1_loss_24: 0.0706 - dense_1_loss_25: 0.0801 - dense_1_loss_26: 0.0725 - dense_1_loss_27: 0.0777 - dense_1_loss_28: 0.0831 - dense_1_loss_29: 0.0982 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5833 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s - loss: 8.2852 - dense_1_loss_1: 3.8423 - dense_1_loss_2: 1.6147 - dense_1_loss_3: 0.6305 - dense_1_loss_4: 0.2277 - dense_1_loss_5: 0.1707 - dense_1_loss_6: 0.1234 - dense_1_loss_7: 0.0970 - dense_1_loss_8: 0.0837 - dense_1_loss_9: 0.0804 - dense_1_loss_10: 0.0676 - dense_1_loss_11: 0.0708 - dense_1_loss_12: 0.0700 - dense_1_loss_13: 0.0599 - dense_1_loss_14: 0.0698 - dense_1_loss_15: 0.0708 - dense_1_loss_16: 0.0677 - dense_1_loss_17: 0.0682 - dense_1_loss_18: 0.0681 - dense_1_loss_19: 0.0674 - dense_1_loss_20: 0.0724 - dense_1_loss_21: 0.0700 - dense_1_loss_22: 0.0666 - dense_1_loss_23: 0.0647 - dense_1_loss_24: 0.0679 - dense_1_loss_25: 0.0765 - dense_1_loss_26: 0.0696 - dense_1_loss_27: 0.0749 - dense_1_loss_28: 0.0794 - dense_1_loss_29: 0.0924 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s - loss: 8.1661 - dense_1_loss_1: 3.8387 - dense_1_loss_2: 1.5956 - dense_1_loss_3: 0.6178 - dense_1_loss_4: 0.2193 - dense_1_loss_5: 0.1647 - dense_1_loss_6: 0.1193 - dense_1_loss_7: 0.0939 - dense_1_loss_8: 0.0805 - dense_1_loss_9: 0.0775 - dense_1_loss_10: 0.0651 - dense_1_loss_11: 0.0680 - dense_1_loss_12: 0.0672 - dense_1_loss_13: 0.0575 - dense_1_loss_14: 0.0672 - dense_1_loss_15: 0.0677 - dense_1_loss_16: 0.0651 - dense_1_loss_17: 0.0659 - dense_1_loss_18: 0.0652 - dense_1_loss_19: 0.0644 - dense_1_loss_20: 0.0696 - dense_1_loss_21: 0.0674 - dense_1_loss_22: 0.0637 - dense_1_loss_23: 0.0626 - dense_1_loss_24: 0.0653 - dense_1_loss_25: 0.0733 - dense_1_loss_26: 0.0670 - dense_1_loss_27: 0.0724 - dense_1_loss_28: 0.0761 - dense_1_loss_29: 0.0881 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s - loss: 8.0508 - dense_1_loss_1: 3.8356 - dense_1_loss_2: 1.5766 - dense_1_loss_3: 0.6044 - dense_1_loss_4: 0.2109 - dense_1_loss_5: 0.1588 - dense_1_loss_6: 0.1143 - dense_1_loss_7: 0.0903 - dense_1_loss_8: 0.0772 - dense_1_loss_9: 0.0744 - dense_1_loss_10: 0.0625 - dense_1_loss_11: 0.0656 - dense_1_loss_12: 0.0645 - dense_1_loss_13: 0.0554 - dense_1_loss_14: 0.0645 - dense_1_loss_15: 0.0652 - dense_1_loss_16: 0.0627 - dense_1_loss_17: 0.0636 - dense_1_loss_18: 0.0626 - dense_1_loss_19: 0.0617 - dense_1_loss_20: 0.0670 - dense_1_loss_21: 0.0650 - dense_1_loss_22: 0.0613 - dense_1_loss_23: 0.0607 - dense_1_loss_24: 0.0629 - dense_1_loss_25: 0.0708 - dense_1_loss_26: 0.0649 - dense_1_loss_27: 0.0695 - dense_1_loss_28: 0.0733 - dense_1_loss_29: 0.0847 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s - loss: 7.9455 - dense_1_loss_1: 3.8327 - dense_1_loss_2: 1.5577 - dense_1_loss_3: 0.5917 - dense_1_loss_4: 0.2046 - dense_1_loss_5: 0.1532 - dense_1_loss_6: 0.1101 - dense_1_loss_7: 0.0873 - dense_1_loss_8: 0.0745 - dense_1_loss_9: 0.0716 - dense_1_loss_10: 0.0604 - dense_1_loss_11: 0.0632 - dense_1_loss_12: 0.0622 - dense_1_loss_13: 0.0535 - dense_1_loss_14: 0.0621 - dense_1_loss_15: 0.0631 - dense_1_loss_16: 0.0604 - dense_1_loss_17: 0.0612 - dense_1_loss_18: 0.0605 - dense_1_loss_19: 0.0596 - dense_1_loss_20: 0.0644 - dense_1_loss_21: 0.0626 - dense_1_loss_22: 0.0594 - dense_1_loss_23: 0.0583 - dense_1_loss_24: 0.0608 - dense_1_loss_25: 0.0682 - dense_1_loss_26: 0.0624 - dense_1_loss_27: 0.0667 - dense_1_loss_28: 0.0710 - dense_1_loss_29: 0.0821 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s - loss: 7.8417 - dense_1_loss_1: 3.8296 - dense_1_loss_2: 1.5397 - dense_1_loss_3: 0.5791 - dense_1_loss_4: 0.1975 - dense_1_loss_5: 0.1479 - dense_1_loss_6: 0.1063 - dense_1_loss_7: 0.0845 - dense_1_loss_8: 0.0722 - dense_1_loss_9: 0.0693 - dense_1_loss_10: 0.0584 - dense_1_loss_11: 0.0610 - dense_1_loss_12: 0.0601 - dense_1_loss_13: 0.0520 - dense_1_loss_14: 0.0599 - dense_1_loss_15: 0.0608 - dense_1_loss_16: 0.0584 - dense_1_loss_17: 0.0588 - dense_1_loss_18: 0.0585 - dense_1_loss_19: 0.0576 - dense_1_loss_20: 0.0620 - dense_1_loss_21: 0.0601 - dense_1_loss_22: 0.0573 - dense_1_loss_23: 0.0559 - dense_1_loss_24: 0.0585 - dense_1_loss_25: 0.0658 - dense_1_loss_26: 0.0596 - dense_1_loss_27: 0.0641 - dense_1_loss_28: 0.0687 - dense_1_loss_29: 0.0781 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s - loss: 7.7470 - dense_1_loss_1: 3.8265 - dense_1_loss_2: 1.5221 - dense_1_loss_3: 0.5677 - dense_1_loss_4: 0.1917 - dense_1_loss_5: 0.1432 - dense_1_loss_6: 0.1032 - dense_1_loss_7: 0.0819 - dense_1_loss_8: 0.0698 - dense_1_loss_9: 0.0672 - dense_1_loss_10: 0.0565 - dense_1_loss_11: 0.0590 - dense_1_loss_12: 0.0583 - dense_1_loss_13: 0.0504 - dense_1_loss_14: 0.0582 - dense_1_loss_15: 0.0585 - dense_1_loss_16: 0.0563 - dense_1_loss_17: 0.0568 - dense_1_loss_18: 0.0564 - dense_1_loss_19: 0.0558 - dense_1_loss_20: 0.0598 - dense_1_loss_21: 0.0577 - dense_1_loss_22: 0.0554 - dense_1_loss_23: 0.0539 - dense_1_loss_24: 0.0565 - dense_1_loss_25: 0.0633 - dense_1_loss_26: 0.0576 - dense_1_loss_27: 0.0622 - dense_1_loss_28: 0.0659 - dense_1_loss_29: 0.0751 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s - loss: 7.6535 - dense_1_loss_1: 3.8233 - dense_1_loss_2: 1.5052 - dense_1_loss_3: 0.5565 - dense_1_loss_4: 0.1859 - dense_1_loss_5: 0.1387 - dense_1_loss_6: 0.0995 - dense_1_loss_7: 0.0792 - dense_1_loss_8: 0.0674 - dense_1_loss_9: 0.0648 - dense_1_loss_10: 0.0546 - dense_1_loss_11: 0.0569 - dense_1_loss_12: 0.0562 - dense_1_loss_13: 0.0487 - dense_1_loss_14: 0.0561 - dense_1_loss_15: 0.0563 - dense_1_loss_16: 0.0544 - dense_1_loss_17: 0.0550 - dense_1_loss_18: 0.0543 - dense_1_loss_19: 0.0537 - dense_1_loss_20: 0.0578 - dense_1_loss_21: 0.0557 - dense_1_loss_22: 0.0535 - dense_1_loss_23: 0.0522 - dense_1_loss_24: 0.0548 - dense_1_loss_25: 0.0608 - dense_1_loss_26: 0.0556 - dense_1_loss_27: 0.0604 - dense_1_loss_28: 0.0638 - dense_1_loss_29: 0.0722 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s - loss: 7.5634 - dense_1_loss_1: 3.8205 - dense_1_loss_2: 1.4887 - dense_1_loss_3: 0.5443 - dense_1_loss_4: 0.1802 - dense_1_loss_5: 0.1344 - dense_1_loss_6: 0.0958 - dense_1_loss_7: 0.0766 - dense_1_loss_8: 0.0651 - dense_1_loss_9: 0.0626 - dense_1_loss_10: 0.0526 - dense_1_loss_11: 0.0551 - dense_1_loss_12: 0.0542 - dense_1_loss_13: 0.0470 - dense_1_loss_14: 0.0541 - dense_1_loss_15: 0.0546 - dense_1_loss_16: 0.0527 - dense_1_loss_17: 0.0533 - dense_1_loss_18: 0.0524 - dense_1_loss_19: 0.0518 - dense_1_loss_20: 0.0560 - dense_1_loss_21: 0.0538 - dense_1_loss_22: 0.0517 - dense_1_loss_23: 0.0507 - dense_1_loss_24: 0.0529 - dense_1_loss_25: 0.0588 - dense_1_loss_26: 0.0540 - dense_1_loss_27: 0.0584 - dense_1_loss_28: 0.0617 - dense_1_loss_29: 0.0696 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s - loss: 7.4786 - dense_1_loss_1: 3.8173 - dense_1_loss_2: 1.4723 - dense_1_loss_3: 0.5342 - dense_1_loss_4: 0.1749 - dense_1_loss_5: 0.1306 - dense_1_loss_6: 0.0927 - dense_1_loss_7: 0.0744 - dense_1_loss_8: 0.0630 - dense_1_loss_9: 0.0605 - dense_1_loss_10: 0.0508 - dense_1_loss_11: 0.0533 - dense_1_loss_12: 0.0524 - dense_1_loss_13: 0.0455 - dense_1_loss_14: 0.0521 - dense_1_loss_15: 0.0531 - dense_1_loss_16: 0.0510 - dense_1_loss_17: 0.0516 - dense_1_loss_18: 0.0506 - dense_1_loss_19: 0.0500 - dense_1_loss_20: 0.0542 - dense_1_loss_21: 0.0520 - dense_1_loss_22: 0.0501 - dense_1_loss_23: 0.0491 - dense_1_loss_24: 0.0511 - dense_1_loss_25: 0.0569 - dense_1_loss_26: 0.0523 - dense_1_loss_27: 0.0563 - dense_1_loss_28: 0.0597 - dense_1_loss_29: 0.0668 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 7.3986 - dense_1_loss_1: 3.8143 - dense_1_loss_2: 1.4569 - dense_1_loss_3: 0.5234 - dense_1_loss_4: 0.1699 - dense_1_loss_5: 0.1265 - dense_1_loss_6: 0.0898 - dense_1_loss_7: 0.0720 - dense_1_loss_8: 0.0609 - dense_1_loss_9: 0.0587 - dense_1_loss_10: 0.0493 - dense_1_loss_11: 0.0517 - dense_1_loss_12: 0.0509 - dense_1_loss_13: 0.0440 - dense_1_loss_14: 0.0506 - dense_1_loss_15: 0.0513 - dense_1_loss_16: 0.0495 - dense_1_loss_17: 0.0499 - dense_1_loss_18: 0.0490 - dense_1_loss_19: 0.0484 - dense_1_loss_20: 0.0525 - dense_1_loss_21: 0.0503 - dense_1_loss_22: 0.0487 - dense_1_loss_23: 0.0474 - dense_1_loss_24: 0.0495 - dense_1_loss_25: 0.0551 - dense_1_loss_26: 0.0506 - dense_1_loss_27: 0.0547 - dense_1_loss_28: 0.0579 - dense_1_loss_29: 0.0648 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s - loss: 7.3226 - dense_1_loss_1: 3.8113 - dense_1_loss_2: 1.4416 - dense_1_loss_3: 0.5135 - dense_1_loss_4: 0.1654 - dense_1_loss_5: 0.1231 - dense_1_loss_6: 0.0874 - dense_1_loss_7: 0.0701 - dense_1_loss_8: 0.0592 - dense_1_loss_9: 0.0570 - dense_1_loss_10: 0.0479 - dense_1_loss_11: 0.0501 - dense_1_loss_12: 0.0494 - dense_1_loss_13: 0.0427 - dense_1_loss_14: 0.0492 - dense_1_loss_15: 0.0497 - dense_1_loss_16: 0.0480 - dense_1_loss_17: 0.0484 - dense_1_loss_18: 0.0475 - dense_1_loss_19: 0.0470 - dense_1_loss_20: 0.0509 - dense_1_loss_21: 0.0487 - dense_1_loss_22: 0.0472 - dense_1_loss_23: 0.0459 - dense_1_loss_24: 0.0479 - dense_1_loss_25: 0.0533 - dense_1_loss_26: 0.0490 - dense_1_loss_27: 0.0531 - dense_1_loss_28: 0.0560 - dense_1_loss_29: 0.0622 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s - loss: 7.2466 - dense_1_loss_1: 3.8083 - dense_1_loss_2: 1.4259 - dense_1_loss_3: 0.5035 - dense_1_loss_4: 0.1602 - dense_1_loss_5: 0.1197 - dense_1_loss_6: 0.0845 - dense_1_loss_7: 0.0678 - dense_1_loss_8: 0.0574 - dense_1_loss_9: 0.0553 - dense_1_loss_10: 0.0465 - dense_1_loss_11: 0.0485 - dense_1_loss_12: 0.0479 - dense_1_loss_13: 0.0414 - dense_1_loss_14: 0.0477 - dense_1_loss_15: 0.0483 - dense_1_loss_16: 0.0466 - dense_1_loss_17: 0.0470 - dense_1_loss_18: 0.0461 - dense_1_loss_19: 0.0455 - dense_1_loss_20: 0.0493 - dense_1_loss_21: 0.0472 - dense_1_loss_22: 0.0458 - dense_1_loss_23: 0.0445 - dense_1_loss_24: 0.0465 - dense_1_loss_25: 0.0514 - dense_1_loss_26: 0.0476 - dense_1_loss_27: 0.0515 - dense_1_loss_28: 0.0544 - dense_1_loss_29: 0.0601 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6167 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s - loss: 7.1767 - dense_1_loss_1: 3.8053 - dense_1_loss_2: 1.4111 - dense_1_loss_3: 0.4944 - dense_1_loss_4: 0.1563 - dense_1_loss_5: 0.1164 - dense_1_loss_6: 0.0819 - dense_1_loss_7: 0.0660 - dense_1_loss_8: 0.0559 - dense_1_loss_9: 0.0536 - dense_1_loss_10: 0.0452 - dense_1_loss_11: 0.0471 - dense_1_loss_12: 0.0465 - dense_1_loss_13: 0.0402 - dense_1_loss_14: 0.0464 - dense_1_loss_15: 0.0468 - dense_1_loss_16: 0.0452 - dense_1_loss_17: 0.0457 - dense_1_loss_18: 0.0447 - dense_1_loss_19: 0.0442 - dense_1_loss_20: 0.0477 - dense_1_loss_21: 0.0459 - dense_1_loss_22: 0.0445 - dense_1_loss_23: 0.0432 - dense_1_loss_24: 0.0451 - dense_1_loss_25: 0.0499 - dense_1_loss_26: 0.0463 - dense_1_loss_27: 0.0501 - dense_1_loss_28: 0.0528 - dense_1_loss_29: 0.0585 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s - loss: 7.1086 - dense_1_loss_1: 3.8023 - dense_1_loss_2: 1.3975 - dense_1_loss_3: 0.4846 - dense_1_loss_4: 0.1520 - dense_1_loss_5: 0.1131 - dense_1_loss_6: 0.0796 - dense_1_loss_7: 0.0642 - dense_1_loss_8: 0.0542 - dense_1_loss_9: 0.0521 - dense_1_loss_10: 0.0440 - dense_1_loss_11: 0.0457 - dense_1_loss_12: 0.0452 - dense_1_loss_13: 0.0390 - dense_1_loss_14: 0.0451 - dense_1_loss_15: 0.0454 - dense_1_loss_16: 0.0439 - dense_1_loss_17: 0.0444 - dense_1_loss_18: 0.0435 - dense_1_loss_19: 0.0429 - dense_1_loss_20: 0.0462 - dense_1_loss_21: 0.0446 - dense_1_loss_22: 0.0433 - dense_1_loss_23: 0.0420 - dense_1_loss_24: 0.0438 - dense_1_loss_25: 0.0485 - dense_1_loss_26: 0.0449 - dense_1_loss_27: 0.0485 - dense_1_loss_28: 0.0515 - dense_1_loss_29: 0.0566 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s - loss: 7.0439 - dense_1_loss_1: 3.7996 - dense_1_loss_2: 1.3831 - dense_1_loss_3: 0.4758 - dense_1_loss_4: 0.1482 - dense_1_loss_5: 0.1103 - dense_1_loss_6: 0.0774 - dense_1_loss_7: 0.0625 - dense_1_loss_8: 0.0527 - dense_1_loss_9: 0.0508 - dense_1_loss_10: 0.0427 - dense_1_loss_11: 0.0444 - dense_1_loss_12: 0.0439 - dense_1_loss_13: 0.0380 - dense_1_loss_14: 0.0439 - dense_1_loss_15: 0.0442 - dense_1_loss_16: 0.0427 - dense_1_loss_17: 0.0431 - dense_1_loss_18: 0.0422 - dense_1_loss_19: 0.0417 - dense_1_loss_20: 0.0450 - dense_1_loss_21: 0.0434 - dense_1_loss_22: 0.0421 - dense_1_loss_23: 0.0408 - dense_1_loss_24: 0.0426 - dense_1_loss_25: 0.0471 - dense_1_loss_26: 0.0436 - dense_1_loss_27: 0.0471 - dense_1_loss_28: 0.0501 - dense_1_loss_29: 0.0549 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s - loss: 6.9822 - dense_1_loss_1: 3.7964 - dense_1_loss_2: 1.3705 - dense_1_loss_3: 0.4674 - dense_1_loss_4: 0.1447 - dense_1_loss_5: 0.1076 - dense_1_loss_6: 0.0752 - dense_1_loss_7: 0.0609 - dense_1_loss_8: 0.0513 - dense_1_loss_9: 0.0495 - dense_1_loss_10: 0.0416 - dense_1_loss_11: 0.0432 - dense_1_loss_12: 0.0427 - dense_1_loss_13: 0.0369 - dense_1_loss_14: 0.0426 - dense_1_loss_15: 0.0431 - dense_1_loss_16: 0.0415 - dense_1_loss_17: 0.0419 - dense_1_loss_18: 0.0410 - dense_1_loss_19: 0.0405 - dense_1_loss_20: 0.0438 - dense_1_loss_21: 0.0421 - dense_1_loss_22: 0.0409 - dense_1_loss_23: 0.0397 - dense_1_loss_24: 0.0414 - dense_1_loss_25: 0.0458 - dense_1_loss_26: 0.0425 - dense_1_loss_27: 0.0458 - dense_1_loss_28: 0.0486 - dense_1_loss_29: 0.0533 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s - loss: 6.9213 - dense_1_loss_1: 3.7934 - dense_1_loss_2: 1.3569 - dense_1_loss_3: 0.4585 - dense_1_loss_4: 0.1414 - dense_1_loss_5: 0.1048 - dense_1_loss_6: 0.0733 - dense_1_loss_7: 0.0593 - dense_1_loss_8: 0.0499 - dense_1_loss_9: 0.0483 - dense_1_loss_10: 0.0405 - dense_1_loss_11: 0.0421 - dense_1_loss_12: 0.0415 - dense_1_loss_13: 0.0360 - dense_1_loss_14: 0.0416 - dense_1_loss_15: 0.0419 - dense_1_loss_16: 0.0404 - dense_1_loss_17: 0.0408 - dense_1_loss_18: 0.0400 - dense_1_loss_19: 0.0393 - dense_1_loss_20: 0.0427 - dense_1_loss_21: 0.0409 - dense_1_loss_22: 0.0397 - dense_1_loss_23: 0.0386 - dense_1_loss_24: 0.0404 - dense_1_loss_25: 0.0445 - dense_1_loss_26: 0.0412 - dense_1_loss_27: 0.0446 - dense_1_loss_28: 0.0474 - dense_1_loss_29: 0.0516 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s - loss: 6.8631 - dense_1_loss_1: 3.7905 - dense_1_loss_2: 1.3437 - dense_1_loss_3: 0.4501 - dense_1_loss_4: 0.1380 - dense_1_loss_5: 0.1022 - dense_1_loss_6: 0.0712 - dense_1_loss_7: 0.0577 - dense_1_loss_8: 0.0485 - dense_1_loss_9: 0.0470 - dense_1_loss_10: 0.0395 - dense_1_loss_11: 0.0409 - dense_1_loss_12: 0.0405 - dense_1_loss_13: 0.0351 - dense_1_loss_14: 0.0405 - dense_1_loss_15: 0.0408 - dense_1_loss_16: 0.0393 - dense_1_loss_17: 0.0397 - dense_1_loss_18: 0.0389 - dense_1_loss_19: 0.0383 - dense_1_loss_20: 0.0415 - dense_1_loss_21: 0.0399 - dense_1_loss_22: 0.0387 - dense_1_loss_23: 0.0376 - dense_1_loss_24: 0.0394 - dense_1_loss_25: 0.0435 - dense_1_loss_26: 0.0401 - dense_1_loss_27: 0.0434 - dense_1_loss_28: 0.0462 - dense_1_loss_29: 0.0504 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s - loss: 6.8084 - dense_1_loss_1: 3.7876 - dense_1_loss_2: 1.3314 - dense_1_loss_3: 0.4427 - dense_1_loss_4: 0.1345 - dense_1_loss_5: 0.0998 - dense_1_loss_6: 0.0695 - dense_1_loss_7: 0.0564 - dense_1_loss_8: 0.0474 - dense_1_loss_9: 0.0459 - dense_1_loss_10: 0.0385 - dense_1_loss_11: 0.0399 - dense_1_loss_12: 0.0395 - dense_1_loss_13: 0.0342 - dense_1_loss_14: 0.0395 - dense_1_loss_15: 0.0398 - dense_1_loss_16: 0.0383 - dense_1_loss_17: 0.0387 - dense_1_loss_18: 0.0379 - dense_1_loss_19: 0.0373 - dense_1_loss_20: 0.0404 - dense_1_loss_21: 0.0388 - dense_1_loss_22: 0.0377 - dense_1_loss_23: 0.0366 - dense_1_loss_24: 0.0384 - dense_1_loss_25: 0.0424 - dense_1_loss_26: 0.0390 - dense_1_loss_27: 0.0423 - dense_1_loss_28: 0.0451 - dense_1_loss_29: 0.0489 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s - loss: 6.7547 - dense_1_loss_1: 3.7849 - dense_1_loss_2: 1.3188 - dense_1_loss_3: 0.4352 - dense_1_loss_4: 0.1317 - dense_1_loss_5: 0.0974 - dense_1_loss_6: 0.0677 - dense_1_loss_7: 0.0550 - dense_1_loss_8: 0.0463 - dense_1_loss_9: 0.0446 - dense_1_loss_10: 0.0375 - dense_1_loss_11: 0.0389 - dense_1_loss_12: 0.0385 - dense_1_loss_13: 0.0333 - dense_1_loss_14: 0.0385 - dense_1_loss_15: 0.0388 - dense_1_loss_16: 0.0375 - dense_1_loss_17: 0.0377 - dense_1_loss_18: 0.0370 - dense_1_loss_19: 0.0363 - dense_1_loss_20: 0.0395 - dense_1_loss_21: 0.0378 - dense_1_loss_22: 0.0367 - dense_1_loss_23: 0.0356 - dense_1_loss_24: 0.0374 - dense_1_loss_25: 0.0414 - dense_1_loss_26: 0.0379 - dense_1_loss_27: 0.0411 - dense_1_loss_28: 0.0440 - dense_1_loss_29: 0.0477 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s - loss: 6.7017 - dense_1_loss_1: 3.7819 - dense_1_loss_2: 1.3066 - dense_1_loss_3: 0.4275 - dense_1_loss_4: 0.1286 - dense_1_loss_5: 0.0953 - dense_1_loss_6: 0.0658 - dense_1_loss_7: 0.0537 - dense_1_loss_8: 0.0451 - dense_1_loss_9: 0.0435 - dense_1_loss_10: 0.0366 - dense_1_loss_11: 0.0379 - dense_1_loss_12: 0.0375 - dense_1_loss_13: 0.0326 - dense_1_loss_14: 0.0374 - dense_1_loss_15: 0.0379 - dense_1_loss_16: 0.0366 - dense_1_loss_17: 0.0368 - dense_1_loss_18: 0.0360 - dense_1_loss_19: 0.0353 - dense_1_loss_20: 0.0385 - dense_1_loss_21: 0.0368 - dense_1_loss_22: 0.0358 - dense_1_loss_23: 0.0347 - dense_1_loss_24: 0.0365 - dense_1_loss_25: 0.0403 - dense_1_loss_26: 0.0370 - dense_1_loss_27: 0.0401 - dense_1_loss_28: 0.0428 - dense_1_loss_29: 0.0463 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s - loss: 6.6526 - dense_1_loss_1: 3.7791 - dense_1_loss_2: 1.2953 - dense_1_loss_3: 0.4206 - dense_1_loss_4: 0.1260 - dense_1_loss_5: 0.0930 - dense_1_loss_6: 0.0642 - dense_1_loss_7: 0.0524 - dense_1_loss_8: 0.0440 - dense_1_loss_9: 0.0425 - dense_1_loss_10: 0.0357 - dense_1_loss_11: 0.0370 - dense_1_loss_12: 0.0366 - dense_1_loss_13: 0.0318 - dense_1_loss_14: 0.0366 - dense_1_loss_15: 0.0370 - dense_1_loss_16: 0.0357 - dense_1_loss_17: 0.0359 - dense_1_loss_18: 0.0352 - dense_1_loss_19: 0.0345 - dense_1_loss_20: 0.0376 - dense_1_loss_21: 0.0359 - dense_1_loss_22: 0.0350 - dense_1_loss_23: 0.0339 - dense_1_loss_24: 0.0357 - dense_1_loss_25: 0.0392 - dense_1_loss_26: 0.0361 - dense_1_loss_27: 0.0392 - dense_1_loss_28: 0.0418 - dense_1_loss_29: 0.0452 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6500 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s - loss: 6.6047 - dense_1_loss_1: 3.7765 - dense_1_loss_2: 1.2836 - dense_1_loss_3: 0.4133 - dense_1_loss_4: 0.1237 - dense_1_loss_5: 0.0909 - dense_1_loss_6: 0.0627 - dense_1_loss_7: 0.0513 - dense_1_loss_8: 0.0430 - dense_1_loss_9: 0.0415 - dense_1_loss_10: 0.0349 - dense_1_loss_11: 0.0362 - dense_1_loss_12: 0.0358 - dense_1_loss_13: 0.0310 - dense_1_loss_14: 0.0357 - dense_1_loss_15: 0.0362 - dense_1_loss_16: 0.0349 - dense_1_loss_17: 0.0351 - dense_1_loss_18: 0.0343 - dense_1_loss_19: 0.0337 - dense_1_loss_20: 0.0367 - dense_1_loss_21: 0.0350 - dense_1_loss_22: 0.0342 - dense_1_loss_23: 0.0331 - dense_1_loss_24: 0.0349 - dense_1_loss_25: 0.0381 - dense_1_loss_26: 0.0353 - dense_1_loss_27: 0.0383 - dense_1_loss_28: 0.0408 - dense_1_loss_29: 0.0440 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6500 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00         \n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s - loss: 6.5578 - dense_1_loss_1: 3.7736 - dense_1_loss_2: 1.2725 - dense_1_loss_3: 0.4058 - dense_1_loss_4: 0.1211 - dense_1_loss_5: 0.0890 - dense_1_loss_6: 0.0609 - dense_1_loss_7: 0.0502 - dense_1_loss_8: 0.0421 - dense_1_loss_9: 0.0406 - dense_1_loss_10: 0.0341 - dense_1_loss_11: 0.0354 - dense_1_loss_12: 0.0350 - dense_1_loss_13: 0.0304 - dense_1_loss_14: 0.0348 - dense_1_loss_15: 0.0354 - dense_1_loss_16: 0.0342 - dense_1_loss_17: 0.0343 - dense_1_loss_18: 0.0336 - dense_1_loss_19: 0.0329 - dense_1_loss_20: 0.0359 - dense_1_loss_21: 0.0342 - dense_1_loss_22: 0.0334 - dense_1_loss_23: 0.0323 - dense_1_loss_24: 0.0341 - dense_1_loss_25: 0.0373 - dense_1_loss_26: 0.0344 - dense_1_loss_27: 0.0374 - dense_1_loss_28: 0.0399 - dense_1_loss_29: 0.0431 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6500 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s - loss: 6.5125 - dense_1_loss_1: 3.7708 - dense_1_loss_2: 1.2615 - dense_1_loss_3: 0.3992 - dense_1_loss_4: 0.1186 - dense_1_loss_5: 0.0870 - dense_1_loss_6: 0.0598 - dense_1_loss_7: 0.0492 - dense_1_loss_8: 0.0412 - dense_1_loss_9: 0.0398 - dense_1_loss_10: 0.0333 - dense_1_loss_11: 0.0347 - dense_1_loss_12: 0.0342 - dense_1_loss_13: 0.0297 - dense_1_loss_14: 0.0342 - dense_1_loss_15: 0.0345 - dense_1_loss_16: 0.0334 - dense_1_loss_17: 0.0335 - dense_1_loss_18: 0.0328 - dense_1_loss_19: 0.0321 - dense_1_loss_20: 0.0350 - dense_1_loss_21: 0.0334 - dense_1_loss_22: 0.0326 - dense_1_loss_23: 0.0316 - dense_1_loss_24: 0.0332 - dense_1_loss_25: 0.0364 - dense_1_loss_26: 0.0334 - dense_1_loss_27: 0.0365 - dense_1_loss_28: 0.0389 - dense_1_loss_29: 0.0420 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6500 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s - loss: 6.4683 - dense_1_loss_1: 3.7681 - dense_1_loss_2: 1.2504 - dense_1_loss_3: 0.3926 - dense_1_loss_4: 0.1162 - dense_1_loss_5: 0.0850 - dense_1_loss_6: 0.0584 - dense_1_loss_7: 0.0480 - dense_1_loss_8: 0.0402 - dense_1_loss_9: 0.0391 - dense_1_loss_10: 0.0326 - dense_1_loss_11: 0.0338 - dense_1_loss_12: 0.0335 - dense_1_loss_13: 0.0290 - dense_1_loss_14: 0.0335 - dense_1_loss_15: 0.0337 - dense_1_loss_16: 0.0326 - dense_1_loss_17: 0.0328 - dense_1_loss_18: 0.0321 - dense_1_loss_19: 0.0314 - dense_1_loss_20: 0.0341 - dense_1_loss_21: 0.0327 - dense_1_loss_22: 0.0320 - dense_1_loss_23: 0.0309 - dense_1_loss_24: 0.0325 - dense_1_loss_25: 0.0355 - dense_1_loss_26: 0.0327 - dense_1_loss_27: 0.0358 - dense_1_loss_28: 0.0380 - dense_1_loss_29: 0.0410 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6500 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s - loss: 6.4269 - dense_1_loss_1: 3.7653 - dense_1_loss_2: 1.2405 - dense_1_loss_3: 0.3867 - dense_1_loss_4: 0.1141 - dense_1_loss_5: 0.0831 - dense_1_loss_6: 0.0571 - dense_1_loss_7: 0.0470 - dense_1_loss_8: 0.0393 - dense_1_loss_9: 0.0382 - dense_1_loss_10: 0.0318 - dense_1_loss_11: 0.0332 - dense_1_loss_12: 0.0327 - dense_1_loss_13: 0.0284 - dense_1_loss_14: 0.0327 - dense_1_loss_15: 0.0330 - dense_1_loss_16: 0.0319 - dense_1_loss_17: 0.0320 - dense_1_loss_18: 0.0314 - dense_1_loss_19: 0.0307 - dense_1_loss_20: 0.0334 - dense_1_loss_21: 0.0320 - dense_1_loss_22: 0.0312 - dense_1_loss_23: 0.0302 - dense_1_loss_24: 0.0318 - dense_1_loss_25: 0.0348 - dense_1_loss_26: 0.0321 - dense_1_loss_27: 0.0349 - dense_1_loss_28: 0.0372 - dense_1_loss_29: 0.0401 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6500 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s - loss: 6.3865 - dense_1_loss_1: 3.7625 - dense_1_loss_2: 1.2301 - dense_1_loss_3: 0.3806 - dense_1_loss_4: 0.1122 - dense_1_loss_5: 0.0818 - dense_1_loss_6: 0.0558 - dense_1_loss_7: 0.0461 - dense_1_loss_8: 0.0385 - dense_1_loss_9: 0.0373 - dense_1_loss_10: 0.0311 - dense_1_loss_11: 0.0323 - dense_1_loss_12: 0.0320 - dense_1_loss_13: 0.0278 - dense_1_loss_14: 0.0317 - dense_1_loss_15: 0.0326 - dense_1_loss_16: 0.0313 - dense_1_loss_17: 0.0313 - dense_1_loss_18: 0.0307 - dense_1_loss_19: 0.0300 - dense_1_loss_20: 0.0328 - dense_1_loss_21: 0.0313 - dense_1_loss_22: 0.0305 - dense_1_loss_23: 0.0296 - dense_1_loss_24: 0.0312 - dense_1_loss_25: 0.0341 - dense_1_loss_26: 0.0314 - dense_1_loss_27: 0.0341 - dense_1_loss_28: 0.0365 - dense_1_loss_29: 0.0394 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6500 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s - loss: 6.3466 - dense_1_loss_1: 3.7599 - dense_1_loss_2: 1.2201 - dense_1_loss_3: 0.3744 - dense_1_loss_4: 0.1103 - dense_1_loss_5: 0.0802 - dense_1_loss_6: 0.0545 - dense_1_loss_7: 0.0451 - dense_1_loss_8: 0.0377 - dense_1_loss_9: 0.0365 - dense_1_loss_10: 0.0304 - dense_1_loss_11: 0.0316 - dense_1_loss_12: 0.0313 - dense_1_loss_13: 0.0272 - dense_1_loss_14: 0.0311 - dense_1_loss_15: 0.0319 - dense_1_loss_16: 0.0306 - dense_1_loss_17: 0.0306 - dense_1_loss_18: 0.0300 - dense_1_loss_19: 0.0293 - dense_1_loss_20: 0.0321 - dense_1_loss_21: 0.0306 - dense_1_loss_22: 0.0298 - dense_1_loss_23: 0.0290 - dense_1_loss_24: 0.0305 - dense_1_loss_25: 0.0334 - dense_1_loss_26: 0.0308 - dense_1_loss_27: 0.0334 - dense_1_loss_28: 0.0357 - dense_1_loss_29: 0.0385 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6500 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0000e+00     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f741987ca20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X, a0, c0], list(Y), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "\n",
    "The model loss will start high, (100 or so), and after 100 epochs, it should be in the single digits.  These won't be the exact number that you'll see, due to random initialization of weights.  \n",
    "For example:\n",
    "```\n",
    "Epoch 1/100\n",
    "60/60 [==============================] - 3s - loss: 125.7673\n",
    "...\n",
    "```\n",
    "Scroll to the bottom to check Epoch 100\n",
    "```\n",
    "...\n",
    "Epoch 100/100\n",
    "60/60 [==============================] - 0s - loss: 6.1861\n",
    "```\n",
    "\n",
    "Now that you have trained a model, let's go to the final section to implement an inference algorithm, and generate some music! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Generating music\n",
    "\n",
    "You now have a trained model which has learned the patterns of the jazz soloist. Lets now use this model to synthesize new music. \n",
    "\n",
    "#### 3.1 - Predicting & Sampling\n",
    "\n",
    "<img src=\"images/music_gen.png\" style=\"width:600;height:400px;\">\n",
    "\n",
    "At each step of sampling, you will:\n",
    "* Take as input the activation '`a`' and cell state '`c`' from the previous state of the LSTM.\n",
    "* Forward propagate by one step.\n",
    "* Get a new output activation as well as cell state. \n",
    "* The new activation '`a`' can then be used to generate the output using the fully connected layer, `densor`. \n",
    "\n",
    "##### Initialization\n",
    "* We will initialize the following to be zeros:\n",
    "    * `x0` \n",
    "    * hidden state `a0` \n",
    "    * cell state `c0` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "* Implement the function below to sample a sequence of musical values. \n",
    "* Here are some of the key steps you'll need to implement inside the for-loop that generates the $T_y$ output characters: \n",
    "\n",
    "* Step 2.A: Use `LSTM_Cell`, which takes in the input layer, as well as the previous step's '`c`' and '`a`' to generate the current step's '`c`' and '`a`'. \n",
    "```Python\n",
    "next_hidden_state, _, next_cell_state = LSTM_cell(input_x, initial_state=[previous_hidden_state, previous_cell_state])\n",
    "```\n",
    "    * Choose the appropriate variables for the input_x, hidden_state, and cell_state\n",
    "\n",
    "* Step 2.B: Compute the output by applying `densor` to compute a softmax on '`a`' to get the output for the current step. \n",
    "\n",
    "* Step 2.C: Append the output to the list `outputs`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Step 2.D: Sample x to be the one-hot version of '`out`'. \n",
    "* This allows you to pass it to the next LSTM's step.  \n",
    "* We have provided the definition of `one_hot(x)` in the 'music_utils.py' file and imported it.\n",
    "Here is the definition of `one_hot`\n",
    "```Python\n",
    "def one_hot(x):\n",
    "    x = K.argmax(x)\n",
    "    x = tf.one_hot(indices=x, depth=78) \n",
    "    x = RepeatVector(1)(x)\n",
    "    return x\n",
    "```\n",
    "Here is what the `one_hot` function is doing:\n",
    "* argmax: within the vector `x`, find the position with the maximum value and return the index of that position.  \n",
    "    * For example: argmax of [-1,0,1] finds that 1 is the maximum value, and returns the index position, which is 2.  Read the documentation for [keras.argmax](https://www.tensorflow.org/api_docs/python/tf/keras/backend/argmax).\n",
    "* one_hot: takes a list of indices and the depth of the one-hot vector (number of categories, which is 78 in this assignment).  It converts each index into the one-hot vector representation.  For instance, if the indices is [2], and the depth is 5, then the one-hot vector returned is [0,0,1,0,0].  Check out the documentation for [tf.one_hot](https://www.tensorflow.org/api_docs/python/tf/one_hot) for more examples and explanations.\n",
    "* RepeatVector(n): This takes a vector and duplicates it `n` times.  Notice that we had it repeat 1 time.  This may seem like it's not doing anything.  If you look at the documentation for [RepeatVector](https://keras.io/layers/core/#repeatvector), you'll notice that if x is a vector with dimension (m,5) and it gets passed into `RepeatVector(1)`, then the output is (m,1,5).  In other words, it adds an additional dimension (of length 1) to the resulting vector.\n",
    "* Apply the custom one_hot encoding using the [Lambda](https://keras.io/layers/core/#lambda) layer.  You saw earlier that the Lambda layer can be used like this:\n",
    "```Python\n",
    "result = Lambda(lambda x: x + 1)(input_var)\n",
    "```\n",
    "\n",
    "If you pre-define a function, you can do the same thing:\n",
    "```Python\n",
    "def add_one(x)\n",
    "    return x + 1\n",
    "\n",
    "# use the add_one function inside of the Lambda function\n",
    "result = Lambda(add_one)(input_var)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Inference Model:  \n",
    "This is how to use the Keras `Model`.\n",
    "```Python\n",
    "model = Model(inputs=[input_x, initial_hidden_state, initial_cell_state], outputs=the_outputs)\n",
    "```\n",
    "\n",
    "\n",
    "* Choose the appropriate variables for the input tensor, hidden state, cell state, and output.\n",
    "* **Hint**: the inputs to the model are the **initial** inputs and states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: music_inference_model\n",
    "\n",
    "def music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 100):\n",
    "    \"\"\"\n",
    "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
    "    \n",
    "    Arguments:\n",
    "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
    "    densor -- the trained \"densor\" from model(), Keras layer object\n",
    "    n_values -- integer, number of unique values\n",
    "    n_a -- number of units in the LSTM_cell\n",
    "    Ty -- integer, number of time steps to generate\n",
    "    \n",
    "    Returns:\n",
    "    inference_model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    x0 = Input(shape=(1, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    x = x0\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Create an empty list of \"outputs\" to later store your predicted values (≈1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop over Ty and generate a value at every time step\n",
    "    for t in range(Ty):\n",
    "        \n",
    "        # Step 2.A: Perform one step of LSTM_cell (≈1 line)\n",
    "        a, _, c = LSTM_cell(x, initial_state=[a, c])\n",
    "        \n",
    "        # Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)\n",
    "        out = densor(a)\n",
    "\n",
    "        # Step 2.C: Append the prediction \"out\" to \"outputs\". out.shape = (None, 78) (≈1 line)\n",
    "        outputs.append(out)\n",
    "        \n",
    "        # Step 2.D: \n",
    "        # Select the next value according to \"out\",\n",
    "        # Set \"x\" to be the one-hot representation of the selected value\n",
    "        # See instructions above.\n",
    "        x = Lambda(one_hot)(out)\n",
    "        \n",
    "    # Step 3: Create model instance with the correct \"inputs\" and \"outputs\" (≈1 line)\n",
    "    inference_model = Model(inputs=[x0, a0, c0], outputs=outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to define your inference model. This model is hard coded to generate 50 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference_model = music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 1, 78)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "a0 (InputLayer)                  (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c0 (InputLayer)                  (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    [(None, 64), (None, 6 36608       input_6[0][0]                    \n",
      "                                                                   a0[0][0]                         \n",
      "                                                                   c0[0][0]                         \n",
      "                                                                   lambda_181[0][0]                 \n",
      "                                                                   lstm_1[180][0]                   \n",
      "                                                                   lstm_1[180][2]                   \n",
      "                                                                   lambda_182[0][0]                 \n",
      "                                                                   lstm_1[181][0]                   \n",
      "                                                                   lstm_1[181][2]                   \n",
      "                                                                   lambda_183[0][0]                 \n",
      "                                                                   lstm_1[182][0]                   \n",
      "                                                                   lstm_1[182][2]                   \n",
      "                                                                   lambda_184[0][0]                 \n",
      "                                                                   lstm_1[183][0]                   \n",
      "                                                                   lstm_1[183][2]                   \n",
      "                                                                   lambda_185[0][0]                 \n",
      "                                                                   lstm_1[184][0]                   \n",
      "                                                                   lstm_1[184][2]                   \n",
      "                                                                   lambda_186[0][0]                 \n",
      "                                                                   lstm_1[185][0]                   \n",
      "                                                                   lstm_1[185][2]                   \n",
      "                                                                   lambda_187[0][0]                 \n",
      "                                                                   lstm_1[186][0]                   \n",
      "                                                                   lstm_1[186][2]                   \n",
      "                                                                   lambda_188[0][0]                 \n",
      "                                                                   lstm_1[187][0]                   \n",
      "                                                                   lstm_1[187][2]                   \n",
      "                                                                   lambda_189[0][0]                 \n",
      "                                                                   lstm_1[188][0]                   \n",
      "                                                                   lstm_1[188][2]                   \n",
      "                                                                   lambda_190[0][0]                 \n",
      "                                                                   lstm_1[189][0]                   \n",
      "                                                                   lstm_1[189][2]                   \n",
      "                                                                   lambda_191[0][0]                 \n",
      "                                                                   lstm_1[190][0]                   \n",
      "                                                                   lstm_1[190][2]                   \n",
      "                                                                   lambda_192[0][0]                 \n",
      "                                                                   lstm_1[191][0]                   \n",
      "                                                                   lstm_1[191][2]                   \n",
      "                                                                   lambda_193[0][0]                 \n",
      "                                                                   lstm_1[192][0]                   \n",
      "                                                                   lstm_1[192][2]                   \n",
      "                                                                   lambda_194[0][0]                 \n",
      "                                                                   lstm_1[193][0]                   \n",
      "                                                                   lstm_1[193][2]                   \n",
      "                                                                   lambda_195[0][0]                 \n",
      "                                                                   lstm_1[194][0]                   \n",
      "                                                                   lstm_1[194][2]                   \n",
      "                                                                   lambda_196[0][0]                 \n",
      "                                                                   lstm_1[195][0]                   \n",
      "                                                                   lstm_1[195][2]                   \n",
      "                                                                   lambda_197[0][0]                 \n",
      "                                                                   lstm_1[196][0]                   \n",
      "                                                                   lstm_1[196][2]                   \n",
      "                                                                   lambda_198[0][0]                 \n",
      "                                                                   lstm_1[197][0]                   \n",
      "                                                                   lstm_1[197][2]                   \n",
      "                                                                   lambda_199[0][0]                 \n",
      "                                                                   lstm_1[198][0]                   \n",
      "                                                                   lstm_1[198][2]                   \n",
      "                                                                   lambda_200[0][0]                 \n",
      "                                                                   lstm_1[199][0]                   \n",
      "                                                                   lstm_1[199][2]                   \n",
      "                                                                   lambda_201[0][0]                 \n",
      "                                                                   lstm_1[200][0]                   \n",
      "                                                                   lstm_1[200][2]                   \n",
      "                                                                   lambda_202[0][0]                 \n",
      "                                                                   lstm_1[201][0]                   \n",
      "                                                                   lstm_1[201][2]                   \n",
      "                                                                   lambda_203[0][0]                 \n",
      "                                                                   lstm_1[202][0]                   \n",
      "                                                                   lstm_1[202][2]                   \n",
      "                                                                   lambda_204[0][0]                 \n",
      "                                                                   lstm_1[203][0]                   \n",
      "                                                                   lstm_1[203][2]                   \n",
      "                                                                   lambda_205[0][0]                 \n",
      "                                                                   lstm_1[204][0]                   \n",
      "                                                                   lstm_1[204][2]                   \n",
      "                                                                   lambda_206[0][0]                 \n",
      "                                                                   lstm_1[205][0]                   \n",
      "                                                                   lstm_1[205][2]                   \n",
      "                                                                   lambda_207[0][0]                 \n",
      "                                                                   lstm_1[206][0]                   \n",
      "                                                                   lstm_1[206][2]                   \n",
      "                                                                   lambda_208[0][0]                 \n",
      "                                                                   lstm_1[207][0]                   \n",
      "                                                                   lstm_1[207][2]                   \n",
      "                                                                   lambda_209[0][0]                 \n",
      "                                                                   lstm_1[208][0]                   \n",
      "                                                                   lstm_1[208][2]                   \n",
      "                                                                   lambda_210[0][0]                 \n",
      "                                                                   lstm_1[209][0]                   \n",
      "                                                                   lstm_1[209][2]                   \n",
      "                                                                   lambda_211[0][0]                 \n",
      "                                                                   lstm_1[210][0]                   \n",
      "                                                                   lstm_1[210][2]                   \n",
      "                                                                   lambda_212[0][0]                 \n",
      "                                                                   lstm_1[211][0]                   \n",
      "                                                                   lstm_1[211][2]                   \n",
      "                                                                   lambda_213[0][0]                 \n",
      "                                                                   lstm_1[212][0]                   \n",
      "                                                                   lstm_1[212][2]                   \n",
      "                                                                   lambda_214[0][0]                 \n",
      "                                                                   lstm_1[213][0]                   \n",
      "                                                                   lstm_1[213][2]                   \n",
      "                                                                   lambda_215[0][0]                 \n",
      "                                                                   lstm_1[214][0]                   \n",
      "                                                                   lstm_1[214][2]                   \n",
      "                                                                   lambda_216[0][0]                 \n",
      "                                                                   lstm_1[215][0]                   \n",
      "                                                                   lstm_1[215][2]                   \n",
      "                                                                   lambda_217[0][0]                 \n",
      "                                                                   lstm_1[216][0]                   \n",
      "                                                                   lstm_1[216][2]                   \n",
      "                                                                   lambda_218[0][0]                 \n",
      "                                                                   lstm_1[217][0]                   \n",
      "                                                                   lstm_1[217][2]                   \n",
      "                                                                   lambda_219[0][0]                 \n",
      "                                                                   lstm_1[218][0]                   \n",
      "                                                                   lstm_1[218][2]                   \n",
      "                                                                   lambda_220[0][0]                 \n",
      "                                                                   lstm_1[219][0]                   \n",
      "                                                                   lstm_1[219][2]                   \n",
      "                                                                   lambda_221[0][0]                 \n",
      "                                                                   lstm_1[220][0]                   \n",
      "                                                                   lstm_1[220][2]                   \n",
      "                                                                   lambda_222[0][0]                 \n",
      "                                                                   lstm_1[221][0]                   \n",
      "                                                                   lstm_1[221][2]                   \n",
      "                                                                   lambda_223[0][0]                 \n",
      "                                                                   lstm_1[222][0]                   \n",
      "                                                                   lstm_1[222][2]                   \n",
      "                                                                   lambda_224[0][0]                 \n",
      "                                                                   lstm_1[223][0]                   \n",
      "                                                                   lstm_1[223][2]                   \n",
      "                                                                   lambda_225[0][0]                 \n",
      "                                                                   lstm_1[224][0]                   \n",
      "                                                                   lstm_1[224][2]                   \n",
      "                                                                   lambda_226[0][0]                 \n",
      "                                                                   lstm_1[225][0]                   \n",
      "                                                                   lstm_1[225][2]                   \n",
      "                                                                   lambda_227[0][0]                 \n",
      "                                                                   lstm_1[226][0]                   \n",
      "                                                                   lstm_1[226][2]                   \n",
      "                                                                   lambda_228[0][0]                 \n",
      "                                                                   lstm_1[227][0]                   \n",
      "                                                                   lstm_1[227][2]                   \n",
      "                                                                   lambda_229[0][0]                 \n",
      "                                                                   lstm_1[228][0]                   \n",
      "                                                                   lstm_1[228][2]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 78)            5070        lstm_1[180][0]                   \n",
      "                                                                   lstm_1[181][0]                   \n",
      "                                                                   lstm_1[182][0]                   \n",
      "                                                                   lstm_1[183][0]                   \n",
      "                                                                   lstm_1[184][0]                   \n",
      "                                                                   lstm_1[185][0]                   \n",
      "                                                                   lstm_1[186][0]                   \n",
      "                                                                   lstm_1[187][0]                   \n",
      "                                                                   lstm_1[188][0]                   \n",
      "                                                                   lstm_1[189][0]                   \n",
      "                                                                   lstm_1[190][0]                   \n",
      "                                                                   lstm_1[191][0]                   \n",
      "                                                                   lstm_1[192][0]                   \n",
      "                                                                   lstm_1[193][0]                   \n",
      "                                                                   lstm_1[194][0]                   \n",
      "                                                                   lstm_1[195][0]                   \n",
      "                                                                   lstm_1[196][0]                   \n",
      "                                                                   lstm_1[197][0]                   \n",
      "                                                                   lstm_1[198][0]                   \n",
      "                                                                   lstm_1[199][0]                   \n",
      "                                                                   lstm_1[200][0]                   \n",
      "                                                                   lstm_1[201][0]                   \n",
      "                                                                   lstm_1[202][0]                   \n",
      "                                                                   lstm_1[203][0]                   \n",
      "                                                                   lstm_1[204][0]                   \n",
      "                                                                   lstm_1[205][0]                   \n",
      "                                                                   lstm_1[206][0]                   \n",
      "                                                                   lstm_1[207][0]                   \n",
      "                                                                   lstm_1[208][0]                   \n",
      "                                                                   lstm_1[209][0]                   \n",
      "                                                                   lstm_1[210][0]                   \n",
      "                                                                   lstm_1[211][0]                   \n",
      "                                                                   lstm_1[212][0]                   \n",
      "                                                                   lstm_1[213][0]                   \n",
      "                                                                   lstm_1[214][0]                   \n",
      "                                                                   lstm_1[215][0]                   \n",
      "                                                                   lstm_1[216][0]                   \n",
      "                                                                   lstm_1[217][0]                   \n",
      "                                                                   lstm_1[218][0]                   \n",
      "                                                                   lstm_1[219][0]                   \n",
      "                                                                   lstm_1[220][0]                   \n",
      "                                                                   lstm_1[221][0]                   \n",
      "                                                                   lstm_1[222][0]                   \n",
      "                                                                   lstm_1[223][0]                   \n",
      "                                                                   lstm_1[224][0]                   \n",
      "                                                                   lstm_1[225][0]                   \n",
      "                                                                   lstm_1[226][0]                   \n",
      "                                                                   lstm_1[227][0]                   \n",
      "                                                                   lstm_1[228][0]                   \n",
      "                                                                   lstm_1[229][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_181 (Lambda)              (None, 1, 78)         0           dense_1[180][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_182 (Lambda)              (None, 1, 78)         0           dense_1[181][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_183 (Lambda)              (None, 1, 78)         0           dense_1[182][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_184 (Lambda)              (None, 1, 78)         0           dense_1[183][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_185 (Lambda)              (None, 1, 78)         0           dense_1[184][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_186 (Lambda)              (None, 1, 78)         0           dense_1[185][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_187 (Lambda)              (None, 1, 78)         0           dense_1[186][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_188 (Lambda)              (None, 1, 78)         0           dense_1[187][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_189 (Lambda)              (None, 1, 78)         0           dense_1[188][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_190 (Lambda)              (None, 1, 78)         0           dense_1[189][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_191 (Lambda)              (None, 1, 78)         0           dense_1[190][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_192 (Lambda)              (None, 1, 78)         0           dense_1[191][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_193 (Lambda)              (None, 1, 78)         0           dense_1[192][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_194 (Lambda)              (None, 1, 78)         0           dense_1[193][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_195 (Lambda)              (None, 1, 78)         0           dense_1[194][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_196 (Lambda)              (None, 1, 78)         0           dense_1[195][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_197 (Lambda)              (None, 1, 78)         0           dense_1[196][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_198 (Lambda)              (None, 1, 78)         0           dense_1[197][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_199 (Lambda)              (None, 1, 78)         0           dense_1[198][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_200 (Lambda)              (None, 1, 78)         0           dense_1[199][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_201 (Lambda)              (None, 1, 78)         0           dense_1[200][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_202 (Lambda)              (None, 1, 78)         0           dense_1[201][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_203 (Lambda)              (None, 1, 78)         0           dense_1[202][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_204 (Lambda)              (None, 1, 78)         0           dense_1[203][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_205 (Lambda)              (None, 1, 78)         0           dense_1[204][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_206 (Lambda)              (None, 1, 78)         0           dense_1[205][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_207 (Lambda)              (None, 1, 78)         0           dense_1[206][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_208 (Lambda)              (None, 1, 78)         0           dense_1[207][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_209 (Lambda)              (None, 1, 78)         0           dense_1[208][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_210 (Lambda)              (None, 1, 78)         0           dense_1[209][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_211 (Lambda)              (None, 1, 78)         0           dense_1[210][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_212 (Lambda)              (None, 1, 78)         0           dense_1[211][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_213 (Lambda)              (None, 1, 78)         0           dense_1[212][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_214 (Lambda)              (None, 1, 78)         0           dense_1[213][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_215 (Lambda)              (None, 1, 78)         0           dense_1[214][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_216 (Lambda)              (None, 1, 78)         0           dense_1[215][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_217 (Lambda)              (None, 1, 78)         0           dense_1[216][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_218 (Lambda)              (None, 1, 78)         0           dense_1[217][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_219 (Lambda)              (None, 1, 78)         0           dense_1[218][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_220 (Lambda)              (None, 1, 78)         0           dense_1[219][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_221 (Lambda)              (None, 1, 78)         0           dense_1[220][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_222 (Lambda)              (None, 1, 78)         0           dense_1[221][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_223 (Lambda)              (None, 1, 78)         0           dense_1[222][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_224 (Lambda)              (None, 1, 78)         0           dense_1[223][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_225 (Lambda)              (None, 1, 78)         0           dense_1[224][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_226 (Lambda)              (None, 1, 78)         0           dense_1[225][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_227 (Lambda)              (None, 1, 78)         0           dense_1[226][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_228 (Lambda)              (None, 1, 78)         0           dense_1[227][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_229 (Lambda)              (None, 1, 78)         0           dense_1[228][0]                  \n",
      "====================================================================================================\n",
      "Total params: 41,678\n",
      "Trainable params: 41,678\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the inference model\n",
    "inference_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Expected Output**\n",
    "If you scroll to the bottom of the output, you'll see:\n",
    "```\n",
    "Total params: 41,678\n",
    "Trainable params: 41,678\n",
    "Non-trainable params: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize inference model\n",
    "The following code creates the zero-valued vectors you will use to initialize `x` and the LSTM state variables `a` and `c`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_initializer = np.zeros((1, 1, 78))\n",
    "a_initializer = np.zeros((1, n_a))\n",
    "c_initializer = np.zeros((1, n_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement `predict_and_sample()`. \n",
    "\n",
    "* This function takes many arguments including the inputs [x_initializer, a_initializer, c_initializer]. \n",
    "* In order to predict the output corresponding to this input, you will need to carry-out 3 steps:\n",
    "\n",
    "\n",
    "#### Step 1\n",
    "* Use your inference model to predict an output given your set of inputs. The output `pred` should be a list of length $T_y$ where each element is a numpy-array of shape (1, n_values).\n",
    "```Python\n",
    "inference_model.predict([input_x_init, hidden_state_init, cell_state_init])\n",
    "```\n",
    "    * Choose the appropriate input arguments to `predict` from the input arguments of this `predict_and_sample` function.\n",
    " \n",
    "#### Step 2\n",
    "* Convert `pred` into a numpy array of $T_y$ indices. \n",
    "    * Each index is computed by taking the `argmax` of an element of the `pred` list. \n",
    "    * Use [numpy.argmax](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html).\n",
    "    * Set the `axis` parameter.\n",
    "        * Remember that the shape of the prediction is $(m, T_{y}, n_{values})$\n",
    "\n",
    "#### Step 3  \n",
    "* Convert the indices into their one-hot vector representations. \n",
    "    * Use [to_categorical](https://keras.io/utils/#to_categorical).\n",
    "    * Set the `num_classes` parameter. Note that for grading purposes: you'll need to either:\n",
    "        * Use a dimension from the given parameters of `predict_and_sample()` (for example, one of the dimensions of x_initializer has the value for the number of distinct classes).\n",
    "        * Or just hard code the number of distinct classes (will pass the grader as well).\n",
    "        * Note that using a global variable such as n_values will not work for grading purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict_and_sample\n",
    "\n",
    "def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, \n",
    "                       c_initializer = c_initializer):\n",
    "    \"\"\"\n",
    "    Predicts the next value of values using the inference model.\n",
    "    \n",
    "    Arguments:\n",
    "    inference_model -- Keras model instance for inference time\n",
    "    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation\n",
    "    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell\n",
    "    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel\n",
    "    \n",
    "    Returns:\n",
    "    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated\n",
    "    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.\n",
    "    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])\n",
    "    # Step 2: Convert \"pred\" into an np.array() of indices with the maximum probabilities\n",
    "    indices = np.argmax(pred, axis=2)\n",
    "    # Step 3: Convert indices to one-hot vectors, the shape of the results should be (Ty, n_values)\n",
    "    results = to_categorical(indices, num_classes = x_initializer.shape[2])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return results, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.argmax(results[12]) = 31\n",
      "np.argmax(results[17]) = 39\n",
      "list(indices[12:18]) = [array([31]), array([15]), array([76]), array([65]), array([74]), array([39])]\n"
     ]
    }
   ],
   "source": [
    "results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)\n",
    "print(\"np.argmax(results[12]) =\", np.argmax(results[12]))\n",
    "print(\"np.argmax(results[17]) =\", np.argmax(results[17]))\n",
    "print(\"list(indices[12:18]) =\", list(indices[12:18]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected (Approximate) Output**: \n",
    "\n",
    "* Your results **may likely differ** because Keras' results are not completely predictable. \n",
    "* However, if you have trained your LSTM_cell with model.fit() for exactly 100 epochs as described above: \n",
    "    * You should very likely observe a sequence of indices that are not all identical. \n",
    "    * Moreover, you should observe that: \n",
    "        * np.argmax(results[12]) is the first element of list(indices[12:18]) \n",
    "        * and np.argmax(results[17]) is the last element of list(indices[12:18]). \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **np.argmax(results[12])** =\n",
    "        </td>\n",
    "        <td>\n",
    "        1\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **np.argmax(results[17])** =\n",
    "        </td>\n",
    "        <td>\n",
    "        42\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **list(indices[12:18])** =\n",
    "        </td>\n",
    "        <td>\n",
    "            [array([1]), array([42]), array([54]), array([17]), array([1]), array([42])]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - Generate music \n",
    "\n",
    "Finally, you are ready to generate music. Your RNN generates a sequence of values. The following code generates music by first calling your `predict_and_sample()` function. These values are then post-processed into musical chords (meaning that multiple values or notes can be played at the same time). \n",
    "\n",
    "Most computational music algorithms use some post-processing because it is difficult to generate music that sounds good without such post-processing. The post-processing does things such as clean up the generated audio by making sure the same sound is not repeated too many times, that two successive notes are not too far from each other in pitch, and so on. One could argue that a lot of these post-processing steps are hacks; also, a lot of the music generation literature has also focused on hand-crafting post-processors, and a lot of the output quality depends on the quality of the post-processing and not just the quality of the RNN. But this post-processing does make a huge difference, so let's use it in our implementation as well. \n",
    "\n",
    "Let's make some music! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to generate music and record it into your `out_stream`. This can take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting new values for different set of chords.\n",
      "Generated 51 sounds using the predicted values for the set of chords (\"1\") and after pruning\n",
      "Generated 50 sounds using the predicted values for the set of chords (\"2\") and after pruning\n",
      "Generated 51 sounds using the predicted values for the set of chords (\"3\") and after pruning\n",
      "Generated 50 sounds using the predicted values for the set of chords (\"4\") and after pruning\n",
      "Generated 51 sounds using the predicted values for the set of chords (\"5\") and after pruning\n",
      "Your generated music is saved in output/my_music.midi\n"
     ]
    }
   ],
   "source": [
    "out_stream = generate_music(inference_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To listen to your music, click File->Open... Then go to \"output/\" and download \"my_music.midi\". Either play it on your computer with an application that can read midi files if you have one, or use one of the free online \"MIDI to mp3\" conversion tools to convert this to mp3.  \n",
    "\n",
    "As a reference, here is a 30 second audio clip we generated using this algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio('./data/30s_trained_model.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    "\n",
    "You have come to the end of the notebook. \n",
    "\n",
    "\n",
    "## What you should remember\n",
    "- A sequence model can be used to generate musical values, which are then post-processed into midi music. \n",
    "- Fairly similar models can be used to generate dinosaur names or to generate music, with the major difference being the input fed to the model.  \n",
    "- In Keras, sequence generation involves defining layers with shared weights, which are then repeated for the different time steps $1, \\ldots, T_x$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on completing this assignment and generating a jazz solo! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "The ideas presented in this notebook came primarily from three computational music papers cited below. The implementation here also took significant inspiration and used many components from Ji-Sung Kim's GitHub repository.\n",
    "\n",
    "- Ji-Sung Kim, 2016, [deepjazz](https://github.com/jisungk/deepjazz)\n",
    "- Jon Gillick, Kevin Tang and Robert Keller, 2009. [Learning Jazz Grammars](http://ai.stanford.edu/~kdtang/papers/smc09-jazzgrammar.pdf)\n",
    "- Robert Keller and David Morrison, 2007, [A Grammatical Approach to Automatic Improvisation](http://smc07.uoa.gr/SMC07%20Proceedings/SMC07%20Paper%2055.pdf)\n",
    "- François Pachet, 1999, [Surprising Harmonies](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.7473&rep=rep1&type=pdf)\n",
    "\n",
    "We're also grateful to François Germain for valuable feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "EG0F7",
   "launcher_item_id": "cxJXc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
